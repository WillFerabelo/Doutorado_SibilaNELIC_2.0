import streamlit as st
import pandas as pd
import json
import os
import time
from datetime import datetime
import plotly.express as px
from io import BytesIO
from fpdf import FPDF
from typing import Dict, List, Any, Optional, Tuple, Callable
import hashlib

# ==========================================
# 1. CONFIGURA√á√ÉO E ESTILO
# ==========================================

st.set_page_config(
    page_title="SISTEMA NELIC - SIBILA",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Vocabul√°rio Controlado e Metodologia (agora em um m√≥dulo de dados)
# (Dados movidos para dentro da classe DataModule para encapsulamento)
# Tipos textuais que N√ÉO exigem resumo anal√≠tico
TIPOS_SEM_RESUMO = {"POEMA", "POEMA(S)", "FIC√á√ÉO", "CAPA", "IMAGEM", "HQ/CHARGE", "HQ", "CHARGE", "ARTES PL√ÅSTICAS"}

# Caminhos de arquivos
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FILE_PATH = os.path.join(BASE_DIR, 'catalogo_sibila.json')
DIARIO_PATH = os.path.join(BASE_DIR, 'diario_sibila.json')
BACKUP_DIR = os.path.join(BASE_DIR, 'backups')
LOGO_PATH = os.path.join(BASE_DIR, 'NELIC.png')  # Arquivo de Logo

# Estilos CSS
CSS_STYLES = """
<style>
.main { 
    background: radial-gradient(circle at top left, #f5f7fb 0%, #f1f3f5 40%, #eceff1 100%);
    padding-top: 1rem;
}
.block-container {
    padding-top: 2.2rem;
    max-width: 1300px;
}
.stDeployButton {display: none !important;}
#MainMenu {visibility: hidden !important;}
footer {visibility: hidden !important;}
.viewerBadge_container__1QSob {display: none !important;}
.styles_viewerBadge__1yB5_ {display: none !important;}
h1 {
    color: #1f2933;
    font-weight: 800 !important;
    text-transform: uppercase;
    border-bottom: 3px solid #2f5f98;
    padding-bottom: 10px;
    margin-bottom: 20px;
    font-size: 2rem !important;
    letter-spacing: 1px;
}
h2, h3, h4 { 
    color: #243b53;
    text-transform: uppercase;
    font-weight: 700;
    margin-top: 1.5rem;
    letter-spacing: 0.06em;
}
section[data-testid="stSidebar"] {
    background: linear-gradient(180deg, #ffffff 0%, #f6f7fb 100%);
    border-right: 1px solid #d8e2ec;
    box-shadow: 2px 0 16px rgba(15, 23, 42, 0.06);
}
section[data-testid="stSidebar"] > div {
    padding-top: 1.5rem;
}
.stButton > button, .stDownloadButton > button {
    border-radius: 999px;
    font-weight: 600;
    text-transform: uppercase;
    width: 100%;
    transition: all 0.25s ease;
    border: 1px solid #2f5f98;
    background-color: #2f5f98;
    color: white;
    letter-spacing: 0.06em;
    font-size: 0.78rem;
}
.stButton > button:hover, .stDownloadButton > button:hover {
    transform: translateY(-1px);
    box-shadow: 0 8px 18px rgba(15, 23, 42, 0.18);
    background-color: #23466f;
    border-color: #23466f;
}
.stTextArea textarea {
    font-family: 'Georgia', 'Times New Roman', serif;
    font-size: 0.95rem;
    line-height: 1.6;
    border-radius: 6px;
    padding: 0.75rem;
}
.stTextInput input {
    font-family: 'Georgia', 'Times New Roman', serif;
    font-size: 0.95rem;
    line-height: 1.5;
}
.nelic-card {
    border-radius: 14px;
    padding: 1.1rem 1.2rem;
    margin-bottom: 0.8rem;
    background: #ffffff;
    border: 1px solid rgba(148, 163, 184, 0.35);
    box-shadow: 0 8 20px rgba(15, 23, 42, 0.04);
}
.nelic-card-header {
    font-weight: 700;
    color: #1f2933;
    margin-bottom: 0.35rem;
    font-size: 0.92rem;
    text-transform: uppercase;
    letter-spacing: 0.06em;
}
.nelic-card-subtitle {
    color: #62748a;
    font-size: 0.8rem;
    margin-bottom: 0.35rem;
}
.nelic-tag {
    display: inline-block;
    padding: 0.15rem 0.55rem;
    margin-right: 0.3rem;
    margin-bottom: 0.3rem;
    border-radius: 999px;
    background-color: #e3edff;
    color: #243b53;
    font-size: 0.72rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.06em;
}
.nelic-tag-muted {
    background-color: #e5e7eb;
    color: #4b5563;
}
.nelic-muted {
    color: #6b7b93;
    font-size: 0.8rem;
}
div[data-testid="stMetricValue"] {
    font-size: 1.8rem;
    font-weight: 700;
    color: #1f2933;
}
div[data-testid="stMetricLabel"] {
    font-size: 0.78rem;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    color: #6b7b93;
}
div[data-testid="stDataFrame"] {
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 8 18px rgba(15, 23, 42, 0.06);
    background-color: white;
}
button[data-baseweb="tab"] {
    font-size: 0.78rem !important;
    text-transform: uppercase;
    letter-spacing: 0.08em;
}
.info-box {
    background-color: #e3f2fd;
    border-left: 4px solid #2f5f98;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}
.warning-box {
    background-color: #fff3e0;
    border-left: 4px solid #ff9800;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}
.success-box {
    background-color: #e8f5e9;
    border-left: 4px solid #4caf50;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}
/* Estilos Metodologia S√≥bria */
.metod-section {
    background: #f9fafb;
    padding: 1.5rem;
    border-radius: 8px;
    margin-bottom: 1.5rem;
    border: 1px solid #e5e7eb;
}
.metod-section h4 {
    color: #374151;
    font-size: 1.05rem;
    font-weight: 700;
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid #d1d5db;
}
.metod-section p, .metod-section li {
    color: #4b5563;
    font-size: 0.95rem;
    line-height: 1.7;
}
.metod-section ul {
    margin: 0.75rem 0;
    padding-left: 1.5rem;
}
.metod-section li {
    margin-bottom: 0.5rem;
}
.metod-section strong {
    color: #1f2937;
    font-weight: 600;
}
</style>
"""

st.markdown(CSS_STYLES, unsafe_allow_html=True)

# ==========================================
# 2. CLASSES E M√ìDULOS
# ==========================================

class DataModule:
    """Encapsula dados est√°ticos e fun√ß√µes de normaliza√ß√£o."""
    LISTA_PALAVRAS_CHAVE = sorted(list(set([x.title() for x in [
        "Absurdo", "Adolesc√™ncia", "√Åfrica", "Agricultura", "Alegoria", "Alemanha", "Alimenta√ß√£o", "Amaz√¥nia",
        "Ambival√™ncia", "Am√©rica", "Am√©rica Latina", "Amor", "An√°lise Do Discurso", "Anarquismo", "Antiguidade",
        "Antologia", "Antropologia", "Argentina", "Arqueologia", "Arquitetura", "Arte",
        "Arte Gr√°fica", "Artes Pl√°sticas", "Artesanato", "Astrologia", "√Åustria", "Autonomia", "Autoria",
        "Autoritarismo", "Barroco", "Best Seller", "B√≠blia", "Biblioteca", "Biografia", "Biologia", "Bossa Nova",
        "Brasil", "Bruxaria", "Burguesia", "C√¢mbio", "C√¢none Liter√°rio", "Capitalismo", "Caricatura", "Carnaval",
        "Cartas", "Casamento", "Catolicismo", "Censura", "Chanchada", "Chile", "China", "Cidade", "Ci√™ncia",
        "Cinema", "Cinema Novo", "Classe", "Classe M√©dia", "Colonialismo", "Com√©dia", "C√¥mico", "Compet√™ncia",
        "Comportamento", "Compromisso", "Comunica√ß√£o", "Comunismo", "Coloniza√ß√£o", "Concretismo", "Concurso",
        "Consumo", "Contempor√¢neo", "Conto", "Contra Cultura", "Cren√ßas Populares", "Cria√ß√£o", "Crise",
        "Cr√≠tica", "Cr√¥nica", "Cuba", "Cultura", "Cultura Alternativa", "Cultura Popular", "Dada√≠smo", "Dan√ßa",
        "D√©cada De 20", "D√©cada De 30", "D√©cada De 40", "D√©cada De 50", "D√©cada De 60", "D√©cada De 70",
        "D√©cada De 80", "D√©cada De 90", "Democracia", "Demografia", "Descoloniza√ß√£o", "Desconhecimento",
        "Desconstru√ß√£o", "Design", "Despotismo", "Dial√©tica", "Direito", "Direitos Autorais", "Discos",
        "Discrimina√ß√£o", "Discurso", "Ditadura", "Document√°rio", "Drama", "Dramaturgia", "Drogas", "Ecletismo",
        "Ecologia", "Economia", "Editor", "Educa√ß√£o", "Efem√©ride", "Elite", "Enciclopedismo", "Energia",
        "Engajamento Pol√≠tico", "Ensaio", "Ensino", "Entretenimento", "Epistemologia", "Erotismo",
        "Escola De Frankfurt", "Escravid√£o", "Escritor", "Escritura", "Escultura", "Exoterismo", "Espa√ßo",
        "Espanha", "Esporte", "Estado", "Estado Novo", "Estados Unidos", "Est√©tica", "Estrutura",
        "Estruturalismo", "√âtica", "Etnografia", "Etno-hist√≥ria", "Etnologia", "Europa", "Eventos",
        "Existencialismo", "Experimentalismo", "Expressionismo", "Fant√°stico", "Fascismo", "Feminismo",
        "Fenomenologia", "Fic√ß√£o", "Fic√ß√£o Cient√≠fica", "Filologia", "Filosofia", "F√≠sica", "Folclore",
        "Folhetim", "Formalismo", "Fotografia", "Fran√ßa", "Funcionalismo", "Futebol", "Futurismo", "Genealogia",
        "G√™nero", "Geografia", "Gera√ß√£o De 45", "Gera√ß√£o Marginal", "Globaliza√ß√£o", "Golpe Militar", "Grafite",
        "Gram√°tica", "Guerra", "Guerra Fria", "Hermen√™utica", "Her√≥i", "Heterogeneidade", "Hispano-Am√©rica",
        "Hist√≥ria", "Hist√≥ria Do Brasil", "Hist√≥ria Em Quadrinhos", "Historiografia", "Homossexualidade",
        "Humanismo", "Humor", "Idade M√©dia", "Idealiza√ß√£o", "Identidade", "Ideograma", "Ideologia", "Idioma",
        "Igreja", "Iluminismo", "Imagem", "Imagina√ß√£o", "Imigra√ß√£o", "Imperialismo", "Imprensa",
        "Imprensa Alternativa", "Impressionismo", "Inconfid√™ncia Mineira", "Inconsciente", "Independ√™ncia",
        "√çndia", "Indianismo", "√çndio", "Ind√∫stria Cultural", "Industrializa√ß√£o", "Inf√¢ncia", "Inform√°tica",
        "Informes", "Inglaterra", "Institui√ß√µes", "Intelectual", "Interdisciplinar", "Intelectualidade",
        "Inven√ß√£o", "Ironia", "It√°lia", "Jap√£o", "Jazz", "Jornalismo", "Juda√≠smo", "Justi√ßa", "Kitsch", "Leitor",
        "Liberalismo", "Liberdade", "L√≠ngua", "L√≠ngua Inglesa", "L√≠ngua Portuguesa", "Linguagem", "Lingu√≠stica",
        "L√≠rico", "Lirismo", "Literatura", "Literatura Comparada", "Literatura De Cordel",
        "Literatura Infanto-juvenil", "Literatura Policial", "Livro Did√°tico", "Livros", "L√≥gica", "Loucura",
        "Luta De Classes", "Magia", "Mais-valia", "Manifesto", "Marginalidade", "Marxismo", "Matem√°tica",
        "Mato Grosso", "Medicina", "Mem√≥ria", "Mercado", "Mercado Editorial", "Mercado Fonogr√°fico",
        "Metaf√≠sica", "Met√°fora", "Metalinguagem", "Metodologia De Pesquisa", "M√©trica", "M√©xico", "M√≠dia",
        "Mimesis", "Minas Gerais", "Minoria Sociais", "Misticismo", "Mito", "Mitologia", "Moda", "Modernidade",
        "Modernismo", "Monarquia", "Monop√≥lio", "Moral", "Morte", "Movimento", "Movimento Ideol√≥gico", "MPB",
        "Mulher", "Museu", "M√∫sica", "M√∫sica Erudita", "M√∫sica Popular", "Na√ß√£o", "Nacionalismo", "Narrador",
        "Narrativa", "Naturalismo", "Natureza", "Nazismo", "Negros", "Neoconcretismo", "Neurologia", "Nordeste",
        "Nova Rep√∫blica", "Novela", "Obra", "Obra De Arte", "Ocidente", "Oligarquia", "Ontologia", "√ìpera",
        "Oralidade", "Oriente", "Origem", "Originalidade", "Paran√°", "Parnasianismo", "Par√≥dia",
        "Partido Comunista", "Pastiche", "Patrim√¥nio Cultural", "Pedagogia", "Periferia", "Periodismo",
        "Peronismo", "Personagem", "Pintura", "Pl√°gio", "Pluralismo", "Poder", "Poema √âpico", "Poema Processo",
        "Poema Visual", "Poesia Marginal", "Poesia", "Po√©tica", "Pol√™mica", "Pol√≠cia", "Polifonia", "Pol√≠tica",
        "Pol√¥nia", "Pop Art", "Populismo", "Pornografia", "Portugal", "P√≥s-estruturalismo", "Positivismo",
        "P√≥s-modernidade", "P√≥s Modernismo", "Pr√© Hist√≥ria", "Pr√™mio", "Premio Nobel", "Privatiza√ß√µes",
        "Proletariado", "Prostitui√ß√£o", "Proto-s√°tira", "Psican√°lise", "Psicologia", "Psicoterapia",
        "Psiquiatria", "Publicidade", "Qu√≠mica", "Racismo", "R√°dio", "Raz√£o", "Rea√ß√£o", "Ready-made", "Realismo",
        "Realismo Fant√°stico", "Realismo M√°gico", "Rebeldia", "Reforma Agr√°ria", "Regime Pol√≠tico",
        "Regionalismo", "Rela√ß√µes Internacionais", "Rela√ß√µes Raciais", "Rela√ß√µes Sociais", "Relato", "Religi√£o",
        "Renascimento", "Reportagem", "Representa√ß√£o", "Repress√£o", "Rep√∫blica", "Rep√∫blica Velha", "Ret√≥rica",
        "Revolu√ß√£o", "Revolu√ß√£o De 1930", "Revolu√ß√£o Francesa", "Revolu√ß√£o Industrial", "Rio De Janeiro",
        "Rio Grande Do Sul", "Rito", "Rock And Roll", "Romance", "Romantismo", "Ruptura", "R√∫ssia", "Samba",
        "S√£o Paulo", "S√°tira", "Sa√∫de", "SBPC", "S√©culo XIX", "S√©culo XVI", "S√©culo XVII", "S√©culo XVIII",
        "S√©culo XX", "S√©culo XXI", "Semana De Arte Moderna", "Sem√¢ntica", "Semiologia", "Semi√≥tica", "Servilismo",
        "Sexualidade", "Sil√™ncio", "Simbolismo", "Simbologia", "Sindicalismo", "S√≠nteses", "Socialismo",
        "Sociedade", "Sociedade Industrial", "Sociologia", "Solid√£o", "Stalinismo", "Subdesenvolvimento",
        "Sujeito", "Surrealismo", "Tatuagem", "Teatro", "T√©cnica", "Tecnocracia", "Tecnologia", "Telespectador",
        "Televis√£o", "Tempo", "Teologia", "Teoria", "Teoria Da Linguagem", "Teoria Liter√°ria", "Teoria Social",
        "Terrorismo", "Texto", "Tortura", "Trabalho", "Tradi√ß√£o", "Tradu√ß√£o", "Trag√©dia", "Trai√ß√£o",
        "Transgress√£o", "Tropicalismo", "Umbanda", "Underground", "Unidade", "Universalidade", "Universidade",
        "Urbanismo", "URSS", "Uruguai", "Utopia", "Vanguarda", "Verdade", "Vestibular", "Viagem", "Viol√™ncia"
    ]])))

    LISTA_ICONOGRAFIA = [
        "Cartografia", "Fac-s√≠mile", "Foto", "Fotograma", "Gr√°fico/Tabela",
        "HQ/Charge", "Ilustra√ß√£o", "Publicidade", "Reprodu√ß√£o"
    ]

    G√äNEROS_TEXTUAIS = {
        "APRESENTA√á√ÉO": ["Sem especifica√ß√£o", "Literatura"],
        "ARTES PL√ÅSTICAS": ["Sem especifica√ß√£o"],
        "CAPA": ["Sem especifica√ß√£o"],
        "CARTAS DO LEITOR": ["Sem especifica√ß√£o"],
        "CHARGE": ["Sem especifica√ß√£o"],
        "CORRESPOND√äNCIA(S)": ["Sem especifica√ß√£o"],
        "DEBATE": ["Sem especifica√ß√£o"],
        "DEPOIMENTO": ["Sem especifica√ß√£o", "Literatura"],
        "EDITORIAL": ["Sem especifica√ß√£o", "Literatura"],
        "ENSAIO": [
            "Sem especifica√ß√£o", "Antropologia", "Arquitetura", "Bibliologia", "Ci√™ncia",
            "Comunica√ß√£o", "Cultura", "Economia", "Educa√ß√£o", "Esporte", "Filosofia",
            "Fotogr√°fico", "Hist√≥ria", "Lingu√≠stica", "Literatura", "Pol√≠tica",
            "Psican√°lise", "Psicologia", "Sociologia", "Teologia"
        ],
        "ENTREVISTA": ["Sem especifica√ß√£o", "Literatura"],
        "FIC√á√ÉO": ["Sem especifica√ß√£o"],
        "HQ": ["Sem especifica√ß√£o"],
        "HQ/CHARGE": ["Sem especifica√ß√£o"],
        "INFORME": ["Sem especifica√ß√£o", "Literatura"],
        "POEMA(S)": ["Sem especifica√ß√£o"],
        "REPORTAGEM": ["Sem especifica√ß√£o", "Literatura"],
        "RESENHA": [
            "Sem especifica√ß√£o", "Antropologia", "Arquitetura", "Bibliologia", "Ci√™ncia",
            "Comunica√ß√£o", "Cultura", "Economia", "Educa√ß√£o", "Filosofia", "Hist√≥ria",
            "Lingu√≠stica", "Literatura", "Pol√≠tica", "Psican√°lise", "Psicologia", "Sociologia"
        ],
        "VARIEDADES": ["Sem especifica√ß√£o"]
    }

    @staticmethod
    def normalizar_texto(val: str | list) -> str | list:
        """Normaliza texto gen√©rico (palavras-chave etc.) para Title Case."""
        if isinstance(val, list):
            return [i.strip().title() for i in val if str(i).strip()]
        if isinstance(val, str):
            return val.strip().title()
        return val

    @staticmethod
    def format_nome_abnt(nome: str | None) -> str:
        """
        Normaliza nomes pessoais segundo ABNT.
        Ex.: 'Bonvicino, R√©gis' -> 'BONVICINO, R√©gis'
        """
        if nome is None:
            return ""
        if not isinstance(nome, str):
            nome = str(nome)
        s = " ".join(nome.strip().split())
        if not s:
            return ""
        if "," in s:
            ult, resto = s.split(",", 1)
            return f"{ult.strip().upper()}, {resto.strip()}" if resto.strip() else ult.strip().upper()
        partes = s.split()
        if len(partes) >= 2:
            sobrenome = partes[-1].upper()
            prenomes = " ".join(partes[:-1])
            return f"{sobrenome}, {prenomes}"
        return s.upper()

    @staticmethod
    def parse_multiline(texto: str | None) -> list[str]:
        if texto is None:
            return []
        if not isinstance(texto, str):
            texto = str(texto)
        # Split only on newlines to preserve commas in ABNT format names
        linhas = texto.split('\n')
        return [l.strip() for l in linhas if l.strip()]

    @staticmethod
    def normalizar_lista_autores(texto: str | list) -> list[str]:
        nomes = DataModule.parse_multiline(texto)
        return [DataModule.format_nome_abnt(n) for n in nomes]

    @staticmethod
    def get_normalized_series(df: pd.DataFrame, col: str) -> pd.Series:
        """
        Explode coluna, remove vazios. Para campos de autor, aplica formata√ß√£o ABNT
        sem rebaixar para Title Case (preserva SOBRENOME em CAIXA ALTA).
        """
        if col not in df.columns:
            return pd.Series(dtype='object')
        s = (
            df.explode(col)[col]
            .dropna()
            .astype(str)
            .str.strip()
            .replace('', pd.NA)
            .dropna()
        )
        if col in {'autores_colaboradores', 'autores_citados', 'tradutores', 'entidade_coletiva', 'nome_pessoal_como_assunto'}:
            s = s.apply(DataModule.format_nome_abnt)
        return s

class PersistenceModule:
    """Encapsula fun√ß√µes de carregamento e salvamento de dados."""
    @staticmethod
    @st.cache_data(ttl=60)
    def load_data():
        if not os.path.exists(FILE_PATH):
            return []
        try:
            with open(FILE_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erro ao carregar dados: {str(e)}")
            return []

    @staticmethod
    def save_data(data):
        try:
            if os.path.exists(FILE_PATH):
                if not os.path.exists(BACKUP_DIR):
                    os.makedirs(BACKUP_DIR)
                bkp = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(FILE_PATH, 'r', encoding='utf-8') as f:
                    with open(os.path.join(BACKUP_DIR, bkp), 'w', encoding='utf-8') as b:
                        json.dump(json.load(f), b, ensure_ascii=False, indent=2)
            with open(FILE_PATH, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            PersistenceModule.load_data.clear()
            return True
        except Exception as e:
            st.error(f"Erro ao salvar dados: {str(e)}")
            return False

    @staticmethod
    def load_diario():
        if not os.path.exists(DIARIO_PATH):
            return []
        try:
            with open(DIARIO_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erro ao carregar di√°rio: {str(e)}")
            return []

    @staticmethod
    def save_diario(entries):
        try:
            with open(DIARIO_PATH, 'w', encoding='utf-8') as f:
                json.dump(entries, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            st.error(f"Erro ao salvar di√°rio: {str(e)}")
            return False

class PDFModule:
    """Encapsula fun√ß√µes de gera√ß√£o de PDF."""
    @staticmethod
    def to_latin1(texto):
        if texto is None:
            return ""
        if not isinstance(texto, str):
            texto = str(texto)
        texto = (
            texto
            .replace('\u2013', '-')
            .replace('\u2014', '-')
            .replace('\u2015', '-')
            .replace('\u2022', '*')
        )
        return texto.encode('latin-1', 'replace').decode('latin-1')

    @staticmethod
    def add_nelic_logo_to_pdf(pdf):
        if os.path.exists(LOGO_PATH):
            try:
                pdf.image(LOGO_PATH, x=10, y=10, w=20, h=0)
            except Exception:
                pass

    @staticmethod
    def gerar_pdf_analitico(df, total, crit):
        """Relat√≥rio anal√≠tico gen√©rico (lista de registros) com % na base."""
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule.add_nelic_logo_to_pdf(pdf)
            pdf.set_font("Arial", 'B', 16)
            pdf.set_xy(35, 12)
            pdf.cell(0, 10, PDFModule.to_latin1("RELAT√ìRIO ANAL√çTICO - PROJETO SIBILA"), ln=True, align='C')
            pdf.set_font("Arial", '', 10)
            pdf.set_x(35)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Emiss√£o: {datetime.now().strftime('%d/%m/%Y')}"), ln=True, align='C')
            pdf.ln(5)
            pdf.set_fill_color(240, 240, 240)
            pdf.rect(10, 45, 190, 25, 'F')
            pdf.set_y(48)
            pdf.set_x(15)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Crit√©rio: {crit}"), ln=True)
            pdf.set_x(15)
            pdf.set_font("Arial", '', 11)
            qtd = len(df)
            pct = (qtd / total * 100) if total > 0 else 0
            pdf.cell(0, 6, PDFModule.to_latin1(f"Registros encontrados: {qtd} de {total} (total da base)"), ln=True)
            pdf.set_x(15)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Percentual da base total: {pct:.2f}%"), ln=True)
            pdf.ln(15)
            for _, r in df.iterrows():
                if pdf.get_y() > 250:
                    pdf.add_page()
                try:
                    tit = PDFModule.to_latin1(r.get('titulo_artigo', ''))
                    tip = PDFModule.to_latin1(r.get('vocabulario_controlado', ''))
                    rev = PDFModule.to_latin1(r.get('n', ''))
                    pags = PDFModule.to_latin1(r.get('paginas', ''))
                    pdf.set_font("Arial", 'B', 11)
                    pdf.multi_cell(0, 6, f"[{tip}] REVISTA {rev} | pp. {pags}")
                    if tit:
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, tit)
                    aut = r.get('autores_colaboradores', [])
                    if aut:
                        if isinstance(aut, list):
                            s_aut = ', '.join([DataModule.format_nome_abnt(a) for a in aut if a])
                        else:
                            s_aut = DataModule.format_nome_abnt(aut)
                        s_aut = PDFModule.to_latin1(s_aut)
                        pdf.set_font("Arial", 'I', 10)
                        pdf.multi_cell(0, 6, f"Autores: {s_aut}")
                    nota_ed = r.get('nota_edicao', '')
                    if nota_ed:
                        ne = PDFModule.to_latin1(nota_ed)
                        pdf.set_font("Arial", 'I', 9)
                        pdf.multi_cell(0, 5, f"Nota de edi√ß√£o: {ne}")
                    icons = r.get('iconografias', [])
                    if isinstance(icons, list) and icons:
                        icon_txt = []
                        for ic in icons:
                            t = ic.get('tipo', '')
                            d = ic.get('descricao', '')
                            if t or d:
                                icon_txt.append(f"{t}: {d}")
                        if icon_txt:
                            s_icon = PDFModule.to_latin1(" | ".join(icon_txt))
                            pdf.set_font("Arial", 'I', 9)
                            pdf.set_text_color(100, 100, 100)
                            pdf.multi_cell(0, 5, f"[Iconografia]: {s_icon}")
                            pdf.set_text_color(0, 0, 0)
                    res = r.get('resumo', '')
                    if res:
                        resumo_txt = PDFModule.to_latin1(res)
                        # REMOVIDA LIMITA√á√ÉO: imprime resumo completo sem corte
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, resumo_txt)
                    pdf.ln(5)
                    pdf.line(10, pdf.get_y(), 200, pdf.get_y())
                    pdf.ln(5)
                except Exception:
                    continue
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_busca_analitica(df_reg, total_base, crit, df_citados=None, df_colab=None):
        """
        Relat√≥rio da aba EXPLORAR DADOS, incluindo:
        - Crit√©rios de busca
        - N¬∫ de registros e % na base
        - Resumo de 'Autores citados' e 'Autores colaboradores' (tabelas da sele√ß√£o)
        - Lista de registros
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule.add_nelic_logo_to_pdf(pdf)
            pdf.set_font("Arial", 'B', 16)
            pdf.set_xy(35, 12)
            pdf.cell(0, 10, PDFModule.to_latin1("RELAT√ìRIO DE BUSCA - PROJETO SIBILA"), ln=True, align='C')
            pdf.set_font("Arial", '', 10)
            pdf.set_x(35)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Emiss√£o: {datetime.now().strftime('%d/%m/%Y')}"), ln=True, align='C')
            pdf.ln(5)
            pdf.set_fill_color(240, 240, 240)
            pdf.rect(10, 45, 190, 30, 'F')
            pdf.set_y(48)
            pdf.set_x(15)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Crit√©rio(s): {crit}"), ln=True)
            qtd = len(df_reg)
            pct = (qtd / total_base * 100) if total_base > 0 else 0
            pdf.set_x(15)
            pdf.set_font("Arial", '', 11)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Registros encontrados: {qtd} de {total_base} (total da base)"), ln=True)
            pdf.set_x(15)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Percentual da base total: {pct:.2f}%"), ln=True)
            pdf.ln(10)
            if df_citados is not None and not df_citados.empty:
                pdf.set_font("Arial", 'B', 11)
                pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores citados na sele√ß√£o (Top 10)"))
                pdf.set_font("Arial", '', 10)
                for _, row in df_citados.head(10).iterrows():
                    if pdf.get_y() > 260:
                        pdf.add_page()
                        pdf.set_font("Arial", 'B', 11)
                        pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores citados na sele√ß√£o (cont.)"))
                        pdf.set_font("Arial", '', 10)
                    linha = f"- {row['Termo']}: {row['Qtd']} ocorr√™ncia(s) ({row['%']})"
                    pdf.multi_cell(0, 5, PDFModule.to_latin1(linha))
                pdf.ln(6)
            if df_colab is not None and not df_colab.empty:
                pdf.set_font("Arial", 'B', 11)
                pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores colaboradores na sele√ß√£o (Top 10)"))
                pdf.set_font("Arial", '', 10)
                for _, row in df_colab.head(10).iterrows():
                    if pdf.get_y() > 260:
                        pdf.add_page()
                        pdf.set_font("Arial", 'B', 11)
                        pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores colaboradores na sele√ß√£o (cont.)"))
                        pdf.set_font("Arial", '', 10)
                    linha = f"- {row['Termo']}: {row['Qtd']} ocorr√™ncia(s) ({row['%']})"
                    pdf.multi_cell(0, 5, PDFModule.to_latin1(linha))
                pdf.ln(8)
            pdf.set_font("Arial", 'B', 11)
            pdf.multi_cell(0, 6, PDFModule.to_latin1("Registros da sele√ß√£o"))
            pdf.ln(3)
            for _, r in df_reg.iterrows():
                if pdf.get_y() > 250:
                    pdf.add_page()
                try:
                    tit = PDFModule.to_latin1(r.get('titulo_artigo', ''))
                    tip = PDFModule.to_latin1(r.get('vocabulario_controlado', ''))
                    rev = PDFModule.to_latin1(r.get('n', ''))
                    pags = PDFModule.to_latin1(r.get('paginas', ''))
                    pdf.set_font("Arial", 'B', 11)
                    pdf.multi_cell(0, 6, f"[{tip}] REVISTA {rev} | pp. {pags}")
                    if tit:
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, tit)
                    aut = r.get('autores_colaboradores', [])
                    if aut:
                        if isinstance(aut, list):
                            s_aut = ', '.join([DataModule.format_nome_abnt(a) for a in aut if a])
                        else:
                            s_aut = DataModule.format_nome_abnt(aut)
                        s_aut = PDFModule.to_latin1(s_aut)
                        pdf.set_font("Arial", 'I', 10)
                        pdf.multi_cell(0, 6, f"Autores: {s_aut}")
                    nota_ed = r.get('nota_edicao', '')
                    if nota_ed:
                        ne = PDFModule.to_latin1(nota_ed)
                        pdf.set_font("Arial", 'I', 9)
                        pdf.multi_cell(0, 5, f"Nota de edi√ß√£o: {ne}")
                    res = r.get('resumo', '')
                    if res:
                        resumo_txt = PDFModule.to_latin1(res)
                        # REMOVIDA LIMITA√á√ÉO: imprime resumo completo sem corte
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, resumo_txt)
                    pdf.ln(5)
                    pdf.line(10, pdf.get_y(), 200, pdf.get_y())
                    pdf.ln(5)
                except Exception:
                    continue
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF da busca: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio de busca"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_ficha(registro):
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule.add_nelic_logo_to_pdf(pdf)
            pdf.set_font("Arial", 'B', 14)
            pdf.set_xy(35, 12)
            pdf.cell(0, 10, PDFModule.to_latin1("FICHA NELIC ‚Äì PROJETO SIBILA"), ln=True, align='C')
            pdf.set_font("Arial", '', 9)
            pdf.set_x(35)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Emiss√£o: {datetime.now().strftime('%d/%m/%Y')}"), ln=True, align='C')
            pdf.ln(4)
            pdf.set_y(30)
            def safe(text):
                return PDFModule.to_latin1(text)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("1. IDENTIFICA√á√ÉO"), ln=True)
            pdf.set_font("Arial", '', 10)
            pdf.multi_cell(0, 5, safe(f"N¬∫ revista: {registro.get('n','')}"))
            pdf.multi_cell(0, 5, safe(f"Registro: {registro.get('registro','')}"))
            pdf.multi_cell(0, 5, safe(f"P√°ginas: {registro.get('paginas','')}"))
            pdf.multi_cell(0, 5, safe(f"Tipo textual: {registro.get('vocabulario_controlado','')}"))
            pdf.multi_cell(
                0, 5,
                safe(f"Idiomas: {registro.get('idioma_01','')} / {registro.get('idioma_02','')}")
            )
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("2. RESPONSABILIDADE AUTORAL"), ln=True)
            pdf.set_font("Arial", '', 10)
            colab = registro.get('autores_colaboradores', [])
            entidade = registro.get('entidade_coletiva', [])
            trad = registro.get('tradutores', [])
            nome_ass = registro.get('nome_pessoal_como_assunto', [])
            if colab:
                lst = colab if isinstance(colab, list) else [colab]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Colaboradores: {s}"))
            if entidade:
                lst = entidade if isinstance(entidade, list) else [entidade]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Entidade Coletiva: {s}"))
            if trad:
                lst = trad if isinstance(trad, list) else [trad]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Tradutores: {s}"))
            if nome_ass:
                lst = nome_ass if isinstance(nome_ass, list) else [nome_ass]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Nome pessoal como assunto: {s}"))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("3. CONTE√öDO"), ln=True)
            pdf.set_font("Arial", '', 10)
            pdf.multi_cell(0, 5, safe(f"T√≠tulo: {registro.get('titulo_artigo','')}"))
            sub = registro.get('subtitulo_artigo', '')
            if sub:
                pdf.multi_cell(0, 5, safe(f"Subt√≠tulo: {sub}"))
            nota_ed = registro.get('nota_edicao', '')
            if nota_ed:
                pdf.multi_cell(0, 5, safe(f"Nota de edi√ß√£o: {nota_ed}"))
            res = registro.get('resumo', '')
            if res:
                pdf.ln(1)
                pdf.set_font("Arial", 'I', 10)
                pdf.multi_cell(0, 4, safe(res))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("4. ASSUNTOS"), ln=True)
            pdf.set_font("Arial", '', 10)
            kw = registro.get('palavras_chave', [])
            aut_cit = registro.get('autores_citados', [])
            if kw:
                s = ", ".join(kw) if isinstance(kw, list) else kw
                pdf.multi_cell(0, 5, safe(f"Palavras-chave: {s}"))
            if aut_cit:
                lst = aut_cit if isinstance(aut_cit, list) else [aut_cit]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Autores citados: {s}"))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("5. ICONOGRAFIA"), ln=True)
            pdf.set_font("Arial", '', 10)
            icons = registro.get('iconografias', [])
            if icons:
                for ic in icons:
                    linha = f"- {ic.get('tipo','')}: {ic.get('descricao','')}"
                    pdf.multi_cell(0, 5, safe(linha))
            else:
                pdf.multi_cell(0, 5, safe("Sem iconografia registrada."))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("6. NOTAS DE PESQUISA"), ln=True)
            pdf.set_font("Arial", '', 10)
            notas = registro.get('notas_pesquisa', [])
            if notas:
                for n in sorted(notas, key=lambda x: x.get('data', ''), reverse=True):
                    data_str = n.get('data', '')[:10]
                    t = n.get('titulo', '')
                    txt = n.get('texto', '')
                    tags = n.get('tags', [])
                    pdf.set_font("Arial", 'B', 9)
                    pdf.multi_cell(0, 4, safe(f"[{data_str}] {t}"))
                    if tags:
                        pdf.set_font("Arial", 'I', 8)
                        pdf.multi_cell(0, 4, safe("Tags: " + ", ".join(tags)))
                    pdf.set_font("Arial", '', 9)
                    pdf.multi_cell(0, 4, safe(txt))
                    pdf.ln(1)
            else:
                pdf.multi_cell(0, 5, safe("Sem notas vinculadas a este registro at√© o momento."))
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar ficha em PDF: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar ficha"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_tabela_estatistica(df_stats, titulo):
        """
        Gera PDF apenas com tabela de estat√≠sticas (campo, num. absoluto, percentual),
        seguindo o modelo dos relat√≥rios de tipos textuais e palavras-chave do sistema original.
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule.add_nelic_logo_to_pdf(pdf)
            pdf.set_font("Arial", 'B', 16)
            pdf.set_xy(35, 12)
            pdf.cell(0, 10, PDFModule.to_latin1(f"ESTAT√çSTICAS - {titulo.upper()}"), ln=True, align='C')
            pdf.set_font("Arial", '', 10)
            pdf.set_x(35)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Emiss√£o: {datetime.now().strftime('%d/%m/%Y')}"), ln=True, align='C')
            pdf.ln(10)
            cols = list(df_stats.columns)
            n_cols = len(cols)
            available_width = 190
            col_width = available_width / n_cols if n_cols > 0 else available_width
            pdf.set_font("Arial", 'B', 10)
            for col in cols:
                pdf.cell(col_width, 8, PDFModule.to_latin1(str(col)), border=1, align='C')
            pdf.ln()
            pdf.set_font("Arial", '', 9)
            for _, row in df_stats.iterrows():
                if pdf.get_y() > 265:
                    pdf.add_page()
                    pdf.ln(10)
                    pdf.set_font("Arial", 'B', 10)
                    for col in cols:
                        pdf.cell(col_width, 8, PDFModule.to_latin1(str(col)), border=1, align='C')
                    pdf.ln()
                    pdf.set_font("Arial", '', 9)
                for col in cols:
                    txt = PDFModule.to_latin1(str(row[col]))
                    pdf.cell(col_width, 6, txt, border=1)
                pdf.ln()
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF de estat√≠sticas: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio de estat√≠sticas"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

class UtilsModule:
    """Encapsula fun√ß√µes utilit√°rias."""
    @staticmethod
    def sanitizar_dataframe(df):
        colunas_lista = [
            'iconografias',
            'autores_colaboradores',
            'tradutores',
            'autores_citados',
            'palavras_chave',
            'nome_pessoal_como_assunto',
            'notas_pesquisa'
        ]
        if df.empty:
            return df
        for col in colunas_lista:
            if col in df.columns:
                df[col] = df[col].apply(lambda x: x if isinstance(x, list) else [])
        return df

    @staticmethod
    def calculate_stats_with_percentage(series):
        if series.empty:
            return pd.DataFrame(columns=['Termo', 'Qtd', '%'])
        counts = series.value_counts().reset_index()
        counts.columns = ['Termo', 'Qtd']
        total = counts['Qtd'].sum()
        counts['%'] = (counts['Qtd'] / total * 100).map('{:.2f}%'.format)
        return counts

    @staticmethod
    def get_registro_by_id(dados, reg_id):
        for r in dados:
            if r.get('_id') == reg_id:
                return r
        return None

    @staticmethod
    def is_bilingue(registro):
        """
        Identifica publica√ß√£o bil√≠ngue procurando 'bil√≠ngue/bilingue'
        tanto em nota de edi√ß√£o quanto no resumo (colchetes, aspas etc.).
        """
        nota = str(registro.get('nota_edicao', '') or '')
        resu = str(registro.get('resumo', '') or '')
        texto = (nota + " " + resu).lower()
        return ('bil√≠ngue' in texto) or ('bilingue' in texto)

    @staticmethod
    def format_list_field(reg, field):
        raw = reg.get(field)
        itens = []
        if isinstance(raw, list):
            for v in raw:
                if v is None:
                    continue
                if isinstance(v, float) and pd.isna(v):
                    continue
                s = str(v).strip()
                if s:
                    itens.append(s)
        elif isinstance(raw, str):
            s = raw.strip()
            if s:
                itens.append(s)
        elif raw is not None and not (isinstance(raw, float) and pd.isna(raw)):
            s = str(raw).strip()
            if s:
                itens.append(s)
        if field in {'autores_colaboradores', 'autores_citados', 'tradutores', 'nome_pessoal_como_assunto'}:
            itens = [DataModule.format_nome_abnt(i) for i in itens]
        return ', '.join(itens) if itens else '‚Äî'

    @staticmethod
    def construir_tipo_textual(tipo_principal: str, subtipo: str | None) -> str:
        """Monta o r√≥tulo completo, ignorando o placeholder 'Sem especifica√ß√£o'."""
        if subtipo and subtipo.strip() and subtipo != "Sem especifica√ß√£o":
            return f"{tipo_principal} - {subtipo.strip()}"
        return tipo_principal

    @staticmethod
    def parse_tipo_textual(valor: str) -> tuple[str, str | None]:
        """Separa o r√≥tulo salvo em principal e subtipo para preencher o formul√°rio.
        Aceita tanto ' - ' quanto ' | ' como separadores."""
        if not valor:
            return "", None
        # Aceitar tanto " - " quanto " | " como separadores
        if " | " in valor:
            partes = valor.split(" | ", 1)
            return partes[0].strip(), partes[1].strip()
        if " - " in valor:
            partes = valor.split(" - ", 1)
            return partes[0].strip(), partes[1].strip()
        return valor.strip(), "Sem especifica√ß√£o"

    @staticmethod
    def converter_excel(df):
        try:
            o = BytesIO()
            with pd.ExcelWriter(o, engine='xlsxwriter') as w:
                df_export = df.copy()
                for col in df_export.columns:
                    df_export[col] = df_export[col].apply(
                        lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, (list, dict)) else x
                    )
                df_export.to_excel(w, index=False, sheet_name='Dados')
            return o.getvalue()
        except Exception as e:
            st.error(f"Erro ao gerar Excel: {str(e)}")
            o = BytesIO()
            pd.DataFrame({'Erro': ['Erro ao gerar planilha']}).to_excel(o, index=False)
            return o.getvalue()

# ==========================================
# 3. COMPONENTES REUTILIZ√ÅVEIS
# ==========================================

class CatalogacaoForm:
    def __init__(self, dados, df):
        self.dados = dados
        self.df = df

    def render(self, rec=None, mode="NOVO REGISTRO"):
        # Inicializa session_state
        if 'loaded_json' not in st.session_state:
            st.session_state.loaded_json = None
        if 'clear_json_input' not in st.session_state:
            st.session_state.clear_json_input = False
        if 'form_clear_counter' not in st.session_state:
            st.session_state.form_clear_counter = 0

        # Carregamento R√°pido via JSON/Excel - APENAS em NOVO REGISTRO
        if mode == "NOVO REGISTRO":
            with st.expander("üì• CARREGAMENTO R√ÅPIDO (JSON ou EXCEL)", expanded=False):
                tipo_import = st.radio("Formato:", ["JSON", "EXCEL"], horizontal=True, key="tipo_import")

                if tipo_import == "JSON":
                    c_txt, c_btn = st.columns([4, 1])
                    with c_txt:
                        json_value = "" if st.session_state.clear_json_input else None
                        j_txt = st.text_area("Cole o JSON:", height=100, key="json_input", value=json_value if json_value is not None else "")
                    with c_btn:
                        st.write(""); st.write("")
                        b_load = st.button("PROCESSAR JSON")

                    if st.session_state.clear_json_input:
                        st.session_state.clear_json_input = False

                    # L√≥gica de Carregamento JSON
                    if b_load and j_txt:
                        try:
                            l = json.loads(j_txt)
                            loaded_rec = l[0] if isinstance(l, list) else l
                            st.session_state.loaded_json = loaded_rec
                            st.success("‚úÖ JSON carregado!")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Erro ao processar JSON: {str(e)}")
                            st.session_state.loaded_json = None
                else:
                    uploaded_file = st.file_uploader("Escolha um arquivo Excel", type=['xlsx', 'xls'])
                    if uploaded_file and st.button("PROCESSAR EXCEL"):
                        try:
                            df_excel = pd.read_excel(uploaded_file)
                            if len(df_excel) > 0:
                                loaded_rec = df_excel.iloc[0].to_dict()
                                st.session_state.loaded_json = loaded_rec
                                st.success(f"‚úÖ Excel carregado! {len(df_excel)} registro(s) encontrado(s). Carregando o primeiro.")
                                st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Erro ao processar Excel: {str(e)}")

        # Prioridade: loaded_json > rec passado como par√¢metro
        if st.session_state.loaded_json is not None:
            rec = st.session_state.loaded_json
            col_info, col_btn = st.columns([3, 1])
            with col_info:
                st.info("üìã Dados carregados via importa√ß√£o.")
            with col_btn:
                if st.button("üóëÔ∏è Limpar dados", use_container_width=True):
                    st.session_state.loaded_json = None
                    st.session_state.selected_record = None
                    st.session_state.clear_json_input = True
                    st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
                    # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                    st.session_state.form_clear_counter += 1
                    # Limpar todos os campos do formul√°rio E campos de busca
                    for key in list(st.session_state.keys()):
                        if key.startswith('form_') or key.startswith('busca_') or key.startswith('confirm_delete_') or key.startswith('icon_'):
                            del st.session_state[key]
                    st.rerun()
        elif rec and mode == "EDITAR EXISTENTE":
            # Se rec foi passado como par√¢metro (da busca), mostrar info
            col_info, col_btn = st.columns([3, 1])
            with col_info:
                st.info(f"üìã Editando: **{rec.get('titulo_artigo', '[sem t√≠tulo]')}**")
            with col_btn:
                if st.button("üßπ Limpar formul√°rio", use_container_width=True):
                    st.session_state.selected_record = None
                    st.session_state.loaded_json = None
                    st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
                    # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                    st.session_state.form_clear_counter += 1
                    # Limpar todos os campos do formul√°rio e campos de busca
                    for key in list(st.session_state.keys()):
                        if key.startswith('form_') or key.startswith('busca_') or key.startswith('icon_'):
                            del st.session_state[key]
                    st.rerun()

        # L√≥gica de Editar Existente (chamada externamente)
        # --- SELE√á√ÉO DE TIPO TEXTUAL (FORA DO FORMUL√ÅRIO) ---
        st.markdown("---")
        st.markdown("#### TIPO TEXTUAL (Vocabul√°rio Controlado)")

        tipo_atual = (rec or {}).get('vocabulario_controlado', '')
        tipo_principal_atual, subtipo_atual = UtilsModule.parse_tipo_textual(tipo_atual) if tipo_atual else (None, None)

        col_tipo1, col_tipo2 = st.columns(2)
        with col_tipo1:
            tipos_principais = sorted(DataModule.G√äNEROS_TEXTUAIS.keys())

            # Encontrar o √≠ndice correto
            idx_tipo = 0  # default
            if tipo_principal_atual and tipo_principal_atual in tipos_principais:
                idx_tipo = tipos_principais.index(tipo_principal_atual)

            # Gerar key √∫nico baseado no valor atual para for√ßar atualiza√ß√£o do selectbox
            key_tipo = f"sel_tipo_principal_{tipo_atual}_{rec.get('_id', 'novo') if rec else 'novo'}"
            tipo_principal_selecionado = st.selectbox(
                "TIPO PRINCIPAL*",
                tipos_principais,
                index=idx_tipo,
                key=key_tipo,
                help="Selecione o tipo textual principal."
            )
        with col_tipo2:
            subtipos_disponiveis = DataModule.G√äNEROS_TEXTUAIS.get(tipo_principal_selecionado, ["Sem especifica√ß√£o"])
            idx_subtipo = subtipos_disponiveis.index(subtipo_atual) if subtipo_atual in subtipos_disponiveis else 0
            # Gerar key √∫nico baseado no valor atual para for√ßar atualiza√ß√£o
            key_subtipo = f"sel_subtipo_{tipo_atual}_{rec.get('_id', 'novo') if rec else 'novo'}"
            subtipo_selecionado = st.selectbox(
                "SUBTIPO (Campo disciplinar)",
                subtipos_disponiveis,
                index=idx_subtipo,
                key=key_subtipo,
                help="Especifique o campo disciplinar."
            )

        tipo_textual_final = UtilsModule.construir_tipo_textual(tipo_principal_selecionado, subtipo_selecionado)
        st.info(f"Ser√° registrado como: **{tipo_textual_final}**")

        # -----------------------------------------------------
        st.markdown("---")
        # --- IN√çCIO DO FORMUL√ÅRIO ---
        # ‚ö†Ô∏è CORRE√á√ÉO DO BUG DE PERSIST√äNCIA:
        # S√≥ atualizar session_state quando o registro REALMENTE mudar
        # Isso evita sobrescrever as edi√ß√µes do usu√°rio a cada rerun

        # Identificar o registro atual
        rec_id_atual = rec.get('_id', 'novo') if rec else 'novo'

        # Verificar se √© um registro diferente do anterior
        if 'current_editing_record_id' not in st.session_state:
            st.session_state.current_editing_record_id = None

        registro_mudou = (st.session_state.current_editing_record_id != rec_id_atual)

        # S√ì atualizar os campos quando:
        # 1. O registro mudou (carregou um diferente) OU
        # 2. Foi solicitado force_form_update (ao clicar em "Carregar Registro")
        should_update_form = registro_mudou or st.session_state.get('force_form_update', False)

        if should_update_form:
            # Atualizar o ID do registro atual
            st.session_state.current_editing_record_id = rec_id_atual

            # Resetar flag de force_form_update
            if 'force_form_update' in st.session_state:
                st.session_state.force_form_update = False

            # Fun√ß√£o auxiliar para converter listas em texto
            def lt(x): return "\n".join(x) if isinstance(x, list) else str(x)

            if rec:
                # Carregar dados do registro
                st.session_state.form_n_rev = str(rec.get('n', ''))
                st.session_state.form_registro = str(rec.get('registro', ''))
                st.session_state.form_paginas = str(rec.get('paginas', ''))
                st.session_state.form_ordem = int(rec.get('ordem_exibicao', 0))
                st.session_state.form_i1 = rec.get('idioma_01', 'POR')
                st.session_state.form_i2 = rec.get('idioma_02', '')
                st.session_state.form_titulo = rec.get('titulo_artigo', '')
                st.session_state.form_sub = rec.get('subtitulo_artigo', '')
                st.session_state.form_nota = rec.get('nota_edicao', '')
                st.session_state.form_autores = lt(rec.get('autores_colaboradores', []))
                st.session_state.form_entidade = lt(rec.get('entidade_coletiva', []))
                st.session_state.form_tradutores = lt(rec.get('tradutores', []))
                st.session_state.form_citados = lt(rec.get('autores_citados', []))
                st.session_state.form_kw = lt(rec.get('palavras_chave', []))
                st.session_state.form_pessoal = lt(rec.get('nome_pessoal_como_assunto', []))
                st.session_state.form_resumo = rec.get('resumo', '')
            else:
                # Formul√°rio vazio (novo registro sem dados)
                st.session_state.form_n_rev = ''
                st.session_state.form_registro = ''
                st.session_state.form_paginas = ''
                st.session_state.form_ordem = 0
                st.session_state.form_i1 = 'POR'
                st.session_state.form_i2 = ''
                st.session_state.form_titulo = ''
                st.session_state.form_sub = ''
                st.session_state.form_nota = ''
                st.session_state.form_autores = ''
                st.session_state.form_entidade = ''
                st.session_state.form_tradutores = ''
                st.session_state.form_citados = ''
                st.session_state.form_kw = ''
                st.session_state.form_pessoal = ''
                st.session_state.form_resumo = ''

        # Usar chave din√¢mica para for√ßar recria√ß√£o do formul√°rio quando registro mudar OU quando limpar
        rec_id = rec.get('_id', 'novo') if rec else 'novo'
        form_key = f"form_{rec_id}_v{st.session_state.form_clear_counter}"
        with st.form(form_key):
            c_form1, c_form2, c_form3, c_form4 = st.columns(4)
            n_rev = c_form1.text_input("N¬∫ REVISTA*", key="form_n_rev")
            reg_txt = c_form2.text_input("REGISTRO*", key="form_registro")
            pag = c_form3.text_input("P√ÅGINAS", key="form_paginas")
            # Verifica√ß√£o de Duplicidade
            if n_rev and reg_txt:
                duplicado = False
                for r in self.dados:
                    if mode == "EDITAR EXISTENTE" and (rec or {}).get('_id') == r.get('_id'): continue
                    if str(r.get('n')) == str(n_rev) and str(r.get('registro')) == str(reg_txt):
                        duplicado = True
                        break
                if duplicado:
                    st.warning(f"‚ö†Ô∏è ATEN√á√ÉO: J√° existe o registro '{reg_txt}' na Revista {n_rev}!", icon="üö®")
            ordem = c_form4.number_input("ORDEM", key="form_ordem")

            c5, c6, c7 = st.columns(3)
            langs = ["POR", "ING", "ESP", "FRA", "ITA", "ALE", "RUS", "CAT", "GRE", "JAP"]
            # Idiomas usam session_state para valores padr√£o
            i1 = c5.selectbox("IDIOMA 1", langs, key="form_i1")
            i2 = c6.selectbox("IDIOMA 2", [""] + langs, key="form_i2")
            st.markdown("---")

            regra_help = "Se sem t√≠tulo: insira o primeiro verso entre aspas..."
            tit = st.text_input("T√çTULO*", help=regra_help, key="form_titulo")
            sub = st.text_input("SUBT√çTULO", key="form_sub")
            nota_ed = st.text_input("NOTA DE EDI√á√ÉO", key="form_nota")

            st.markdown("---")
            st.markdown("#### RESPONSABILIDADE AUTORAL")
            c8, c9, c10 = st.columns(3)
            aut = c8.text_area("COLABORADORES", key="form_autores")
            entidade = c9.text_area("ENTIDADE COLETIVA", key="form_entidade", help="Responsabilidade institucional quando n√£o h√° autor individual")
            trad = c10.text_area("TRADUTORES", key="form_tradutores")

            st.markdown("---")
            st.markdown("#### ASSUNTOS")
            c10, c11 = st.columns(2)
            cit = c10.text_area("AUTORES CITADOS", key="form_citados")
            kw = c11.text_area("PALAVRAS-CHAVE", key="form_kw")
            nome_pessoal = st.text_area("NOME PESSOAL COMO ASSUNTO", key="form_pessoal")

            st.markdown("---")
            st.markdown("#### RESUMO ANAL√çTICO")
            tipo_base = tipo_principal_selecionado.upper().replace(" ", "")
            requer_resumo = tipo_base not in TIPOS_SEM_RESUMO
            label_resumo = "RESUMO" + (" (OBRIGAT√ìRIO)" if requer_resumo else " (OPCIONAL)")
            resumo = st.text_area(label_resumo, height=200, key="form_resumo")

            st.markdown("---")
            st.markdown("#### ICONOGRAFIA")

            # Obter iconografias existentes do registro
            icon_data = (rec or {}).get('iconografias', [])

            # Controle de quantidade (number_input funciona dentro de forms!)
            num_icons_inicial = len(icon_data) if icon_data else 0
            num_icons = st.number_input(
                "Quantidade de iconografias",
                min_value=0,
                max_value=20,
                value=num_icons_inicial,
                step=1,
                key=f"num_icons_{rec_id}_{st.session_state.form_clear_counter}",
                help="Ajuste a quantidade de iconografias que deseja cadastrar"
            )

            # Renderizar campos para cada iconografia
            iconografias_list = []
            for idx in range(int(num_icons)):
                st.markdown(f"**Iconografia {idx+1}**")
                col_tipo, col_desc = st.columns([2, 5])

                # Obter valores existentes ou usar defaults
                tipo_existente = icon_data[idx].get('tipo', DataModule.LISTA_ICONOGRAFIA[0]) if idx < len(icon_data) else DataModule.LISTA_ICONOGRAFIA[0]
                desc_existente = icon_data[idx].get('descricao', '') if idx < len(icon_data) else ''

                with col_tipo:
                    tipo_idx = 0
                    if tipo_existente in DataModule.LISTA_ICONOGRAFIA:
                        tipo_idx = DataModule.LISTA_ICONOGRAFIA.index(tipo_existente)

                    tipo = st.selectbox(
                        f"Tipo",
                        DataModule.LISTA_ICONOGRAFIA,
                        index=tipo_idx,
                        key=f"icon_tipo_{idx}_{rec_id}_{st.session_state.form_clear_counter}",
                        label_visibility="collapsed"
                    )

                with col_desc:
                    descricao = st.text_input(
                        f"Descri√ß√£o",
                        value=desc_existente,
                        key=f"icon_desc_{idx}_{rec_id}_{st.session_state.form_clear_counter}",
                        placeholder="Digite a descri√ß√£o da iconografia...",
                        label_visibility="collapsed"
                    )

                # Adicionar √† lista se tiver descri√ß√£o
                if tipo and descricao and descricao.strip():
                    iconografias_list.append({"tipo": tipo, "descricao": descricao.strip()})

            # Informa√ß√£o visual
            if num_icons == 0:
                st.info("‚ÑπÔ∏è Nenhuma iconografia. Aumente o n√∫mero acima para adicionar.")
            else:
                st.caption(f"üí° Dica: Aumente o n√∫mero acima para adicionar mais iconografias, diminua para remover.")

            st.markdown("---")
            # BOT√ÉO SALVAR (DENTRO DO FORM)
            submit_btn = st.form_submit_button("üíæ SALVAR", type="primary")

        # L√ìGICA DE SALVAMENTO (FORA DO FORM, MAS GATILHADA PELO BOT√ÉO)
        if submit_btn:
            if not n_rev or not reg_txt:
                st.error("‚ùå Campos obrigat√≥rios: N¬∫ REVISTA e REGISTRO!")
                st.stop()
            if requer_resumo and not resumo.strip():
                st.error(f"‚ùå O tipo textual '{tipo_textual_final}' exige RESUMO ANAL√çTICO!")
                st.stop()

            # Usar a lista de iconografias j√° filtrada que foi constru√≠da no formul√°rio
            icon_list = iconografias_list

            new = {
                "n": n_rev,
                "registro": reg_txt,
                "ordem_exibicao": ordem,
                "idioma_01": i1,
                "idioma_02": i2 if i2 else "",
                "vocabulario_controlado": tipo_textual_final,
                "titulo_artigo": tit,
                "subtitulo_artigo": sub,
                "paginas": pag,
                "resumo": resumo,
                "nota_edicao": nota_ed,
                "autores_colaboradores": DataModule.normalizar_lista_autores(aut),
                "entidade_coletiva": DataModule.normalizar_lista_autores(entidade),
                "tradutores": DataModule.normalizar_lista_autores(trad),
                "autores_citados": DataModule.normalizar_lista_autores(cit),
                "palavras_chave": DataModule.normalizar_texto(kw.replace(',', '\n').split('\n')),
                "nome_pessoal_como_assunto": DataModule.normalizar_lista_autores(nome_pessoal),
                "iconografias": icon_list,
                "_timestamp": datetime.now().isoformat()
            }
            # Preservar notas de pesquisa do registro original, se existir
            if 'notas_pesquisa' in (rec or {}):
                new['notas_pesquisa'] = (rec or {}).get('notas_pesquisa', [])

            # L√ìGICA APRIMORADA: Buscar registro existente por Revista + Registro
            # Isso evita duplicatas mesmo quando n√£o h√° _id no rec
            registro_existente = None
            indice_existente = None

            for i, d in enumerate(self.dados):
                if str(d.get('n')) == str(n_rev) and str(d.get('registro')) == str(reg_txt):
                    # Encontrou registro com mesma Revista + Registro
                    registro_existente = d
                    indice_existente = i
                    break

            if mode == "EDITAR EXISTENTE":
                # Modo EDITAR: Verificar se h√° registro para substituir
                if registro_existente:
                    # Substituir o registro existente, preservando o _id original
                    new['_id'] = registro_existente.get('_id', str(int(datetime.now().timestamp() * 1000)))
                    # Preservar notas de pesquisa do registro original
                    if 'notas_pesquisa' in registro_existente:
                        new['notas_pesquisa'] = registro_existente.get('notas_pesquisa', [])
                    self.dados[indice_existente] = new
                    st.info(f"‚ÑπÔ∏è Registro existente (ID: {new['_id']}) foi ATUALIZADO.")
                elif '_id' in (rec or {}):
                    # Tem _id mas n√£o encontrou por revista+registro (usu√°rio pode ter mudado esses campos)
                    # Buscar pelo _id original
                    new['_id'] = (rec or {})['_id']
                    for i, d in enumerate(self.dados):
                        if d.get('_id') == new['_id']:
                            self.dados[i] = new
                            st.info(f"‚ÑπÔ∏è Registro (ID: {new['_id']}) foi ATUALIZADO.")
                            break
                else:
                    # Est√° em modo EDITAR mas n√£o encontrou registro existente - criar novo
                    new['_id'] = str(int(datetime.now().timestamp() * 1000))
                    new.setdefault('notas_pesquisa', [])
                    self.dados.append(new)
                    st.warning("‚ö†Ô∏è N√£o foi encontrado registro existente para editar. Criado NOVO registro.")
            else:
                # Modo NOVO REGISTRO
                if registro_existente:
                    # ATEN√á√ÉO: J√° existe um registro com essa Revista + Registro!
                    st.error(f"‚ùå ERRO: J√° existe um registro com Revista {n_rev} e Registro {reg_txt} (ID: {registro_existente.get('_id')})")
                    st.error("üí° Use o modo 'EDITAR EXISTENTE' para modificar este registro ou altere os campos Revista/Registro.")
                    st.stop()
                else:
                    # Criar novo registro normalmente
                    new['_id'] = str(int(datetime.now().timestamp() * 1000))
                    new.setdefault('notas_pesquisa', [])
                    self.dados.append(new)

            if PersistenceModule.save_data(self.dados):
                st.success("‚úÖ Registro salvo com sucesso!")
                st.balloons()

                # Limpar automaticamente o formul√°rio ap√≥s salvar
                st.session_state.loaded_json = None
                st.session_state.selected_record = None
                st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
                # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                st.session_state.form_clear_counter += 1

                # Limpar todos os campos do formul√°rio
                for key in list(st.session_state.keys()):
                    if key.startswith('form_') or key.startswith('busca_') or key.startswith('confirm_delete_') or key.startswith('icon_'):
                        del st.session_state[key]

                # Recarregar a p√°gina para mostrar formul√°rio limpo
                st.rerun()


class FichasNotasView:
    def __init__(self, df, dados):
        self.df = df
        self.dados = dados

    def render(self):
        st.title("üìá FICHAS & NOTAS NELIC")
        if self.df.empty:
            st.warning("Base de dados vazia. Cadastre registros na aba CATALOGA√á√ÉO.")
            return

        st.markdown("### üîç Navega√ß√£o por Revista")
        revistas_disponiveis = sorted(self.df['n'].astype(str).unique())
        revista_selecionada = st.selectbox(
            "Selecione a revista:",
            ["Todas as revistas"] + revistas_disponiveis,
            help="Filtre os registros por n√∫mero da revista para facilitar a navega√ß√£o"
        )

        if revista_selecionada == "Todas as revistas":
            df_filtrado = self.df
        else:
            df_filtrado = self.df[self.df['n'].astype(str) == revista_selecionada]

        st.markdown("---")
        opcoes = [
            f"{r.get('n','?')} | Reg: {r.get('registro','?')} | {r.get('titulo_artigo','[sem t√≠tulo]')}"
            for _, r in df_filtrado.iterrows()
        ]
        if not opcoes:
            st.warning(f"‚ö†Ô∏è Nenhum registro encontrado para a revista {revista_selecionada}")
            return

        escolha = st.selectbox("Selecione o registro espec√≠fico:", opcoes)
        idx = opcoes.index(escolha)
        reg_sel = df_filtrado.iloc[idx].to_dict()
        reg_id = reg_sel.get('_id')

        c_esq, c_dir = st.columns([2, 1])
        with c_esq:
            st.markdown(
                f"""
                <div class="nelic-card">
                    <div class="nelic-card-header">FICHA NELIC ‚Äì REGISTRO {reg_sel.get('registro','')}</div>
                    <div class="nelic-card-subtitle">
                        Revista {reg_sel.get('n','?')} ¬∑ Tipo {reg_sel.get('vocabulario_controlado','')} ¬∑ pp. {reg_sel.get('paginas','')}
                    </div>
                    <div>
                        <strong>T√≠tulo:</strong> {reg_sel.get('titulo_artigo','[sem t√≠tulo]')}<br>
                        <strong>Subt√≠tulo:</strong> {reg_sel.get('subtitulo_artigo','')}
                    </div>
                    <div style="margin-top:0.4rem;">
                        <span class="nelic-tag">Idioma 1: {reg_sel.get('idioma_01','')}</span>
                        <span class="nelic-tag nelic-tag-muted">Idioma 2: {reg_sel.get('idioma_02','')}</span>
                    </div>
                </div>
                """,
                unsafe_allow_html=True
            )

            st.markdown("#### Conte√∫do e Assuntos")
            with st.expander("üìå Conte√∫do", expanded=True):
                st.markdown(f"**Nota de edi√ß√£o:** {reg_sel.get('nota_edicao','‚Äî')}")
                st.markdown("**Resumo:**")
                st.write(reg_sel.get('resumo', '‚Äî'))

            with st.expander("üéØ Assuntos e Autores", expanded=False):
                st.markdown(f"**Palavras-chave:** {UtilsModule.format_list_field(reg_sel, 'palavras_chave')}")
                st.markdown(f"**Autores citados:** {UtilsModule.format_list_field(reg_sel, 'autores_citados')}")
                st.markdown(f"**Nomes pessoais como assunto:** {UtilsModule.format_list_field(reg_sel, 'nome_pessoal_como_assunto')}")

            with st.expander("üñºÔ∏è Iconografia", expanded=False):
                icons = reg_sel.get('iconografias', [])
                if icons:
                    for ic in icons:
                        st.markdown(f"- **{ic.get('tipo','')}** ¬∑ {ic.get('descricao','')}")
                else:
                    st.markdown("Nenhuma iconografia registrada.")

        with c_dir:
            st.markdown("#### Exportar Ficha")
            pdf_ficha = PDFModule.gerar_pdf_ficha(reg_sel)
            st.download_button(
                "üìÑ BAIXAR FICHA EM PDF",
                pdf_ficha,
                f"ficha_sibila_{reg_sel.get('registro','')}.pdf",
                "application/pdf",
                width='stretch'
            )

            st.markdown("---")
            st.markdown("#### Notas de Pesquisa")
            # Carregamos o di√°rio aqui para garantir atualiza√ß√£o
            diario = PersistenceModule.load_diario()
            notas = reg_sel.get('notas_pesquisa', []) or []
            with st.form("form_nota_registro"):
                titulo_nota = st.text_input("T√≠tulo da nota")
                texto_nota = st.text_area("Texto da nota", height=120)
                tags_nota = st.text_input("Tags (separadas por v√≠rgula)")
                if st.form_submit_button("‚ûï Adicionar nota a este registro"):
                    if texto_nota.strip():
                        nova_nota = {
                            "id": str(int(datetime.now().timestamp() * 1000)),
                            "data": datetime.now().isoformat(),
                            "titulo": titulo_nota.strip() or "[sem t√≠tulo]",
                            "texto": texto_nota.strip(),
                            "tags": [t.strip() for t in tags_nota.split(',') if t.strip()],
                            "registro_id": reg_id
                        }
                        # Precisamos buscar o registro na lista original 'dados' para salvar
                        reg_real = UtilsModule.get_registro_by_id(self.dados, reg_id)
                        if reg_real is not None:
                            reg_real.setdefault('notas_pesquisa', [])
                            reg_real['notas_pesquisa'].append(nova_nota)
                            if PersistenceModule.save_data(self.dados):
                                st.success("Nota adicionada ao registro.")
                                st.rerun() # Recarrega para mostrar a nota nova
                        else:
                            st.error("Erro ao vincular nota.")
                    else:
                        st.warning("O texto da nota n√£o pode estar vazio.")

            if notas:
                st.markdown("##### Notas j√° cadastradas")
                for n in sorted(notas, key=lambda x: x.get('data', ''), reverse=True):
                    dt = n.get('data', '')[:16].replace("T", " ")
                    st.markdown(
                        f"""
                        <div class="nelic-card">
                            <div class="nelic-card-header">{n.get('titulo','[sem t√≠tulo]')}</div>
                            <div class="nelic-card-subtitle">Data: {dt}</div>
                            <div class="nelic-muted">{n.get('texto','')}</div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    tags = n.get('tags', [])
                    if tags:
                        st.markdown(" ".join([f"<span class='nelic-tag nelic-tag-muted'>{t}</span>" for t in tags]), unsafe_allow_html=True)
            else:
                st.info("Nenhuma nota vinculada.")

# ==========================================
# 4. FUN√á√ïES DE RELAT√ìRIOS
# ==========================================

def relatorio_mapa_colaboracao(df):
    st.markdown("#### Mapa de colabora√ß√£o por n√∫mero da revista")
    def unique_colab_por_revista(df_local):
        def uniq(lst):
            if not isinstance(lst, list):
                return set()
            return set([str(x).strip() for x in lst if str(x).strip()])
        rows = []
        for rev, sub in df_local.groupby('n'):
            s = set()
            for line in sub['autores_colaboradores']:
                s |= uniq(line if isinstance(line, list) else [line])
            rows.append({"Revista": str(rev), "Colaboradores distintos": len(s)})
        return pd.DataFrame(rows)

    df_rel = unique_colab_por_revista(df)
    st.dataframe(df_rel, width='stretch')
    fig = px.bar(df_rel, x="Revista", y="Colaboradores distintos", text="Colaboradores distintos")
    fig.update_layout(height=380, title="Colaboradores distintos por n√∫mero da revista")
    st.plotly_chart(fig, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(df_rel)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_mapa_colaboracao_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = df_rel.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_mapa_colaboracao_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_analitico(df, len(df), "Mapa de colabora√ß√£o por revista")
    col3.download_button(
        "üìÑ PDF (lista completa)",
        pdf_rel,
        f"rel_mapa_colaboracao_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_bilinguismo(df):
    st.markdown("#### √çndice de publica√ß√µes bil√≠ngues por n√∫mero da revista")
    df_local = df.copy()
    df_local['bilingue'] = df_local.apply(UtilsModule.is_bilingue, axis=1)
    resumo = (
        df_local.groupby('n')['bilingue']
        .agg(total='count', bil='sum')
        .reset_index()
    )
    resumo['% bil√≠ngue'] = resumo.apply(
        lambda r: (r['bil'] / r['total'] * 100) if r['total'] > 0 else 0, axis=1
    )
    resumo['n'] = resumo['n'].astype(str)
    st.dataframe(resumo, width='stretch')
    fig = px.bar(
        resumo,
        x='n',
        y='% bil√≠ngue',
        text=resumo['% bil√≠ngue'].map(lambda x: f"{x:.1f}%")
    )
    fig.update_layout(
        height=380,
        title="% de registros bil√≠ngues (nota ou resumo) por revista",
        xaxis_title="Revista",
        yaxis_title="% bil√≠ngue"
    )
    st.plotly_chart(fig, width='stretch')
    st.markdown("##### Exportar")
    col1, col2 = st.columns(2)
    excel_rel = UtilsModule.converter_excel(resumo)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_bilinguismo_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = resumo.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_bilinguismo_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )

def relatorio_iconografia(df):
    st.markdown("#### Iconografia por n√∫mero da revista")
    df_local = df.copy()
    df_local['tem_iconografia'] = df_local['iconografias'].apply(
        lambda x: isinstance(x, list) and len(x) > 0
    )
    resumo = (
        df_local.groupby('n')['tem_iconografia']
        .agg(total='count', com_icon='sum')
        .reset_index()
    )
    resumo['% com iconografia'] = resumo.apply(
        lambda r: (r['com_icon'] / r['total'] * 100) if r['total'] > 0 else 0, axis=1
    )
    resumo['n'] = resumo['n'].astype(str)
    st.dataframe(resumo, width='stretch')
    fig = px.bar(
        resumo,
        x='n',
        y='% com iconografia',
        text=resumo['% com iconografia'].map(lambda x: f"{x:.1f}%")
    )
    fig.update_layout(
        height=380,
        title="% de registros com iconografia por revista",
        xaxis_title="Revista",
        yaxis_title="% registros com iconografia"
    )
    st.plotly_chart(fig, width='stretch')
    st.markdown("##### Exportar")
    col1, col2 = st.columns(2)
    excel_rel = UtilsModule.converter_excel(resumo)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_iconografia_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = resumo.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_iconografia_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )

def relatorio_autores_assunto_colab(df):
    st.markdown("#### Autores como assunto vs colaboradores")
    s_colab = DataModule.get_normalized_series(df, 'autores_colaboradores')
    s_ass = DataModule.get_normalized_series(df, 'nome_pessoal_como_assunto')
    df_colab = UtilsModule.calculate_stats_with_percentage(s_colab)
    df_ass = UtilsModule.calculate_stats_with_percentage(s_ass)
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**Colaboradores (top 20)**")
        st.dataframe(df_colab.head(20), width='stretch')
    with c2:
        st.markdown("**Nomes pessoais como assunto (top 20)**")
        st.dataframe(df_ass.head(20), width='stretch')
    intersect = set(df_colab['Termo']).intersection(set(df_ass['Termo']))
    st.markdown("---")
    st.markdown("##### Interse√ß√µes (quem √© autor e tema)")
    if intersect:
        st.write(", ".join(sorted(intersect)))
    else:
        st.write("Nenhum nome aparece simultaneamente como colaborador e como assunto na amostra.")

def relatorio_generos_textuais(df):
    st.markdown("#### An√°lise por tipos textuais")
    df_local = df.copy()
    df_local['tipo_base'] = df_local['vocabulario_controlado'].astype(str).apply(
        lambda x: x.split(' - ')[0]
    )
    counts = df_local['tipo_base'].value_counts().reset_index()
    counts.columns = ['Tipo textual', 'Num. Absoluto']
    total = counts['Num. Absoluto'].sum()
    counts['Percentual'] = (counts['Num. Absoluto'] / total * 100).map(lambda x: f"{x:.2f}%")
    st.dataframe(counts, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(counts)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_generos_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = counts.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_generos_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(counts, "Tipos textuais")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_generos_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_manifesto(df):
    st.markdown("#### Textos relacionados a 'Manifesto' (tipo textual, palavra-chave ou t√≠tulo)")
    df_local = df.copy()
    def verificar_manifesto(registro):
        locais = []
        tipo = str(registro.get('vocabulario_controlado', '')).lower()
        if 'manifesto' in tipo:
            locais.append('Tipo textual')
        kw = registro.get('palavras_chave', [])
        if isinstance(kw, list):
            for palavra in kw:
                if palavra and 'manifesto' in str(palavra).lower():
                    locais.append('Palavra-chave')
                    break
        titulo = str(registro.get('titulo_artigo', '')).lower()
        if 'manifesto' in titulo:
            locais.append('T√≠tulo')
        resumo = str(registro.get('resumo', '')).lower()
        if 'manifesto' in resumo:
            locais.append('Resumo')
        return locais

    df_local['locais_manifesto'] = df_local.apply(verificar_manifesto, axis=1)
    df_man = df_local[df_local['locais_manifesto'].apply(lambda x: len(x) > 0)].copy()
    st.write(f"Registros encontrados: {len(df_man)} de {len(df)} (total da base)")
    if not df_man.empty:
        df_man['onde_encontrado'] = df_man['locais_manifesto'].apply(lambda x: ', '.join(x))
        st.dataframe(
            df_man[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo', 'onde_encontrado']],
            column_config={
                'n': 'Revista',
                'registro': 'Registro',
                'vocabulario_controlado': 'Tipo',
                'titulo_artigo': 'T√≠tulo',
                'onde_encontrado': 'Encontrado em'
            },
            width='stretch'
        )
        st.markdown("##### Exportar")
        col1, col2, col3 = st.columns(3)
        df_export = df_man[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo', 'palavras_chave', 'onde_encontrado']].copy()
        excel_rel = UtilsModule.converter_excel(df_export)
        col1.download_button(
            "üìä EXCEL",
            excel_rel,
            f"rel_manifesto_{datetime.now().strftime('%Y%m%d')}.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            width='stretch'
        )
        csv_rel = df_export.to_csv(index=False, encoding='utf-8-sig')
        col2.download_button(
            "üìã CSV",
            csv_rel,
            f"rel_manifesto_{datetime.now().strftime('%Y%m%d')}.csv",
            "text/csv",
            width='stretch'
        )
        pdf_rel = PDFModule.gerar_pdf_analitico(df_man, len(df), "Manifesto ou manifesto")
        col3.download_button(
            "üìÑ PDF",
            pdf_rel,
            f"rel_manifesto_{datetime.now().strftime('%Y%m%d')}.pdf",
            "application/pdf",
            width='stretch'
        )
    else:
        st.info("Nenhum registro relacionado a 'Manifesto' foi encontrado na base.")

def relatorio_palavras_chave(df):
    st.markdown("#### Estat√≠sticas de palavras-chave (vocabul√°rio controlado)")
    s = DataModule.get_normalized_series(df, 'palavras_chave')
    counts = UtilsModule.calculate_stats_with_percentage(s)
    df_stats = counts.rename(
        columns={'Termo': 'Palavra-chave', 'Qtd': 'Num. Absoluto', '%': 'Percentual'}
    )
    st.dataframe(df_stats, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(df_stats)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_palavras_chave_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = df_stats.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_palavras_chave_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(df_stats, "Palavras-chave")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_palavras_chave_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

# ==========================================
# 5. MAIN APP LOGIC
# ==========================================

def main():
    # Logo e cabe√ßalho
    if os.path.exists(LOGO_PATH):
        st.sidebar.image(LOGO_PATH, width='stretch', output_format='PNG')
    st.sidebar.markdown("### SISTEMA NELIC")
    st.sidebar.markdown("**PROJETO SIBILA**")
    st.sidebar.markdown("---")

    # ==================================================
    # SISTEMA DE AUTENTICA√á√ÉO
    # ==================================================

    # Campo de senha na sidebar
    senha_digitada = st.sidebar.text_input(
        "üîê √Årea Restrita (Catalogadores)",
        type="password",
        placeholder="Digite a senha...",
        help="Digite a senha para acessar fun√ß√µes de cataloga√ß√£o e exporta√ß√£o"
    )

    # Verificar autentica√ß√£o
    usuario_autenticado = False
    senha_correta = None

    # Tenta pegar a senha dos secrets (Streamlit Cloud)
    try:
        if "SENHA_ADMIN" in st.secrets:
            senha_correta = st.secrets["SENHA_ADMIN"]
    except:
        pass

    # Se n√£o encontrou nos secrets, usa senha padr√£o local
    if senha_correta is None:
        senha_correta = "nelic2025"  # Senha padr√£o para uso local

    # Verifica se a senha est√° correta
    if senha_digitada == senha_correta:
        usuario_autenticado = True
        st.sidebar.success("‚úÖ Modo Editor: ATIVADO")

        # Detecta se est√° rodando no Streamlit Cloud
        is_cloud = os.environ.get('STREAMLIT_SHARING_MODE') or os.environ.get('STREAMLIT_SERVER_HEADLESS')

        if is_cloud:
            st.sidebar.warning("‚ö†Ô∏è **Aten√ß√£o**: Dados inseridos online n√£o s√£o salvos permanentemente. Para cataloga√ß√£o segura, use o sistema local no seu computador.")
    elif senha_digitada:
        st.sidebar.error("‚ùå Senha incorreta")

    st.sidebar.markdown("---")

    # ==================================================
    # MENU ADAPTATIVO (baseado na autentica√ß√£o)
    # ==================================================

    # Menu completo para usu√°rios autenticados
    if usuario_autenticado:
        opcoes_menu = [
            "NELIC",
            "CATALOGA√á√ÉO",
            "FICHAS & NOTAS",
            "EXPLORAR DADOS",
            "RELAT√ìRIOS",
            "AN√ÅLISE COMPARATIVA",
            "QUALIDADE DOS DADOS",
            "DI√ÅRIO DE PESQUISA",
            "METODOLOGIA",
            "MAIS DADOS",
            "EXPORTAR"
        ]
    else:
        # Menu p√∫blico (apenas visualiza√ß√£o)
        opcoes_menu = [
            "NELIC",
            "FICHAS & NOTAS",
            "EXPLORAR DADOS",
            "RELAT√ìRIOS",
            "AN√ÅLISE COMPARATIVA",
            "QUALIDADE DOS DADOS",
            "METODOLOGIA",
            "MAIS DADOS"
        ]

    menu = st.sidebar.radio(
        "NAVEGA√á√ÉO",
        opcoes_menu,
        label_visibility="collapsed"
    )

    st.sidebar.markdown("---")

    # Status do sistema
    if usuario_autenticado:
        st.sidebar.markdown("üîì **Modo Catalogador**")
    else:
        st.sidebar.markdown("üëÅÔ∏è **Modo Visitante**")
        st.sidebar.info("üí° Digite a senha acima para catalogar")

    dados = PersistenceModule.load_data()
    df = pd.DataFrame(dados)
    df = UtilsModule.sanitizar_dataframe(df)

    # DEBUG TEMPOR√ÅRIO - Remover depois de resolver
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîß DEBUG")
    st.sidebar.write(f"üìä Registros carregados: **{len(dados)}**")
    st.sidebar.write(f"üìê DataFrame shape: **{df.shape}**")
    if not df.empty and 'vocabulario_controlado' in df.columns:
        vocab_values = df['vocabulario_controlado'].unique()
        st.sidebar.write(f"üìù Tipos √∫nicos: **{len(vocab_values)}**")
        st.sidebar.write(f"üî§ Primeiros 5:")
        for v in list(vocab_values)[:5]:
            st.sidebar.write(f"- `{v}`")
    else:
        st.sidebar.error("‚ùå DataFrame vazio ou coluna ausente")

    # --- NELIC ---
    if menu == "NELIC":
        st.title("N√öCLEO DE ESTUDOS LITER√ÅRIOS & CULTURAIS")
        st.markdown("---")

        # Introdu√ß√£o
        st.markdown("""
        O **N√∫cleo de Estudos Liter√°rios e Culturais (NELIC)**, sediado no Departamento de L√≠ngua e
        Literatura Vern√°culas da UFSC, consolidou-se desde meados dos anos 1990 como um dos principais
        laborat√≥rios de pesquisa sobre **periodismo liter√°rio e cultural**, **forma√ß√£o de c√¢nones** e
        **arquivo no Brasil**, articulando cr√≠tica liter√°ria, teoria cultural, estudos de poesia e
        reflex√£o sobre o contempor√¢neo.

        Seu eixo estruturante √© o estudo de revistas, jornais e suplementos culturais (sobretudo da
        segunda metade do s√©culo XX) e a constru√ß√£o de um amplo arquivo e base de dados, a partir dos
        quais se interrogam a modernidade, a mem√≥ria, o anacronismo e a pr√≥pria ideia de literatura.
        """)

        st.markdown("---")

        # Origem e perfil institucional
        st.markdown("## 1. Origem e Perfil Institucional")
        st.markdown("""
        O NELIC nasce em **1996**, no CCE/UFSC, vinculado ao Departamento de L√≠ngua e Literatura
        Vern√°culas (DLLV), a partir do projeto integrado **"Po√©ticas Contempor√¢neas"**, coordenado
        por **Maria Lucia de Barros Camargo**.

        Desde sua cria√ß√£o, se define como **laborat√≥rio de forma√ß√£o de pesquisadores** (gradua√ß√£o e
        p√≥s-gradua√ß√£o) em cr√≠tica textual e cr√≠tica cultural, dedicando-se ao mapeamento da cr√≠tica
        liter√°ria e cultural brasileira a partir dos anos 1970, por meio da indexa√ß√£o e estudo de
        peri√≥dicos liter√°rios e/ou culturais em circula√ß√£o no pa√≠s.

        O trabalho √© descrito como uma leitura do peri√≥dico como **"tecido sem√¢ntico"**, cuja
        inteligibilidade depende de leitura retrospectiva e de cruzamentos de dados, bem como uma
        proposta de **"ciclo de leitura da cr√≠tica liter√°ria e cultural"**, que vai do texto cr√≠tico
        √† cr√≠tica da cr√≠tica, produzindo uma metacr√≠tica do campo.
        """)

        st.markdown("---")

        # Acervo e Base de Dados
        st.markdown("## 2. Acervo e Base de Dados")

        col_acervo1, col_acervo2 = st.columns([3, 2])

        with col_acervo1:
            st.markdown("""
            O NELIC mant√©m um amplo **acervo f√≠sico de peri√≥dicos liter√°rios e culturais** ‚Äì
            revistas, jornais e suplementos, nacionais e estrangeiros ‚Äì aberto √† consulta e pesquisa local.

            Esse acervo √© complementado pela **Base de Dados "Periodismo Liter√°rio e Cultural"**, que:

            - üìä Re√∫ne mais de **46 mil artigos indexados**
            - üì∞ Cobre cerca de **70 revistas, jornais e suplementos**
            - üîç Permite busca por palavras-chave, autores colaboradores, autores citados, resumos
            """)

        with col_acervo2:
            st.info("""
            **Peri√≥dicos Mapeados:**

            ‚Ä¢ Revista Civiliza√ß√£o Brasileira
            ‚Ä¢ Folhetim e Mais! (Folha de S.Paulo)
            ‚Ä¢ Revista do Livro
            ‚Ä¢ Cult
            ‚Ä¢ Argumento
            ‚Ä¢ Opini√£o
            ‚Ä¢ Versus
            ‚Ä¢ Revista USP
            ‚Ä¢ Almanaque
            ‚Ä¢ Revista Brasileira de Poesia
            ‚Ä¢ Jos√©
            ‚Ä¢ 34 Letras
            ‚Ä¢ Entre outros
            """)

        st.markdown("---")

        # Boletim de Pesquisa NELIC
        st.markdown("## 3. Boletim de Pesquisa NELIC")
        st.markdown("""
        O **Boletim de Pesquisa NELIC** √© o peri√≥dico cient√≠fico semestral do n√∫cleo, voltado √†
        publica√ß√£o de textos acad√™micos nas √°reas de literatura e cultura contempor√¢neas, com √™nfase
        em produ√ß√£o brasileira e latino-americana.

        **Dados Institucionais:**
        - üìÖ In√≠cio da publica√ß√£o: **1997**
        - üî¢ ISSN (online): **1984-784X**
        - üåê Indexado em: DOAJ, Latindex, OpenAlex, ROAD, CariNiana
        """)

        st.markdown("---")

        # Pesquisadores Principais
        st.markdown("## 4. Pesquisadores Principais")

        # Maria Lucia de Barros Camargo
        with st.expander("üë©‚Äçüè´ **Maria Lucia de Barros Camargo** - Fundadora e Pesquisadora S√™nior"):
            st.markdown("""
            **Trajet√≥ria:**
            - Doutora em Letras (Teoria Liter√°ria e Literatura Comparada) pela USP (1990)
            - Tese sobre a poesia de **Ana Cristina Cesar**
            - Professora titular de Teoria Liter√°ria (aposentada em 2019)
            - Criadora do NELIC e do projeto "Po√©ticas Contempor√¢neas" (1996)
            - Vice-presidente da ABRALIC (1996-1998)
            - Pr√≥-Reitora de P√≥s-Gradua√ß√£o da UFSC (2008-2012)
            - Coordenadora do PPG em Literatura (2013-2018)

            **√Åreas de Pesquisa:**
            - Periodismo cultural
            - Revistas liter√°rias
            - Poesia contempor√¢nea
            - Anos 70
            - Cr√≠tica cultural

            **Obra Principal:**
            *Atr√°s dos olhos pardos: uma leitura da poesia de Ana Cristina Cesar* (Editora Argos, 2003)
            """)

        # Carlos Eduardo Schmidt Capela
        with st.expander("üë®‚Äçüè´ **Carlos Eduardo Schmidt Capela** - Coordenador Atual"):
            st.markdown("""
            **Coordena√ß√£o:**
            - Coordenador docente do NELIC
            - Editor do Boletim de Pesquisa NELIC

            **Projetos de Pesquisa:**
            - *Heran√ßas de andan√ßas de Ahasverus pela Am√©rica Latina* (2023‚Äìatual)
            - *Ahasverus (heran√ßas : err√¢ncias : hi√¢ncias)* (2019‚Äì2023)
            - *A gesta entre n√≥s, tal gesto: disposi√ß√µes e dispositivos* (2013‚Äì2019)

            **Linha de Pesquisa:**
            Literaturas comparadas, estudos de arquivos ficcionais e figura√ß√µes da err√¢ncia e da estrangeiridade
            """)

        # Ra√∫l Antelo
        with st.expander("üë®‚Äçüè´ **Ra√∫l Antelo** - Pesquisador S√™nior"):
            st.markdown("""
            **Trajet√≥ria:**
            - Cr√≠tico e te√≥rico argentino-brasileiro (n. 1950)
            - Professor titular de Literatura Brasileira na UFSC (aposentado)
            - Pesquisador do CNPq
            - Guggenheim Fellow
            - Ex-presidente da ABRALIC
            - Doutorado *honoris causa* pela Universidad Nacional de Cuyo

            **Projeto Atual:**
            *Por uma conceitua√ß√£o da bioest√©tica: arquivo e diagramas do vivente na Am√©rica Latina* (2018‚Äìatual)

            **Obras Principais:**
            - *Literatura em revista*
            - *Jo√£o do Rio: o d√¢ndi e a especula√ß√£o*
            - *Maria com Marcel. Duchamp nos tr√≥picos*
            - *Archifilolog√≠as latinoamericanas*
            - *Cr√≠tica ac√©fala*
            - *A m√°quina afilol√≥gica*
            - *A ruinologia*
            """)

        st.markdown("---")

        # Outros pesquisadores e linhas de pesquisa
        st.markdown("## 5. Outros Pesquisadores e Linhas de Pesquisa no NELIC")

        st.markdown("""
        Atuando em projetos que articulam **cr√≠tica e cria√ß√£o na modernidade**, **po√©ticas da Am√©rica Latina**,
        **autografias e escritas de si**, **literatura**, **cinema**, **cultura**, e **contracultura**.
        """)

        # Pesquisadores por categoria
        with st.expander("üë• **Pesquisadores do NELIC** (expandir para ver lista completa)"):
            st.markdown("""
            **Docentes:**
            Carlos Eduardo Schmidt Capela, Maria Lucia de Barros Camargo, Ra√∫l Antelo, Jorge Hoffmann Wolff,
            Artur de Vargas Giorgi, Andr√© Fiorussi, Jair Tadeu da Fonseca, La√≠se Ribas Bastos,
            Luz Maria Luisa Rodriguez, Manoel Ricardo de Lima, J√∫lia Vasconcelos Studart, Renata Telles,
            Valentina da Silva Nunes, Jeferson Candido, Fernando Floriani Petry.

            **Doutorado:**
            Joaqu√≠n Emanuel Correa, Adner De Almeida Sena, Alessandra Guterres Deifeld, Allende Renck Pereira,
            Andr√© Vichara Barcellos, Arthur Katrein Mora, Carlos Speck Pereira, Dennis Lauro Rad√ºnz,
            Denise Rogenski Raizel, Diogo Araujo Da Silva, Gabriela Cristina Carvalho Gon√ßalves Dos Santos,
            Isabel Cristina Costa Louzada, Jo√£o Paulo Zarelli Rocha, Julio Aied Passos, Karoline Zampiva Corr√™a,
            Lisbeth Juliana Monroy Ortiz, Lucas De Mello Schlemper, Lucas Garcia Nunes, Luci√©le Bernardi De Souza,
            Mar√≠a Mercedes Rodriguez, Patr√≠cia Galelli, Raquel de Figueredo Eltermann, Renato Bradbury De Oliveira,
            S√©rgio Leite Barboza, Sinval Soares Paulino, William Fernandes Rabelo Da Silva, Wilson Sousa Oliveira.

            **Mestrado:**
            Carolina Maria Cardoso Pilati, Clara Padial Lucas, Clareana Moreira De Castro Eug√™nio,
            Emmanuele Amaral Santos, Matheus Reiser Muller, Renato Rodrigues, Zulmar Dustin Ribeiro Anchieta.

            **Gradua√ß√£o:**
            Nycolas Gomes Correia, Vivianne Oliveira Rodrigues.
            """)

        st.info("""
        **Nota:** O NELIC funciona como rede de pesquisadores associados e ex‚Äëorientandos.
        Nesse sentido, listamos La√≠se Ribas Bastos, Jeferson Candido, Simone Dias, Fernando Floriani Petry,
        Renata Telles, Valentina Nunes, J√∫lia Studart, Manoel Ricardo de Lima, que hoje atuam em outras
        institui√ß√µes e continuam vinculados a projetos ou publica√ß√µes do n√∫cleo.
        """)

        st.markdown("---")

        # Forma√ß√£o de Pesquisadores: Teses e Disserta√ß√µes
        st.markdown("## 6. Forma√ß√£o de Pesquisadores: Teses e Disserta√ß√µes")
        st.markdown("""
        O **NELIC** mant√©m listas extensas de **teses e disserta√ß√µes** defendidas sob sua √©gide,
        sobretudo no **Programa de P√≥s-Gradua√ß√£o em Literatura (PPGLit/UFSC)**, abrangendo temas
        centrais do n√∫cleo com forte inser√ß√£o nacional e latino‚Äëamericana.

        O n√∫cleo integra o PPGLit/UFSC, atuando na forma√ß√£o de mestres e doutores com foco em:

        - Literatura Brasileira Contempor√¢nea
        - Teoria Liter√°ria e Cr√≠tica Cultural
        - Pr√°ticas de Arquivo e Mem√≥ria Liter√°ria
        - Metodologia NELIC de cataloga√ß√£o e an√°lise de peri√≥dicos
        - Periodismo Liter√°rio e Cultural

        Al√©m disso, desde sua funda√ß√£o, o n√∫cleo incorpora estudantes de **gradua√ß√£o** (bolsistas de
        Inicia√ß√£o Cient√≠fica PIBIC/CNPq e volunt√°rios) em suas atividades de cataloga√ß√£o, digitaliza√ß√£o e
        pesquisa, promovendo a forma√ß√£o completa do pesquisador acad√™mico.
        """)

        st.markdown("---")

        # Contato
        st.markdown("## üìß Contato e Informa√ß√µes")

        col_contato1, col_contato2 = st.columns(2)

        with col_contato1:
            st.markdown("""
            **Website:**
            [nelic.ufsc.br](http://nelic.ufsc.br)

            **Boletim de Pesquisa NELIC:**
            [periodicos.ufsc.br/index.php/nelic](https://periodicos.ufsc.br/index.php/nelic)

            **Base de Dados:**
            Acesso via site do NELIC
            """)

        with col_contato2:
            st.markdown("""
            **Endere√ßo:**
            Universidade Federal de Santa Catarina
            Centro de Comunica√ß√£o e Express√£o
            Departamento de L√≠ngua e Literatura Vern√°culas
            Campus Universit√°rio - Trindade
            88040-900 - Florian√≥polis - SC
            """)

        st.markdown("---")

        st.info("""
        üí° **Mais Informa√ß√µes:** O NELIC est√° aberto √† colabora√ß√£o com pesquisadores, projetos
        interinstitucionais e consultas ao acervo f√≠sico mediante agendamento. Entre em contato
        para mais detalhes sobre o acesso √† Base de Dados, possibilidades de pesquisa conjunta ou
        orienta√ß√µes acad√™micas na √°rea de periodismo liter√°rio e cultural.
        """)

    # --- CATALOGA√á√ÉO ---
    elif menu == "CATALOGA√á√ÉO":
        st.title("EDITOR DE REGISTROS")
        form = CatalogacaoForm(dados, df)

        # Sele√ß√£o de Modo com Bot√£o de Limpeza
        col_mode1, col_mode2, col_mode3 = st.columns([2, 3, 5])
        with col_mode1:
            st.markdown("**Modo:**")
        with col_mode2:
            mode = st.radio("Selecione:", ["NOVO REGISTRO", "EDITAR EXISTENTE"], key="mode_radio", horizontal=True, label_visibility="collapsed")
        with col_mode3:
            # Bot√£o LIMPAR TUDO - s√≥ aparece e funciona em NOVO REGISTRO
            if 'mode_radio' in st.session_state and st.session_state.mode_radio == "NOVO REGISTRO":
                if st.button("üóëÔ∏è LIMPAR TUDO", help="Limpa todos os campos do formul√°rio"):
                    # Limpar TUDO no session_state relacionado ao formul√°rio
                    st.session_state.selected_record = None
                    st.session_state.loaded_json = None
                    st.session_state.clear_json_input = True
                    st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento

                    # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                    if 'form_clear_counter' not in st.session_state:
                        st.session_state.form_clear_counter = 0
                    st.session_state.form_clear_counter += 1

                    # Limpar TODOS os campos do formul√°rio e busca
                    keys_to_delete = [key for key in st.session_state.keys()
                                      if key.startswith('form_') or key.startswith('busca_') or
                                      key.startswith('confirm_delete_') or key.startswith('sel_tipo_') or
                                      key.startswith('sel_subtipo_') or key.startswith('icon_')]
                    for key in keys_to_delete:
                        del st.session_state[key]

                    st.success("‚úÖ Formul√°rio limpo!")
                    time.sleep(0.3)
                    st.rerun()

        # Inicializar session_state para registro selecionado
        if 'selected_record' not in st.session_state:
            st.session_state.selected_record = None

        # Limpar registro selecionado e formul√°rio ao mudar de modo
        if 'previous_mode' not in st.session_state:
            st.session_state.previous_mode = mode
        if st.session_state.previous_mode != mode:
            st.session_state.selected_record = None
            st.session_state.loaded_json = None
            st.session_state.previous_mode = mode
            st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
            # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
            if 'form_clear_counter' not in st.session_state:
                st.session_state.form_clear_counter = 0
            st.session_state.form_clear_counter += 1
            # Limpar TODOS os campos do formul√°rio ao mudar de modo
            for key in list(st.session_state.keys()):
                if key.startswith('form_') or key.startswith('busca_') or key.startswith('confirm_delete_') or key.startswith('icon_'):
                    del st.session_state[key]
            # IMPORTANTE: Recarregar a p√°gina para aplicar a limpeza
            st.rerun()

        rec = {}

        # No modo NOVO REGISTRO, garantir que rec seja vazio se n√£o houver registro carregado
        if mode == "NOVO REGISTRO":
            # Se selected_record for None, garantir que rec seja vazio
            if st.session_state.selected_record is None:
                rec = {}
            else:
                rec = st.session_state.selected_record

        # L√≥gica de Editar Existente
        elif mode == "EDITAR EXISTENTE" and dados:
            st.markdown("---")
            st.markdown("### üîç BUSCAR REGISTRO PARA EDITAR")

            # Campos de busca
            col1, col2, col3 = st.columns(3)
            with col1:
                # Listar todas as revistas √∫nicas
                revistas_disponiveis = sorted(list(set([str(d.get('n', '')) for d in dados if d.get('n')])))
                revista_busca = st.selectbox("N¬∫ REVISTA", [""] + revistas_disponiveis, key="busca_revista")

            with col2:
                # Filtrar registros por revista selecionada e criar lista com t√≠tulos
                if revista_busca:
                    registros_filtrados = [d for d in dados if str(d.get('n', '')) == revista_busca]
                else:
                    registros_filtrados = dados

                # Criar dicion√°rio: "registro - t√≠tulo" -> dados completos
                registros_opcoes = {}
                for d in registros_filtrados:
                    if d.get('registro'):
                        titulo = d.get('titulo_artigo', '[sem t√≠tulo]')
                        # Limitar t√≠tulo a 60 caracteres
                        titulo_curto = titulo[:60] + "..." if len(titulo) > 60 else titulo
                        chave = f"{d.get('registro')} - {titulo_curto}"
                        registros_opcoes[chave] = d

                # Ordenar por n√∫mero de registro (extrair parte num√©rica para ordena√ß√£o correta)
                def extrair_numero(chave):
                    try:
                        # Extrair "10 de 23" -> 10
                        parte_reg = chave.split(' - ')[0]  # "10 de 23"
                        numero = parte_reg.split(' ')[0]   # "10"
                        return int(numero)
                    except:
                        return 0
                opcoes_ordenadas = sorted(registros_opcoes.keys(), key=extrair_numero)

                registro_busca = st.selectbox("REGISTRO (t√≠tulo)", [""] + opcoes_ordenadas, key="busca_registro")

            with col3:
                # Bot√£o de busca
                st.write("")
                st.write("")
                buscar = st.button("üîé CARREGAR REGISTRO", type="primary", use_container_width=True)

            # Encontrar e carregar o registro
            if registro_busca and registro_busca in registros_opcoes:
                # Registro selecionado diretamente do dropdown com t√≠tulo
                novo_rec = registros_opcoes[registro_busca]
                # Verificar se √© um registro diferente do atual
                if st.session_state.selected_record is None or st.session_state.selected_record.get('_id') != novo_rec.get('_id'):
                    st.session_state.selected_record = novo_rec
                    st.session_state.force_form_update = True
                    st.rerun()
                rec = novo_rec
                st.success(f"‚úÖ Registro carregado: **{rec.get('titulo_artigo', '[sem t√≠tulo]')}**")
            elif buscar and (revista_busca or registro_busca):
                st.warning("‚ö†Ô∏è Por favor, selecione um registro da lista.")

            # Usar registro do session_state se existir
            if st.session_state.selected_record is not None:
                rec = st.session_state.selected_record

        form.render(rec=rec, mode=mode)

    # --- FICHAS & NOTAS ---
    elif menu == "FICHAS & NOTAS":
        view = FichasNotasView(df, dados)
        view.render()

    # --- EXPLORAR DADOS ---
    elif menu == "EXPLORAR DADOS":
        st.title("üîé EXPLORAR DADOS")
        if not df.empty:
            # Debug: Informa√ß√µes sobre os dados carregados
            with st.expander("üîß Debug - Informa√ß√µes do Dataset", expanded=False):
                st.write(f"**Total de registros:** {len(df)}")
                st.write(f"**Colunas dispon√≠veis:** {', '.join(df.columns.tolist())}")

                if 'vocabulario_controlado' in df.columns:
                    vocab_values = df['vocabulario_controlado'].dropna().unique()
                    st.write(f"**Valores √∫nicos em 'vocabulario_controlado':** {len(vocab_values)}")
                    st.write("**Primeiros 10 valores:**")
                    for val in list(vocab_values)[:10]:
                        st.write(f"- `{val}`")
                else:
                    st.error("‚ö†Ô∏è Coluna 'vocabulario_controlado' n√£o encontrada!")

            # Linha de filtros com bot√£o de reset
            st.markdown("### üîç FILTROS DE BUSCA")

            # EXTRA√á√ÉO DE TIPOS TEXTUAIS (fora das colunas para evitar problemas)
            tipos_set = set()
            for valor in df['vocabulario_controlado']:
                if pd.notna(valor) and str(valor).strip() and str(valor) != 'nan':
                    tipo_principal = str(valor).split(' - ')[0].strip()
                    if tipo_principal:
                        tipos_set.add(tipo_principal)
            tipos_clean = sorted(list(tipos_set))

            # Preparar listas para os multiselects (ANTES das colunas)
            revs = sorted(df['n'].astype(str).unique())

            # Debug de sucesso (fora das colunas)
            st.caption(f"üîç **Debug:**")
            st.caption(f"   ‚Ä¢ Revistas dispon√≠veis: {len(revs)} ‚Üí {list(revs)[:5]}")
            st.caption(f"   ‚Ä¢ Tipos dispon√≠veis: {len(tipos_clean)} ‚Üí {tipos_clean}")
            st.caption(f"   ‚Ä¢ Palavras-chave dispon√≠veis: {len(DataModule.LISTA_PALAVRAS_CHAVE)}")

            # TESTE: Multiselect ULTRA SIMPLES
            st.markdown("**üß™ TESTES DE DIAGN√ìSTICO:**")

            # Teste 1: Lista hardcoded
            st.write("**Teste 1: Lista hardcoded sem key**")
            teste1 = st.multiselect("Teste lista fixa", ["A", "B", "C"])
            st.write(f"Selecionado: {teste1}")

            # Teste 2: Com vari√°vel
            st.write("**Teste 2: Vari√°vel tipos_clean**")
            st.write(f"Conte√∫do de tipos_clean: {tipos_clean}")
            teste2 = st.multiselect("Teste vari√°vel", tipos_clean)
            st.write(f"Selecionado: {teste2}")

            # Teste 3: Selectbox (para comparar)
            st.write("**Teste 3: Selectbox (n√£o √© multi)**")
            teste3 = st.selectbox("Teste selectbox", tipos_clean if tipos_clean else ["Vazio"])
            st.write(f"Selecionado: {teste3}")

            # FILTROS EM COLUNAS
            col_filtros1, col_filtros2, col_filtros3, col_filtros4, col_reset = st.columns([3, 3, 3, 3, 2])

            with col_filtros1:
                termo = st.text_input("Busca Livre (T√≠tulo/Resumo):", key="explorar_termo")

            with col_filtros2:
                f_rev = st.multiselect("Revista", revs, key="explorar_revista")

            with col_filtros3:
                f_tipo = st.multiselect(
                    "Tipo Textual",
                    tipos_clean,
                    key="explorar_tipo"
                )

            with col_filtros4:
                f_kw = st.multiselect("Palavras-Chave", DataModule.LISTA_PALAVRAS_CHAVE, key="explorar_kw")

            with col_reset:
                st.write("")  # Espa√ßamento
                st.write("")  # Espa√ßamento
                if st.button("üîÑ Limpar Filtros", use_container_width=True, help="Remove todos os filtros aplicados"):
                    # Limpar todos os filtros
                    for key in ['explorar_termo', 'explorar_revista', 'explorar_tipo', 'explorar_kw']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

            # Aplicar filtros
            res = df.copy()
            criterios = []

            if f_rev:
                res = res[res['n'].astype(str).isin(f_rev)]
                criterios.append(f"Revistas: {', '.join(f_rev)}")

            if f_tipo:
                # CORRE√á√ÉO: Filtro mais robusto que lida com valores nulos e vazios
                def filtro_tipo(valor):
                    if pd.isna(valor) or not valor:
                        return False
                    tipo_principal = str(valor).split(' - ')[0].strip()
                    return tipo_principal in f_tipo

                res = res[res['vocabulario_controlado'].apply(filtro_tipo)]
                criterios.append(f"Tipos: {', '.join(f_tipo)}")

            if f_kw:
                res = res[
                    res['palavras_chave'].apply(
                        lambda x: any(
                            k.lower() in [i.lower() for i in (x if isinstance(x, list) else [])]
                            for k in f_kw
                        )
                    )
                ]
                criterios.append(f"Palavras-chave: {', '.join(f_kw)}")

            if termo:
                res = res[
                    res.astype(str).apply(lambda x: x.str.contains(termo, case=False, na=False)).any(axis=1)
                ]
                criterios.append(f"Termo livre: '{termo}'")

            # Estat√≠sticas dos resultados
            str_criterios = " | ".join(criterios) if criterios else "Toda a base de dados"
            total_base = len(df)
            qtd_res = len(res)
            pct_res = (qtd_res / total_base * 100) if total_base > 0 else 0

            st.markdown("---")
            col_info1, col_info2 = st.columns(2)
            with col_info1:
                st.metric("Registros Encontrados", f"{qtd_res} de {total_base}", f"{pct_res:.1f}% da base")
            with col_info2:
                if criterios:
                    st.info(f"üîç Filtros ativos: {str_criterios}")
                else:
                    st.info("üìä Mostrando todos os registros")

            # Tabela de resultados com configura√ß√£o aprimorada
            st.markdown("### üìã RESULTADOS")

            # Configura√ß√£o de colunas vis√≠veis
            if 'colunas_visiveis' not in st.session_state:
                st.session_state.colunas_visiveis = ['n', 'registro', 'titulo_artigo', 'autores_colaboradores', 'vocabulario_controlado']

            with st.expander("‚öôÔ∏è Configurar Colunas Vis√≠veis", expanded=False):
                todas_colunas = list(res.columns)
                colunas_recomendadas = ['n', 'registro', 'titulo_artigo', 'autores_colaboradores', 'vocabulario_controlado', 'palavras_chave', 'paginas']

                col_config1, col_config2 = st.columns([4, 1])
                with col_config1:
                    st.session_state.colunas_visiveis = st.multiselect(
                        "Selecione as colunas a exibir:",
                        todas_colunas,
                        default=st.session_state.colunas_visiveis if st.session_state.colunas_visiveis else colunas_recomendadas,
                        key="multiselect_colunas"
                    )
                with col_config2:
                    if st.button("‚Üª Reset", help="Mostrar colunas padr√£o", use_container_width=True):
                        st.session_state.colunas_visiveis = colunas_recomendadas
                        st.rerun()

            # Exibir apenas colunas selecionadas
            res_display = res[st.session_state.colunas_visiveis] if st.session_state.colunas_visiveis else res

            st.dataframe(
                res_display,
                column_config={
                    "n": "Rev",
                    "registro": "Registro",
                    "titulo_artigo": "T√≠tulo",
                    "autores_colaboradores": "Autores",
                    "vocabulario_controlado": "Tipo Textual",
                    "palavras_chave": "Palavras-Chave",
                    "paginas": "P√°ginas"
                },
                use_container_width=True,
                height=400
            )

            df_citados = None
            df_colab = None
            if not res.empty:
                st.markdown("---")
                st.subheader("üìä AN√ÅLISE COM BASE NA SELE√á√ÉO DOS DADOS")
                s_citados = DataModule.get_normalized_series(res, 'autores_citados')
                c_stat1, c_stat2 = st.columns(2)
                with c_stat1:
                    if not s_citados.empty:
                        df_citados = UtilsModule.calculate_stats_with_percentage(s_citados)
                        st.markdown("üìå **AUTORES MAIS CITADOS**")
                        st.dataframe(df_citados.head(10), width='stretch')
                    else:
                        st.info("Nenhum autor citado nestes registros.")

                with c_stat2:
                    s_colab = DataModule.get_normalized_series(res, 'autores_colaboradores')
                    if not s_colab.empty:
                        df_colab = UtilsModule.calculate_stats_with_percentage(s_colab)
                        st.markdown("‚úçÔ∏è **AUTORES COLABORADORES**")
                        st.dataframe(df_colab.head(10), width='stretch')
                    else:
                        st.info("Nenhum colaborador listado nestes registros.")

            st.markdown("---")
            st.markdown("### üì• EXPORTAR RESULTADOS DA BUSCA")

            # Layout melhorado para bot√µes de exporta√ß√£o com espa√ßamento adequado
            col_export1, col_export2, col_export3 = st.columns([1, 1, 1])

            excel_busca = UtilsModule.converter_excel(res)
            pdf_busca = PDFModule.gerar_pdf_busca_analitica(res, len(df), str_criterios, df_citados, df_colab)

            with col_export1:
                st.download_button(
                    "üìä BAIXAR EXCEL",
                    excel_busca,
                    f"busca_sibila_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    help="Exportar resultados para Excel"
                )

            with col_export2:
                st.download_button(
                    "üìÑ BAIXAR PDF",
                    pdf_busca,
                    f"relatorio_sibila_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                    "application/pdf",
                    use_container_width=True,
                    help="Exportar relat√≥rio para PDF"
                )

            with col_export3:
                # Informa√ß√£o sobre o que ser√° exportado
                st.info(f"üìä Exportando {qtd_res} registro(s)")

        else:
            st.warning("‚ö†Ô∏è Base de dados vazia. Cadastre registros na aba CATALOGA√á√ÉO.")

    # --- RELAT√ìRIOS ---
    elif menu == "RELAT√ìRIOS":
        st.title("üìë RELAT√ìRIOS NELIC")
        if df.empty:
            st.warning("Base vazia.")
        else:
            tipo_rel = st.selectbox(
                "Selecione o relat√≥rio:",
                [
                    "Mapa de colabora√ß√£o por revista",
                    "√çndice de publica√ß√µes bil√≠ngues",
                    "Iconografia por revista",
                    "Autores como assunto vs colaboradores",
                    "An√°lise por tipos textuais",
                    "Manifesto ou manifesto",
                    "Palavras-chave"
                ]
            )
            if tipo_rel == "Mapa de colabora√ß√£o por revista":
                relatorio_mapa_colaboracao(df)
            elif tipo_rel == "√çndice de publica√ß√µes bil√≠ngues":
                relatorio_bilinguismo(df)
            elif tipo_rel == "Iconografia por revista":
                relatorio_iconografia(df)
            elif tipo_rel == "Autores como assunto vs colaboradores":
                relatorio_autores_assunto_colab(df)
            elif tipo_rel == "An√°lise por tipos textuais":
                relatorio_generos_textuais(df)
            elif tipo_rel == "Manifesto ou manifesto":
                relatorio_manifesto(df)
            elif tipo_rel == "Palavras-chave":
                relatorio_palavras_chave(df)

    # --- AN√ÅLISE COMPARATIVA ---
    elif menu == "AN√ÅLISE COMPARATIVA":
        st.title("üìä AN√ÅLISE COMPARATIVA")
        if df.empty:
            st.warning("Base vazia.")
        else:
            st.markdown("Compare dois conjuntos de registros a partir de filtros NELIC.")

            def aplicar_filtros(df_base, prefix):
                c1, c2, c3, c4 = st.columns(4)
                termo = c1.text_input(f"{prefix} ¬∑ termo livre (t√≠tulo/resumo)", key=f"termo_{prefix}")
                revs_local = sorted(df_base['n'].astype(str).unique())
                f_rev = c2.multiselect(f"{prefix} ¬∑ revistas", revs_local, key=f"rev_{prefix}")
                tipos_raw_local = df_base['vocabulario_controlado'].astype(str).unique()
                tipos_clean_local = sorted(list(set([t.split(' - ')[0] for t in tipos_raw_local])))
                f_tipo = c3.multiselect(f"{prefix} ¬∑ tipos textuais", tipos_clean_local, key=f"tipo_{prefix}")
                f_bil = c4.selectbox(
                    f"{prefix} ¬∑ bil√≠ngue",
                    ["Todos", "Apenas bil√≠ngues", "Apenas n√£o bil√≠ngues"],
                    key=f"bil_{prefix}"
                )
                res_local = df_base.copy()
                if f_rev:
                    res_local = res_local[res_local['n'].astype(str).isin(f_rev)]
                if f_tipo:
                    res_local = res_local[
                        res_local['vocabulario_controlado'].apply(lambda x: str(x).split(' - ')[0] in f_tipo)
                    ]
                res_local = res_local.copy()
                res_local['__bil'] = res_local.apply(UtilsModule.is_bilingue, axis=1)
                if f_bil == "Apenas bil√≠ngues":
                    res_local = res_local[res_local['__bil']]
                elif f_bil == "Apenas n√£o bil√≠ngues":
                    res_local = res_local[~res_local['__bil']]
                if termo:
                    res_local = res_local[
                        res_local.astype(str).apply(lambda x: x.str.contains(termo, case=False)).any(axis=1)
                    ]
                return res_local.drop(columns=['__bil'], errors='ignore')

            st.markdown("#### Conjunto A")
            df_A = aplicar_filtros(df, "A")
            st.markdown(f"Conjunto A: {len(df_A)} registros.")

            st.markdown("#### Conjunto B")
            df_B = aplicar_filtros(df, "B")
            st.markdown(f"Conjunto B: {len(df_B)} registros.")

            if not df_A.empty or not df_B.empty:
                st.markdown("---")
                st.subheader("üî¨ M√©tricas comparadas")
                def metricas(df_sub):
                    s_colab = DataModule.get_normalized_series(df_sub, 'autores_colaboradores')
                    s_cit = DataModule.get_normalized_series(df_sub, 'autores_citados')
                    ic = df_sub['iconografias'].apply(
                        lambda x: isinstance(x, list) and len(x) > 0
                    ).sum()
                    df_tmp = df_sub.copy()
                    df_tmp['__bil'] = df_tmp.apply(UtilsModule.is_bilingue, axis=1)
                    bil = df_tmp['__bil'].sum()
                    total = len(df_tmp)
                    return {
                        "registros": total,
                        "colab_distintos": s_colab.nunique(),
                        "cit_distintos": s_cit.nunique(),
                        "pct_iconografia": (ic / total * 100) if total > 0 else 0,
                        "pct_bilingue": (bil / total * 100) if total > 0 else 0
                    }

                mA = metricas(df_A) if not df_A.empty else None
                mB = metricas(df_B) if not df_B.empty else None
                cA, cB = st.columns(2)
                with cA:
                    st.markdown("##### Conjunto A")
                    if mA:
                        st.metric("Registros", mA["registros"])
                        st.metric("Colaboradores distintos", mA["colab_distintos"])
                        st.metric("Autores citados distintos", mA["cit_distintos"])
                        st.metric("% com iconografia", f"{mA['pct_iconografia']:.1f}%")
                        st.metric("% bil√≠ngue", f"{mA['pct_bilingue']:.1f}%")
                    else:
                        st.info("Sem registros no conjunto A.")

                with cB:
                    st.markdown("##### Conjunto B")
                    if mB:
                        st.metric("Registros", mB["registros"])
                        st.metric("Colaboradores distintos", mB["colab_distintos"])
                        st.metric("Autores citados distintos", mB["cit_distintos"])
                        st.metric("% com iconografia", f"{mB['pct_iconografia']:.1f}%")
                        st.metric("% bil√≠ngue", f"{mB['pct_bilingue']:.1f}%")
                    else:
                        st.info("Sem registros no conjunto B.")

    # --- QUALIDADE DOS DADOS ---
    elif menu == "QUALIDADE DOS DADOS":
        st.title("üß™ QUALIDADE DOS DADOS")
        if df.empty:
            st.warning("Base vazia.")
        else:
            st.markdown(
                "Monitoramento de consist√™ncia e lacunas conforme as exig√™ncias metodol√≥gicas do NELIC."
            )
            df_local = df.copy()
            sem_pag = df_local[
                df_local['paginas'].isna() |
                (df_local['paginas'].astype(str).str.strip() == '')
            ]
            sem_tit = df_local[
                df_local['titulo_artigo'].isna() |
                (df_local['titulo_artigo'].astype(str).str.strip() == '')
            ]
            df_local['tipo_base'] = df_local['vocabulario_controlado'].astype(str).apply(
                lambda x: x.split(' - ')[0]
            )
            precisa_resumo = ~df_local['tipo_base'].isin(TIPOS_SEM_RESUMO)
            sem_resumo = df_local[
                precisa_resumo &
                (
                    df_local['resumo'].isna() |
                    (df_local['resumo'].astype(str).str.strip() == '')
                )
            ]
            t1, t2, t3, t4 = st.tabs(
                ["Sem p√°ginas", "Sem t√≠tulo", "Sem resumo (quando exigido)", "Duplicidade de registro"]
            )
            with t1:
                st.markdown("#### Registros sem informa√ß√£o de p√°ginas")
                st.write(f"Total: {len(sem_pag)}")
                st.dataframe(sem_pag[['n', 'registro', 'titulo_artigo', 'paginas']], width='stretch')
            with t2:
                st.markdown("#### Registros sem t√≠tulo")
                st.write(f"Total: {len(sem_tit)}")
                st.dataframe(sem_tit[['n', 'registro', 'paginas']], width='stretch')
            with t3:
                st.markdown("#### Registros sem resumo em tipos que demandam resumo anal√≠tico")
                st.write(f"Total: {len(sem_resumo)}")
                st.dataframe(
                    sem_resumo[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo']],
                    width='stretch'
                )
            with t4:
                st.markdown("#### Duplicidade potencial de campo REGISTRO")
                df_local['chave_unica'] = df_local['n'].astype(str) + '_' + df_local['registro'].astype(str)
                duplicatas = df_local[df_local.duplicated(subset=['chave_unica'], keep=False)]
                if not duplicatas.empty:
                    st.write(f"Total: {len(duplicatas)} registros com potencial duplicidade")

                    if usuario_autenticado:
                        st.warning("‚ö†Ô∏è Use os bot√µes üóëÔ∏è para excluir registros duplicados. Esta a√ß√£o √© IRREVERS√çVEL!")
                    else:
                        st.info("‚ÑπÔ∏è Para excluir registros duplicados, fa√ßa login com a senha de editor.")

                    for chave in duplicatas['chave_unica'].unique():
                        grupo = duplicatas[duplicatas['chave_unica'] == chave]
                        st.markdown(f"**üî¥ Duplicata encontrada: Revista {grupo.iloc[0]['n']} - Registro {grupo.iloc[0]['registro']}**")

                        # Mostrar cada registro duplicado com bot√£o de exclus√£o
                        for idx, row in grupo.iterrows():
                            if usuario_autenticado:
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.write(f"**ID:** {row['_id']} | **T√≠tulo:** {row['titulo_artigo']} | **P√°ginas:** {row['paginas']}")
                                with col2:
                                    if st.button(f"üóëÔ∏è Excluir", key=f"delete_{row['_id']}"):
                                        # Confirmar exclus√£o
                                        if f"confirm_delete_{row['_id']}" not in st.session_state:
                                            st.session_state[f"confirm_delete_{row['_id']}"] = True
                                            st.warning(f"‚ö†Ô∏è Clique novamente para CONFIRMAR a exclus√£o do registro ID: {row['_id']}")
                                            st.rerun()
                                        else:
                                            # Excluir o registro
                                            dados_novos = [d for d in dados if d.get('_id') != row['_id']]
                                            if PersistenceModule.save_data(dados_novos):
                                                st.success(f"‚úÖ Registro ID {row['_id']} exclu√≠do com sucesso!")
                                                del st.session_state[f"confirm_delete_{row['_id']}"]
                                                st.rerun()
                                            else:
                                                st.error("‚ùå Erro ao salvar os dados ap√≥s exclus√£o.")
                            else:
                                # Visitantes veem apenas as informa√ß√µes, sem bot√£o de exclus√£o
                                st.write(f"**ID:** {row['_id']} | **T√≠tulo:** {row['titulo_artigo']} | **P√°ginas:** {row['paginas']}")
                        st.markdown("---")
                else:
                    st.success("‚úÖ Nenhuma duplicidade detectada! Todos os registros possuem combina√ß√µes √∫nicas de Revista + Registro.")
                df_local = df_local.drop(columns=['chave_unica'])

    # --- DI√ÅRIO DE PESQUISA ---
    elif menu == "DI√ÅRIO DE PESQUISA":
        st.title("üìù DI√ÅRIO DE PESQUISA ‚Äì PROJETO SIBILA")
        diario = PersistenceModule.load_diario()
        with st.expander("‚ûï Registrar nova entrada no di√°rio", expanded=True):
            with st.form("form_diario_geral"):
                titulo = st.text_input("T√≠tulo da entrada")
                texto = st.text_area("Texto da entrada", height=160)
                tags = st.text_input("Tags (separadas por v√≠rgula)")
                reg_ops = []
                reg_ids = []
                for r in dados:
                    label = f"{r.get('n','?')} | Reg: {r.get('registro','?')} | {r.get('titulo_artigo','[sem t√≠tulo]')}"
                    reg_ops.append(label)
                    reg_ids.append(r.get('_id'))
                registros_sel = st.multiselect(
                    "Vincular a registros espec√≠ficos (opcional)", reg_ops
                )
                if st.form_submit_button("üíæ Salvar entrada no di√°rio"):
                    if texto.strip():
                        vinc_ids = [
                            reg_ids[reg_ops.index(lbl)] for lbl in registros_sel
                        ]
                        entrada = {
                            "id": str(int(datetime.now().timestamp() * 1000)),
                            "data": datetime.now().isoformat(),
                            "titulo": titulo.strip() or "[sem t√≠tulo]",
                            "texto": texto.strip(),
                            "tags": [t.strip() for t in tags.split(',') if t.strip()],
                            "registros_relacionados": vinc_ids
                        }
                        diario.append(entrada)
                        if PersistenceModule.save_diario(diario):
                            st.success("Entrada adicionada ao di√°rio.")
                    else:
                        st.warning("O texto da entrada n√£o pode estar vazio.")

        st.markdown("---")
        st.subheader("Entradas registradas")
        if not diario:
            st.info("Nenhuma entrada registrada ainda.")
        else:
            tags_existentes = sorted(
                list(
                    set(
                        t
                        for d in diario
                        for t in d.get('tags', [])
                    )
                )
            )
            c1, c2 = st.columns([1, 2])
            with c1:
                tag_filtro = st.multiselect("Filtrar por tags", tags_existentes)
            with c2:
                ordem = st.selectbox("Ordenar por", ["Mais recentes primeiro", "Mais antigas primeiro"])

            entradas = diario.copy()
            entradas = sorted(
                entradas,
                key=lambda x: x.get('data', ''),
                reverse=(ordem == "Mais recentes primeiro")
            )
            if tag_filtro:
                entradas = [
                    e for e in entradas
                    if any(t in e.get('tags', []) for t in tag_filtro)
                ]

            for e in entradas:
                dt = e.get('data', '')[:16].replace("T", " ")
                st.markdown(
                    f"""
                    <div class="nelic-card">
                        <div class="nelic-card-header">{e.get('titulo','[sem t√≠tulo]')}</div>
                        <div class="nelic-card-subtitle">Data: {dt}</div>
                        <div class="nelic-muted">{e.get('texto','')}</div>
                        <div style="margin-top:0.4rem;">
                    """,
                    unsafe_allow_html=True
                )
                if e.get('tags'):
                    st.markdown(
                        " ".join(
                            [f"<span class='nelic-tag nelic-tag-muted'>{t}</span>" for t in e['tags']]
                        ),
                        unsafe_allow_html=True
                    )
                if e.get('registros_relacionados'):
                    st.markdown("<br><span class='nelic-muted'>Registros vinculados:</span>", unsafe_allow_html=True)
                    labels = []
                    for reg_id in e.get('registros_relacionados', []):
                        r = UtilsModule.get_registro_by_id(dados, reg_id)
                        if r:
                            labels.append(
                                f"{r.get('n','?')} | Reg: {r.get('registro','?')} | {r.get('titulo_artigo','[sem t√≠tulo]')}"
                            )
                    if labels:
                        st.markdown(
                            "<br>".join(labels),
                            unsafe_allow_html=True
                        )
                st.markdown("</div>", unsafe_allow_html=True)

    # --- METODOLOGIA ---
    elif menu == "METODOLOGIA":
        st.title("üìö METODOLOGIA NELIC")

        st.markdown("""
        <div class="info-box">
        <p><strong>Sistema NELIC</strong> √© uma ferramenta de cataloga√ß√£o bibliogr√°fica especializada,
        desenvolvida para documenta√ß√£o sistem√°tica de peri√≥dicos liter√°rios. Este sistema implementa
        a metodologia NELIC de indexa√ß√£o para a cataloga√ß√£o de arquivos, auxiliando em an√°lises e
        reflex√µes cr√≠ticas sobre a produ√ß√£o cultural e liter√°ria.</p>
        </div>
        """, unsafe_allow_html=True)

        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üìù Cataloga√ß√£o",
            "üîç Busca e Explora√ß√£o",
            "üìä An√°lises e Relat√≥rios",
            "üéì Metodologia Detalhada",
            "üí° Dicas de Uso"
        ])

        with tab1:
            st.markdown("### üìù GUIA DE CATALOGA√á√ÉO")

            st.markdown("""
            <div class="metod-section">
            <h4>Editor de Registros</h4>
            <p>O editor permite criar novos registros ou editar registros existentes. Cada registro representa
            um texto publicado e deve conter informa√ß√µes bibliogr√°ficas completas.</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("#### Campos do Formul√°rio de Cataloga√ß√£o")

            st.markdown("""
            <div class="metod-section">
            <h4>1. IDENTIFICA√á√ÉO B√ÅSICA</h4>
            <p><em>Campos obrigat√≥rios marcados com asterisco (*)</em></p>
            <ul>
                <li><strong>N¬∫ REVISTA:</strong> N√∫mero da edi√ß√£o da revista (1 a 13)</li>
                <li><strong>REGISTRO:</strong> C√≥digo √∫nico de identifica√ß√£o</li>
                <li><strong>P√ÅGINAS:</strong> Intervalo de p√°ginas (exemplo: 45-48)</li>
                <li><strong>ORDEM:</strong> N√∫mero de ordem de exibi√ß√£o no sistema</li>
                <li><strong>IDIOMAS:</strong> Idioma prim√°rio e secund√°rio (se bil√≠ngue)</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>2. TIPO TEXTUAL (Sistema Hier√°rquico)</h4>
            <p>O sistema utiliza classifica√ß√£o em <strong>dois n√≠veis</strong>:</p>

            <p><strong>TIPOS PRINCIPAIS:</strong></p>
            <ul>
                <li>POEMA(S) - n√£o exige resumo</li>
                <li>ENSAIO - exige resumo anal√≠tico</li>
                <li>RESENHA - exige resumo anal√≠tico</li>
                <li>ENTREVISTA - exige resumo anal√≠tico</li>
                <li>FIC√á√ÉO - n√£o exige resumo</li>
                <li>EDITORIAL</li>
                <li>APRESENTA√á√ÉO</li>
                <li>REPORTAGEM</li>
                <li>CARTAS DO LEITOR</li>
                <li>E outros</li>
            </ul>

            <p><strong>SUBTIPOS (Campo disciplinar):</strong></p>
            <p>Alguns tipos principais permitem especifica√ß√£o disciplinar:</p>
            <ul>
                <li>ENSAIO: Literatura, Filosofia, Hist√≥ria, Lingu√≠stica, etc.</li>
                <li>RESENHA: Literatura, Antropologia, Sociologia, etc.</li>
                <li>ENTREVISTA: Literatura</li>
                <li>INFORME: Literatura</li>
            </ul>
            <p><strong>Exemplo:</strong> ENSAIO - Filosofia</p>
            <p><strong>‚ö†Ô∏è ATEN√á√ÉO:</strong> O sistema valida automaticamente se o tipo textual exige resumo anal√≠tico.</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>3. T√çTULOS E NOTAS</h4>
            <p><strong>T√çTULO (obrigat√≥rio):</strong></p>
            <ul>
                <li>Se o texto possui t√≠tulo: transcreva fielmente</li>
                <li>Se poema sem t√≠tulo: insira primeiro verso entre aspas e retic√™ncias
                    <br>Exemplo: "n√£o penses enquanto passa (‚Ä¶)"</li>
                <li>Se prosa sem t√≠tulo: reproduza as 4-5 primeiras palavras</li>
            </ul>

            <p><strong>SUBT√çTULO:</strong> Caso exista</p>

            <p><strong>NOTA DE EDI√á√ÉO:</strong> Informa√ß√µes editoriais importantes</p>
            <ul>
                <li>[publica√ß√£o bil√≠ngue]</li>
                <li>[tradu√ß√£o do ingl√™s]</li>
                <li>[texto republicado de...]</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>4. RESPONSABILIDADE AUTORAL</h4>
            <p><strong>FORMATO ABNT (autom√°tico):</strong> O sistema converte automaticamente para SOBRENOME, Prenomes</p>

            <p><strong>Exemplos:</strong></p>
            <ul>
                <li>Digite: R√©gis Bonvicino ‚Üí Sistema salva: BONVICINO, R√©gis</li>
                <li>Digite: Claudio Daniel ‚Üí Sistema salva: DANIEL, Claudio</li>
            </ul>

            <p><strong>COLABORADORES:</strong> Autores do texto (um por linha)</p>
            <p><strong>TRADUTORES:</strong> Se aplic√°vel (um por linha)</p>
            <p><strong>üí° Dica:</strong> Digite um nome por linha ou separe por v√≠rgulas</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>5. ASSUNTOS E INDEXA√á√ÉO</h4>
            <p><strong>AUTORES CITADOS:</strong> Autores mencionados no texto (um por linha)</p>
            <ul>
                <li>Use para mapear refer√™ncias bibliogr√°ficas</li>
                <li>Importante para an√°lise de redes intelectuais</li>
            </ul>

            <p><strong>PALAVRAS-CHAVE:</strong> Use APENAS termos do Vocabul√°rio Controlado</p>
            <ul>
                <li>Lista pr√©-estabelecida de 400+ termos</li>
                <li>Garante consist√™ncia nas buscas</li>
                <li>Exemplos: Poesia, Modernismo, Vanguarda, Literatura Brasileira</li>
            </ul>

            <p><strong>NOME PESSOAL COMO ASSUNTO:</strong> Pessoas que s√£o tema principal</p>
            <ul>
                <li>Use para biografias, homenagens, estudos cr√≠ticos</li>
                <li>Exemplo: texto sobre Drummond ‚Üí ANDRADE, Carlos Drummond de</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>6. RESUMO ANAL√çTICO</h4>
            <p><strong>‚ö†Ô∏è OBRIGAT√ìRIO PARA:</strong></p>
            <ul>
                <li>ENSAIO</li>
                <li>RESENHA</li>
                <li>ENTREVISTA</li>
                <li>REPORTAGEM</li>
                <li>EDITORIAL (com conte√∫do anal√≠tico)</li>
                <li>APRESENTA√á√ÉO</li>
                <li>DEBATE</li>
            </ul>

            <p><strong>N√ÉO EXIGIDO PARA:</strong></p>
            <ul>
                <li>POEMA(S)</li>
                <li>FIC√á√ÉO</li>
                <li>CAPA</li>
                <li>IMAGENS</li>
                <li>HQ/CHARGE</li>
            </ul>

            <p><strong>Como escrever:</strong> S√≠ntese cr√≠tica do conte√∫do (150-300 palavras)</p>
            <ul>
                <li>Tema central</li>
                <li>Argumentos principais</li>
                <li>Conclus√µes ou posi√ß√µes defendidas</li>
            </ul>

            <p><strong>Nota:</strong> O sistema valida automaticamente e impede salvar se resumo estiver ausente quando obrigat√≥rio.</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>7. ICONOGRAFIA</h4>
            <p>Documenta√ß√£o sistem√°tica de elementos visuais:</p>

            <p><strong>TIPOS:</strong></p>
            <ul>
                <li>Foto</li>
                <li>Ilustra√ß√£o</li>
                <li>Reprodu√ß√£o (de obra de arte)</li>
                <li>Fac-s√≠mile</li>
                <li>Cartografia</li>
                <li>Gr√°fico/Tabela</li>
                <li>HQ/Charge</li>
                <li>Fotograma</li>
                <li>Publicidade</li>
            </ul>

            <p><strong>DESCRI√á√ÉO:</strong> T√≠tulo da obra, cr√©ditos, data</p>
            <p><strong>Exemplo:</strong></p>
            <ul>
                <li>Tipo: Foto</li>
                <li>Descri√ß√£o: "Retrato de Jo√£o Cabral de Melo Neto. Foto: Arquivo Nacional, 1960"</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

        with tab2:
            st.markdown("### üîç Busca e Explora√ß√£o")

            st.markdown("""
            <div class="metod-section">
            <p>A busca e a explora√ß√£o de dados no sistema NELIC de indexa√ß√£o se organizam em torno de uma ideia simples:
            qualquer consulta come√ßa pela defini√ß√£o de um recorte dentro do conjunto de registros catalogados. Esse recorte
            pode ser temporal (per√≠odo, fasc√≠culos, volumes), formal (tipologia dos textos), lingu√≠stico (idiomas envolvidos),
            autoral (quem escreve, quem √© citado), tem√°tico (palavras-chave) ou material (presen√ßa de iconografia).</p>

            <p>O sistema NELIC de indexa√ß√£o funciona sempre sobre a mesma base de dados estruturada, em que cada texto possui
            campos definidos (idioma, vocabul√°rio controlado, autores colaboradores, autores citados, palavras-chave, iconografia,
            p√°ginas, entidade coletiva, entre outros). A busca consiste em selecionar combina√ß√µes desses campos para obter
            subconjuntos coerentes. Alguns exemplos de recortes poss√≠veis:</p>

            <ul>
                <li>textos de um determinado per√≠odo e de um √∫nico tipo textual, como "ensaios entre 2001 e 2002";</li>
                <li>textos em mais de um idioma, de modo a isolar publica√ß√µes bil√≠ngues;</li>
                <li>textos que tenham uma palavra-chave espec√≠fica, como "modernismo" ou "tradu√ß√£o";</li>
                <li>textos em que um determinado nome aparece como autor colaborador, como autor citado ou como "nome pessoal como assunto".</li>
            </ul>

            <p>No caso de recortes temporais, como "ensaios entre 2001 e 2002", o sistema n√£o possui um filtro direto por ano.
            O procedimento depende do mapeamento entre ano e n√∫mero da revista: √© necess√°rio saber quais n√∫meros correspondem
            a 2001 e 2002 e, em seguida, selecionar esses n√∫meros no filtro de "Revista" da aba EXPLORAR DADOS, combinando
            com o tipo textual "Ensaio".</p>

            <p>A l√≥gica √© cumulativa: ao combinar crit√©rios de tipologia, idioma, palavra-chave e autoria, o sistema reduz
            progressivamente o universo de registros at√© chegar a um conjunto bem delimitado. Um recorte como "ensaios em espanhol
            sobre cultura que citam determinado te√≥rico" pode ser trabalhado, na pr√°tica, da seguinte forma: na aba EXPLORAR DADOS,
            selecionar "Ensaio" em "Tipo Textual", escolher "Cultura" (ou o termo tem√°tico mais pr√≥ximo dispon√≠vel) no campo de
            "Palavras-Chave" e inserir o sobrenome do te√≥rico no campo de "Busca Livre (T√≠tulo/Resumo)". Essa busca livre percorre
            tamb√©m colunas textuais internas, de modo que registros em que o te√≥rico apare√ßa como autor citado tendem a ser recuperados.
            Como n√£o h√° filtro espec√≠fico por idioma nessa tela, a etapa "em espanhol" exige um passo adicional: depois de obter o
            conjunto de ensaios com aquele tema e aquele te√≥rico, basta exportar os resultados para Excel e filtrar, na planilha,
            a coluna de idioma pela sigla correspondente (por exemplo, "ESP" para espanhol).</p>

            <p>O resultado t√≠pico de uma busca √© uma lista tabular de registros, em que cada linha corresponde a um texto e cada
            coluna a um campo relevante (t√≠tulo, autores, tipo textual, idiomas, p√°ginas, palavras-chave, presen√ßa de iconografia).
            A partir dessa lista, j√° √© poss√≠vel observar padr√µes simples, como a concentra√ß√£o de um mesmo autor em determinado per√≠odo,
            a recorr√™ncia de certas palavras-chave em tipos textuais espec√≠ficos ou a distribui√ß√£o da iconografia ao longo de uma cole√ß√£o.</p>

            <p>Essa etapa de busca e explora√ß√£o funciona como momento de delimita√ß√£o do corpus para an√°lises posteriores. A qualidade
            desse trabalho depende diretamente da consist√™ncia da cataloga√ß√£o: quanto mais rigorosamente os campos forem preenchidos,
            mais precisos se tornam os recortes poss√≠veis.</p>
            </div>
            """, unsafe_allow_html=True)


        with tab3:
            st.markdown("### üìä An√°lise e Relat√≥rios")

            st.markdown("""
            <div class="metod-section">
            <p>A etapa de an√°lise trabalha com os mesmos registros catalogados, mas desloca o foco da descri√ß√£o individual de
            cada texto para a observa√ß√£o de distribui√ß√µes, frequ√™ncias e propor√ß√µes. Em vez de perguntar "quais textos satisfazem
            determinado crit√©rio?", passa-se a perguntar "como os dados se distribuem dentro de um crit√©rio ou combina√ß√£o de crit√©rios?".</p>

            <p>O sistema NELIC de indexa√ß√£o calcula, a partir dos campos preenchidos, tabelas de frequ√™ncia e percentuais. Alguns
            exemplos de sa√≠das poss√≠veis:</p>

            <ul>
                <li>distribui√ß√£o dos tipos textuais no conjunto: quantos ensaios, resenhas, poemas, entrevistas, fic√ß√µes, editoriais etc.,
                    em n√∫meros absolutos e em porcentagem;</li>
                <li>lista de autores colaboradores com o n√∫mero de textos publicados e sua participa√ß√£o relativa no total;</li>
                <li>lista de autores citados, ordenada por n√∫mero de ocorr√™ncias, o que permite mapear redes de refer√™ncia e campos te√≥ricos predominantes;</li>
                <li>distribui√ß√£o de palavras-chave mais recorrentes, indicando temas estruturantes do corpus;</li>
                <li>propor√ß√£o de textos com iconografia em rela√ß√£o ao total, bem como varia√ß√µes dessa propor√ß√£o em diferentes recortes
                    (por per√≠odo, por tipo textual, por idioma, quando esses dados forem combinados com filtros e exporta√ß√µes).</li>
            </ul>

            <p>Quando a an√°lise √© feita sobre um recorte previamente delimitado na busca (por exemplo, "todos os ensaios de um certo per√≠odo"),
            as tabelas e propor√ß√µes dizem respeito apenas a esse subconjunto. Isso permite, por exemplo, comparar os autores mais citados em
            ensaios com os autores mais citados em resenhas, ou a distribui√ß√£o de idiomas em textos cr√≠ticos em rela√ß√£o √† distribui√ß√£o em
            textos criativos.</p>

            <p>Os resultados podem ser organizados em tabelas simples com as colunas "valor" (por exemplo, o nome do autor ou da palavra-chave),
            "frequ√™ncia absoluta" e "percentual no conjunto analisado". A mesma informa√ß√£o pode ser representada em gr√°ficos de barras que
            facilitam a identifica√ß√£o de concentra√ß√µes, aus√™ncias e deslocamentos.</p>

            <p>Al√©m da visualiza√ß√£o dentro do sistema, as an√°lises podem ser exportadas em formatos adequados ao trabalho de pesquisa. Em
            planilhas, o pesquisador pode reorganizar, filtrar e combinar as tabelas com outros dados. Em relat√≥rios em PDF, os resultados
            podem ser incorporados diretamente a projetos, artigos e cap√≠tulos, documentando com clareza os crit√©rios utilizados e os n√∫meros obtidos.</p>
            </div>
            """, unsafe_allow_html=True)


        with tab4:
            st.markdown("### üéì Metodologia Detalhada")

            st.markdown("""
            <div class="metod-section">
            <p>A metodologia do sistema de cataloga√ß√£o parte da defini√ß√£o de um conjunto de campos que precisam ser preenchidos de
            maneira uniforme. Cada campo corresponde a um aspecto do texto e pode ser posteriormente utilizado como crit√©rio de busca
            ou de an√°lise. O preenchimento cuidadoso desses campos √© a base de toda a explora√ß√£o posterior.</p>

            <p><strong>Alguns campos centrais:</strong></p>

            <h4>Identifica√ß√£o b√°sica</h4>
            <p>Inclui n√∫mero ou c√≥digo do fasc√≠culo, ordem de exibi√ß√£o do texto dentro da cole√ß√£o, intervalo de p√°ginas e registro √∫nico.
            Esses dados permitem localizar o texto fisicamente e reconstruir a organiza√ß√£o interna de cada n√∫mero.</p>

            <h4>Idiomas</h4>
            <p>Registra o idioma principal do texto e, quando pertinente, um segundo idioma em caso de tradu√ß√µes ou publica√ß√µes bil√≠ngues.
            O uso de siglas padronizadas (POR, ESP, ING, ITA etc.) evita ambiguidades e facilita contagens posteriores de distribui√ß√£o lingu√≠stica.</p>

            <h4>Entidade coletiva e autoria</h4>
            <p>Quando um texto n√£o √© atribu√≠do a um indiv√≠duo, o campo "entidade coletiva" indica a responsabilidade institucional (por exemplo,
            a pr√≥pria revista ou um grupo editorial). Nos demais casos, os "autores colaboradores" s√£o listados com nome normalizado em formato
            padr√£o (sobrenome em mai√∫sculas, seguido do prenome). Em entrevistas, tanto entrevistador(es) quanto entrevistado(a) s√£o inclu√≠dos,
            de modo que a busca por qualquer um deles recupere o registro.</p>

            <h4>Tradutor</h4>
            <p>Sempre que houver tradu√ß√£o, o tradutor √© identificado pelo nome completo. Nos casos em que a tradu√ß√£o √© mencionada sem cr√©dito,
            registra-se essa condi√ß√£o (por exemplo, "sem cr√©dito") para n√£o deixar o campo vazio e, ao mesmo tempo, n√£o atribuir autoria inexistente.</p>

            <h4>T√≠tulo, subt√≠tulo e resumo</h4>
            <p>O t√≠tulo √© transcrito conforme aparece no texto, com regras espec√≠ficas para poemas ou textos em prosa sem t√≠tulo, em que se
            utilizam versos ou primeiras palavras como forma de identifica√ß√£o. O subt√≠tulo, quando existe, complementa o t√≠tulo e pode reunir
            dados adicionais, como informa√ß√µes sobre obras resenhadas. O resumo oferece uma descri√ß√£o concisa do conte√∫do em textos de car√°ter
            anal√≠tico (ensaios, resenhas, entrevistas, reportagens, apresenta√ß√µes) e √© dispensado em textos ficcionais ou po√©ticos. Notas
            complementares, informa√ß√µes de publica√ß√£o original ou peculiaridades de autoria s√£o acrescentadas entre colchetes.</p>

            <h4>Vocabul√°rio controlado (tipologia)</h4>
            <p>Cada texto recebe uma categoria de tipo textual, escolhida a partir de uma lista limitada e previamente definida. Entre as
            possibilidades est√£o apresenta√ß√£o, poema, resenha, reportagem, cartas do leitor, correspond√™ncia, depoimento, entrevista, fic√ß√£o,
            editorial, informe, HQ/charge, ensaio, entre outras. Em alguns casos, acrescenta-se um segundo termo para indicar a √°rea disciplinar
            (por exemplo, ensaio ‚Äì filosofia; resenha ‚Äì literatura). Essa solu√ß√£o permite cruzar forma textual e campo de conhecimento.</p>

            <h4>Palavras-chave</h4>
            <p>Em textos anal√≠ticos, o catalogador seleciona at√© seis palavras-chave a partir de um vocabul√°rio controlado mais amplo, que
            inclui conceitos, temas, correntes e no√ß√µes recorrentes. Isso evita varia√ß√µes arbitr√°rias de grafia e garante comparabilidade entre
            textos. Poemas, fic√ß√µes, capas, HQs e charges, em geral, n√£o recebem palavras-chave tem√°ticas para preservar a especificidade de
            seu registro.</p>

            <h4>Nome pessoal como assunto</h4>
            <p>Esse campo √© preenchido quando o texto trata diretamente de uma pessoa (autores, artistas, cr√≠ticos, te√≥ricos), independentemente
            de quem assine o texto. O mesmo nome deve aparecer tamb√©m entre os autores citados, de modo a permitir pesquisas tanto por "assunto
            pessoa" quanto por "cita√ß√£o".</p>

            <h4>Autores citados</h4>
            <p>Re√∫ne os nomes mencionados ao longo do texto. N√£o se trata de uma lista bibliogr√°fica completa, mas de um registro dos nomes que
            aparecem como refer√™ncia ou interlocu√ß√£o. Esse campo √© crucial para an√°lises de redes de cita√ß√£o, identifica√ß√£o de c√¢nones cr√≠ticos
            e mapeamento de refer√™ncias te√≥ricas.</p>

            <h4>Iconografia</h4>
            <p>Registra a presen√ßa de imagens associadas ao texto, classificadas em categorias (cartografia, fac-s√≠mile, fotografia, fotograma,
            gr√°fico/tabela, HQ/charge, ilustra√ß√£o, publicidade, reprodu√ß√£o). Para cada item, descrevem-se t√≠tulo, cr√©dito e data, com conven√ß√µes
            para casos em que essas informa√ß√µes n√£o est√£o dispon√≠veis.</p>

            <p><strong>Considera√ß√µes finais:</strong></p>
            <p>Todos esses campos s√£o simultaneamente descritivos e anal√≠ticos. Ao preencher "vocabul√°rio controlado" e "palavras-chave",
            estabelece-se a base para an√°lises tem√°ticas e formais. Ao registrar "autores citados" e "nome pessoal como assunto", cria-se a
            possibilidade de estudar redes de influ√™ncia. Ao marcar iconografia, torna-se poss√≠vel discutir o papel das imagens no conjunto.
            O sistema de indexa√ß√£o transforma, assim, o conjunto de textos em um banco de dados preparado para opera√ß√µes comparativas de diferentes ordens.</p>
            </div>
            """, unsafe_allow_html=True)


        with tab5:
            st.markdown("### üí° Dicas de Uso")

            st.markdown("""
            <div class="metod-section">
            <p>O sistema de cataloga√ß√£o foi pensado para ser √∫til tanto em consultas pontuais quanto em pesquisas de f√¥lego. Algumas
            orienta√ß√µes podem facilitar esse uso.</p>

            <p>Uma primeira etapa consiste em transformar perguntas vagas em recortes claros. Em vez de "quero ver artigos sobre teoria",
            √© poss√≠vel formular quest√µes como "ensaios com palavra-chave teoria" ou "textos em que determinado autor aparece como citado".
            A partir disso, os filtros correspondentes podem ser aplicados de forma mais precisa, em especial na aba EXPLORAR DADOS e nas
            p√°ginas de an√°lise.</p>

            <p>Os cruzamentos de dados tornam-se mais interessantes quando se pensa em pares de campos. Alguns exemplos de perguntas que
            o sistema ajuda a responder, combinando filtros e an√°lises:</p>

            <ul>
                <li>Qual a distribui√ß√£o de tipos textuais em determinado per√≠odo da cole√ß√£o?</li>
                <li>Quais autores colaboradores concentram mais publica√ß√µes em um intervalo de n√∫meros de revista?</li>
                <li>Quais autores s√£o mais citados em textos classificados como "ensaio ‚Äì literatura", e como isso se compara a textos
                    classificados como "ensaio ‚Äì filosofia"?</li>
                <li>Que palavras-chave aparecem com maior frequ√™ncia em textos bil√≠ngues, identificados depois na coluna de idiomas?</li>
                <li>Em quais tipos de texto a iconografia √© mais utilizada?</li>
            </ul>

            <p>As sa√≠das num√©ricas (contagens e percentuais) precisam ser lidas sempre em rela√ß√£o ao conjunto considerado. Um mesmo autor
            pode aparecer com um percentual baixo na base completa, mas ser central em um recorte espec√≠fico. Interpretar a propor√ß√£o dentro
            de cada recorte √© decisivo para n√£o generalizar conclus√µes.</p>

            <p>Os arquivos exportados em planilha permitem prolongar as an√°lises: calcular m√©dias, criar gr√°ficos personalizados, agrupar
            registros por per√≠odos (aproximados pelos n√∫meros da revista), comparar duas ou mais cole√ß√µes. J√° os relat√≥rios em PDF s√£o adequados
            para registrar o estado de uma pesquisa em determinado momento, servindo como documento de trabalho e registro dos recortes utilizados.</p>

            <p>O uso continuado do sistema tamb√©m funciona como revis√£o da pr√≥pria cataloga√ß√£o. Consultas que retornam resultados inesperados
            podem revelar inconsist√™ncias de preenchimento, diferen√ßas indesejadas de grafia ou campos sem dados em lugares estrat√©gicos. Nesse
            sentido, a explora√ß√£o n√£o apenas extrai informa√ß√£o anal√≠tica, mas retroalimenta o cuidado com o banco de dados, fortalecendo a
            confiabilidade do sistema de indexa√ß√£o como um todo.</p>
            </div>
            """, unsafe_allow_html=True)



    # --- MAIS DADOS ---
    elif menu == "MAIS DADOS":
        st.title("üìä MAIS DADOS - AN√ÅLISE COMPLETA")
        if not df.empty:
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("REGISTROS", len(df))
            c2.metric("COLABORADORES", DataModule.get_normalized_series(df, 'autores_colaboradores').nunique())
            c3.metric("AUTORES CITADOS", DataModule.get_normalized_series(df, 'autores_citados').nunique())
            if 'iconografias' in df.columns:
                n_icon = df['iconografias'].apply(
                    lambda x: 1 if isinstance(x, list) and len(x) > 0 else 0
                ).sum()
                p_icon = (n_icon / len(df)) * 100
                c4.metric("√çNDICE ICONOGRAFIA", f"{p_icon:.1f}%", help=f"{n_icon} registros cont√™m iconografia")
            else:
                c4.metric("√çNDICE ICONOGRAFIA", "0%")

            st.markdown("---")
            st.subheader("üì• EXPORTAR BASE COMPLETA")
            col_exp1, col_exp2, col_exp3 = st.columns(3)
            excel_completo = UtilsModule.converter_excel(df)
            pdf_completo = PDFModule.gerar_pdf_analitico(df, len(df), "Base de dados completa")
            json_completo = json.dumps(dados, ensure_ascii=False, indent=2)
            col_exp1.download_button(
                "üìä EXCEL COMPLETO",
                excel_completo,
                f"sibila_completo_{datetime.now().strftime('%Y%m%d')}.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width='stretch'
            )
            col_exp2.download_button(
                "üìÑ PDF COMPLETO",
                pdf_completo,
                f"sibila_completo_{datetime.now().strftime('%Y%m%d')}.pdf",
                "application/pdf",
                width='stretch'
            )
            col_exp3.download_button(
                "üíæ JSON COMPLETO",
                json_completo,
                f"sibila_completo_{datetime.now().strftime('%Y%m%d')}.json",
                "application/json",
                width='stretch'
            )

            st.markdown("---")
            g1, g2 = st.columns(2)
            with g1:
                s = df['vocabulario_controlado'].apply(
                    lambda x: str(x).split(' - ')[0] if isinstance(x, str) else x
                )
                v = s.value_counts().head(10).reset_index()
                v.columns = ['Tipo', 'Qtd']
                fig = px.bar(v, x='Tipo', y='Qtd', text='Qtd')
                fig.update_layout(title="DISTRIBUI√á√ÉO POR TIPO TEXTUAL", height=380)
                st.plotly_chart(fig, width='stretch')
            with g2:
                r = df['n'].value_counts().reset_index()
                r.columns = ['Revista', 'Qtd']
                fig2 = px.bar(
                    r.sort_values('Revista'),
                    x='Revista',
                    y='Qtd',
                    text='Qtd'
                )
                fig2.update_layout(title="REGISTROS POR REVISTA", height=380)
                st.plotly_chart(fig2, width='stretch')

            st.markdown("---")
            t1, t2, t3, t4 = st.tabs(
                ["PALAVRAS-CHAVE", "AUTORES CITADOS", "COLABORADORES", "TRADUTORES"]
            )
            def show_stats_with_export(col, label, tab_key):
                s = DataModule.get_normalized_series(df, col)
                if s.empty:
                    st.info(f"Sem dados de {label.lower()}.")
                    return
                counts = UtilsModule.calculate_stats_with_percentage(s)
                df_export = counts.rename(
                    columns={'Termo': 'Campo', 'Qtd': 'Num. Absoluto', '%': 'Percentual'}
                )
                st.markdown(f"### üì• Exportar dados de {label}")
                exp_col1, exp_col2, exp_col3 = st.columns(3)
                excel_cat = UtilsModule.converter_excel(df_export)
                exp_col1.download_button(
                    f"üìä EXCEL - {label.upper()}",
                    excel_cat,
                    f"sibila_{tab_key}_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    width='stretch',
                    key=f"btn_excel_{tab_key}"
                )
                pdf_cat = PDFModule.gerar_pdf_tabela_estatistica(df_export, label)
                exp_col2.download_button(
                    f"üìÑ PDF - {label.upper()}",
                    pdf_cat,
                    f"sibila_{tab_key}_{datetime.now().strftime('%Y%m%d')}.pdf",
                    "application/pdf",
                    width='stretch',
                    key=f"btn_pdf_{tab_key}"
                )
                csv_data = df_export.to_csv(index=False, encoding='utf-8-sig')
                exp_col3.download_button(
                    f"üìã CSV - {label.upper()}",
                    csv_data,
                    f"sibila_{tab_key}_{datetime.now().strftime('%Y%m%d')}.csv",
                    "text/csv",
                    width='stretch',
                    key=f"btn_csv_{tab_key}"
                )
                st.markdown("---")
                st.markdown(f"**‚¨ÜÔ∏è {label.upper()} MAIS FREQUENTES (Top 30)**")
                st.dataframe(counts.head(30), width='stretch')
                with st.expander(f"Mostrar tabela completa de {label} ({len(counts)} termos)"):
                    st.dataframe(counts, width='stretch')

            with t1:
                show_stats_with_export('palavras_chave', 'Palavra-chave', 'palavras_chave')
            with t2:
                show_stats_with_export('autores_citados', 'Autor Citado', 'autores_citados')
            with t3:
                show_stats_with_export('autores_colaboradores', 'Colaborador', 'colaboradores')
            with t4:
                show_stats_with_export('tradutores', 'Tradutor', 'tradutores')
        else:
            st.warning("‚ö†Ô∏è Base de dados vazia. Cadastre registros na aba CATALOGA√á√ÉO.")

    # --- EXPORTAR ---
    elif menu == "EXPORTAR":
        st.title("üíæ GERENCIAMENTO DE DADOS")
        st.markdown("### üì§ IMPORTA√á√ÉO")
        c1, c2 = st.columns(2)
        with c1:
            u = st.file_uploader("Importar JSON (cat√°logo)", type=['json'])
            if u:
                try:
                    n = json.load(u)
                    if isinstance(n, list):
                        dados.extend(n)
                        un = {v.get('_id', str(i)): v for i, v in enumerate(dados)}.values()
                        if PersistenceModule.save_data(list(un)):
                            st.success("‚úÖ Dados importados com sucesso!")
                            st.balloons()
                except Exception as e:
                    st.error(f"‚ùå Erro ao importar: {str(e)}")
        with c2:
            u2 = st.file_uploader("Importar JSON (di√°rio de pesquisa)", type=['json'])
            if u2:
                try:
                    d = json.load(u2)
                    if isinstance(d, list):
                        if PersistenceModule.save_diario(d):
                            st.success("‚úÖ Di√°rio importado com sucesso!")
                            st.balloons()
                except Exception as e:
                    st.error(f"‚ùå Erro ao importar di√°rio: {str(e)}")

        st.markdown("---")
        st.markdown("### üì• EXPORTA√á√ÉO")
        if not df.empty:
            exp_row1_col1, exp_row1_col2, exp_row1_col3 = st.columns(3)
            js = json.dumps(dados, ensure_ascii=False, indent=2)
            exp_row1_col1.download_button(
                "üì• BAIXAR JSON (CAT√ÅLOGO)",
                js,
                f"backup_sibila_{datetime.now().strftime('%Y%m%d')}.json",
                "application/json",
                width='stretch'
            )
            excel_data = UtilsModule.converter_excel(df)
            exp_row1_col2.download_button(
                "üìä BAIXAR EXCEL (CAT√ÅLOGO)",
                excel_data,
                f"backup_sibila_{datetime.now().strftime('%Y%m%d')}.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width='stretch'
            )
            csv_data = df.astype(str).to_csv(index=False, encoding='utf-8-sig')
            exp_row1_col3.download_button(
                "üìÑ BAIXAR CSV (CAT√ÅLOGO)",
                csv_data,
                f"backup_sibila_{datetime.now().strftime('%Y%m%d')}.csv",
                "text/csv",
                width='stretch'
            )
        else:
            st.info("Nenhum dado para exportar (cat√°logo).")

        st.markdown("#### Di√°rio de pesquisa")
        diario = PersistenceModule.load_diario()
        if diario:
            js_d = json.dumps(diario, ensure_ascii=False, indent=2)
            st.download_button(
                "üì• BAIXAR JSON (DI√ÅRIO)",
                js_d,
                f"diario_sibila_{datetime.now().strftime('%Y%m%d')}.json",
                "application/json",
                width='stretch'
            )
        else:
            st.info("Nenhuma entrada no di√°rio para exportar.")

        st.markdown("---")
        st.markdown("### üìä ESTAT√çSTICAS DO SISTEMA")
        stat_col1, stat_col2 = st.columns(2)
        if os.path.exists(BACKUP_DIR):
            backups = sorted(os.listdir(BACKUP_DIR), reverse=True)
            stat_col1.metric("Backups dispon√≠veis", len(backups))
        else:
            backups = []
            stat_col1.metric("Backups dispon√≠veis", 0)
        stat_col2.metric("Total de Registros", len(df))
        diario = PersistenceModule.load_diario()
        st.markdown(f"**Entradas no di√°rio de pesquisa:** {len(diario)}")
        if backups:
            st.markdown("#### üì¶ Backups salvos (√∫ltimos 5)")
            backups_recentes = backups[:5]
            for bkp in backups_recentes:
                bkp_path = os.path.join(BACKUP_DIR, bkp)
                try:
                    with open(bkp_path, 'r', encoding='utf-8') as f:
                        conteudo = f.read()
                    st.download_button(
                        f"üì• Baixar {bkp}",
                        conteudo,
                        file_name=bkp,
                        mime="application/json",
                        width='stretch',
                        key=f"btn_bkp_{bkp}"
                    )
                except Exception as e:
                    st.warning(f"N√£o foi poss√≠vel carregar o backup {bkp}: {e}")
            if len(backups) > 5:
                st.info(f"‚ÑπÔ∏è Existem mais {len(backups) - 5} backup(s) antigo(s) n√£o exibido(s).")

if __name__ == "__main__":
    main()