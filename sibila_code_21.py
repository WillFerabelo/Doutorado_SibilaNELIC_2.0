import streamlit as st
import pandas as pd
import json
import os
import time
from datetime import datetime
import plotly.express as px
from io import BytesIO
from fpdf import FPDF
from typing import Dict, List, Any, Optional, Tuple, Callable
import hashlib
import uuid
from streamlit_option_menu import option_menu
import re

# ==========================================
# IMPORTS PARA AN√ÅLISE AVAN√áADA (Humanidades Digitais)
# ==========================================
# Imports condicionais para evitar quebra se bibliotecas n√£o estiverem instaladas
try:
    import networkx as nx
    NETWORKX_AVAILABLE = True
except ImportError:
    NETWORKX_AVAILABLE = False

try:
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')  # Backend n√£o-interativo para Streamlit
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False

try:
    import seaborn as sns
    SEABORN_AVAILABLE = True
except ImportError:
    SEABORN_AVAILABLE = False

except ImportError:
    SEABORN_AVAILABLE = False

try:
    from pyvis.network import Network
    import streamlit.components.v1 as components
    PYVIS_AVAILABLE = True
except ImportError:
    PYVIS_AVAILABLE = False

try:
    from collections import Counter
    import string
    
    # Tentativa de usar NLTK (conforme solicitado no plano avan√ßado)
    try:
        import nltk
        try:
            nltk.data.find('corpora/stopwords')
        except LookupError:
            nltk.download('stopwords', quiet=True)
        from nltk.corpus import stopwords
        STOP_WORDS_PT = set(stopwords.words('portuguese'))
        NLP_AVAILABLE = True
    except (ImportError, Exception):
        # Fallback para lista embutida caso NLTK falhe
        STOP_WORDS_PT = {
            'a', '√†', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', '√†s',
            'at√©', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois',
            'do', 'dos', 'e', '√©', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram',
            'essa', 'essas', 'esse', 'esses', 'esta', 'estas', 'este', 'estes', 'eu', 'foi',
            'fomos', 'for', 'fora', 'foram', 'forem', 'formos', 'fosse', 'fossem', 'fui', 'h√°',
            'isso', 'isto', 'j√°', 'lhe', 'lhes', 'lo', 'mais', 'mas', 'me', 'mesmo', 'meu',
            'meus', 'minha', 'minhas', 'muito', 'na', 'n√£o', 'nas', 'nem', 'no', 'nos', 'n√≥s',
            'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela',
            'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 's√£o', 'se', 'seja',
            'sejam', 'sejamos', 'sem', 'ser', 'ser√°', 'ser√£o', 'seria', 'seriam', 'ser√≠amos',
            'seu', 'seus', 's√≥', 'somos', 'sou', 'sua', 'suas', 'tamb√©m', 'te', 'tem', 't√©m',
            'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'ter', 'teu', 'teus', 'ti', 'tido',
            'tinha', 'tinham', 't√≠nhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram',
            'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tiv√©ssemos', 'tu', 'tua', 'tuas',
            'um', 'uma', 'umas', 'uns', 'voc√™', 'voc√™s', 'vos', 'vossa', 'vossas', 'vosso',
            'vossos', 'ainda', 'assim', 'bem', 'bom', 'cada', 'coisa', 'coisas', 'dele', 'desse',
            'desses', 'dessa', 'dessas', 'deste', 'destes', 'desta', 'destas', 'disto', 'daquele',
            'daqueles', 'daquela', 'daquelas', 'daquilo', 'donde', 'ent√£o', 'etc', 'fazer', 'feito',
            'grande', 'grandes', 'h√°', 'isto', 'l√°', 'la', 'lo', 'lugar', 'maior', 'maiores',
            'melhor', 'melhores', 'menor', 'menores', 'menos', 'mesma', 'mesmas', 'mesmos', 'muita',
            'muitas', 'muitos', 'nada', 'nela', 'nelas', 'nele', 'neles', 'nenhum', 'nenhuma',
            'nesse', 'nesses', 'nessa', 'nessas', 'neste', 'nestes', 'nesta', 'nestas', 'ningu√©m',
            'nisso', 'nisto', 'novo', 'novos', 'onde', 'ora', 'outra', 'outras', 'outro', 'outros',
            'parte', 'partes', 'pois', 'pouca', 'poucas', 'pouco', 'poucos', 'primeira', 'primeiras',
            'primeiro', 'primeiros', 'pr√≥pria', 'pr√≥prias', 'pr√≥prio', 'pr√≥prios', 'qual', 'quais',
            'qualquer', 'quase', 'quatro', 'segundo', 'segunda', 'sempre', 'ser', 'seus', 'tal',
            'tais', 'tanto', 'tantos', 'tanta', 'tantas', 'ter', 'toda', 'todas', 'todo', 'todos',
            'tr√™s', 'tudo', '√∫ltima', '√∫ltimas', '√∫ltimo', '√∫ltimos', 'vai', 'v√£o', 'v√°rios',
            'v√°rias', 'ver', 'vez', 'vezes', 'vindo', 'vir', 'sobre', 'sob', 'sendo', 'sido',
            'tendo', 'tendo', 'partir', 'atrav√©s', 'apenas', 'alguns', 'algumas', 'algum', 'alguma',
            'algo', 'aqui', 'ali', 'a√≠', 'l√°', 'c√°', 'lhe', 'lhes', 'me', 'mim', 'nos', 'vos',
            'si', 'consigo', 'comigo', 'contigo', 'conosco', 'convosco'
        }
        NLP_AVAILABLE = True

    # Tentar importar SPACY para an√°lise gramatical mais robusta (Substantivos/Adjetivos)
    try:
        import spacy
        try:
            # Tenta carregar modelo pequeno para portugu√™s
            nlp_spacy = spacy.load("pt_core_news_sm")
            SPACY_AVAILABLE = True
        except OSError:
            # Tenta baixar se n√£o encontrar e carrega novamente
            from spacy.cli import download
            download("pt_core_news_sm")
            nlp_spacy = spacy.load("pt_core_news_sm")
            SPACY_AVAILABLE = True
    except Exception:
        SPACY_AVAILABLE = False
        nlp_spacy = None
        
except Exception:
    NLP_AVAILABLE = False
    STOP_WORDS_PT = set()
    SPACY_AVAILABLE = False

# ==========================================
# CONSTANTES GLOBAIS
# ==========================================
ORDEM_SIBILA = ["0", "1", "2", "3", "4", "5", "6", "7", "8-9", "10", "11", "12"]

# ==========================================
# 1. CONFIGURA√á√ÉO E ESTILO
# ==========================================

st.set_page_config(
    page_title="SISTEMA NELIC - SIBILA",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Vocabul√°rio Controlado e Metodologia (agora em um m√≥dulo de dados)
# (Dados movidos para dentro da classe DataModule para encapsulamento)
# Tipos textuais que N√ÉO exigem resumo anal√≠tico
# Tipos textuais que N√ÉO exigem resumo anal√≠tico
TIPOS_SEM_RESUMO = {"POEMA", "POEMA(S)", "FIC√á√ÉO", "CAPA", "IMAGEM", "HQ/CHARGE", "HQ", "CHARGE", "ARTES PL√ÅSTICAS"}

# Mapeamento de Autores Can√¥nicos (Normaliza√ß√£o de Nomes)
CANONICAL_AUTHORS = {
    # BACH
    "BACH": "BACH, Johann Sebastian",
    "BACH, J. S.": "BACH, Johann Sebastian",
    "BACH, Johann S.": "BACH, Johann Sebastian",
    
    # NOVAS REGRAS
    "ADORNO, Theodor": "ADORNO, Theodor W.",
    "ALIGHIERI, DANTE": "ALIGHIERI, Dante",
    "ALLEN, Donald": "ALLEN, Donald M.",
    "ALVIM, Chico": "ALVIM, Francisco",
    "ARA√öJO, Lais Corr√™a de": "ARA√öJO, La√≠s Corr√™a de",
    "ARIST√ìTELES, Arist√≥teles": "ARIST√ìTELES",
    "BALL": "BALL, Hugo",
    "BUENO": "BUENO, Wilson",
    "BYRON": "BYRON, Lord",
    "CABRAL, Jo√£o": "CABRAL, Jo√£o (de Melo Neto)",
    "CABRAL, Jo√£o (Melo Neto)": "CABRAL, Jo√£o (de Melo Neto)",
    "CAM√ïES, Lu√≠s de": "CAM√ïES, Lu√≠s Vaz de",
    "CAYMMI, Dori": "CAYMMI, Dorival",
    "CHOPIN, Fryderyk": "CHOPIN, Fr√©d√©ric",
    "CLARK, L√≠gia": "CLARK, Lygia",
    "CORBUSIER, LE": "CORBUSIER, Le",
    "CRISTOBO, Anibal": "CRISTOBO, An√≠bal",
    "CUMMINGS, E. E.": "CUMMINGS, e. e.",
    "CUMMINGS, e.e.": "CUMMINGS, e. e.",
    "DAO, BEI": "DAO, Bei",
    "DICK, Andr√©": "DICK, Andr√© Henrique",
    "DOLHNIKOFF, Lu√≠s": "DOLHNIKOFF, Luis",
    
    # NOVAS REGRAS (LOTE 2)
    "DRUMMOND, Carlos": "DRUMMOND, Carlos (de Andrade)",
    "DRUMMOND, Drummond": "DRUMMOND, Carlos (de Andrade)",
    "ANDRADE, Carlos Drummond de": "DRUMMOND, Carlos (de Andrade)",
    "DUFR√äNE": "DUFR√äNE, Fran√ßois",
    "EISENSTEIN, Sergei": "EISENSTEIN, Sergei M.",
    "ELIOT, T.S.": "ELIOT, T. S.",
    "FERRARI, L√©on": "FERRARI, Le√≥n",
    "FERREIRA": "FERREIRA, Evandro Affonso",
    "FONTANA": "FONTANA, Lucio",
    "FROTA": "FROTA, Eduardo",
    "GIL": "GIL, Gilberto",
    "GOETHE": "GOETHE, Johann Wolfgang von",
    "GOLDSMITH, Kenny": "GOLDSMITH, Kenneth",

    # NOVAS REGRAS (LOTE 3)
    "GUIMAR√ÉES, J√∫lio C.": "GUIMAR√ÉES, J√∫lio Casta√±on",
    "HOLLANDA, Heloisa Buarque de": "HOLLANDA, Helo√≠sa Buarque de",
    "JOBIM, Tom": "JOBIM, Ant√¥nio Carlos",
    "JOHNSON": "JOHNSON, Robert",
    "JOYCE": "JOYCE, James",
    "KHLI√âBNIKOV, Viel√≠mir": "KHLI√âBNIKOV, Velimir",
    "KHL√âBNIKOV, Velimir": "KHLI√âBNIKOV, Velimir",
    "KHL√âBNIKOV, Vel√≠mir": "KHLI√âBNIKOV, Velimir",
    "KOZER, Jos": "KOZER, Jos√©",
    "KOZER, Jose": "KOZER, Jos√©",
    "LAUTR√âAMONT": "LAUTR√âAMONT, Conde de",
    "LEITE, Sebasti√£o Uch√¥a": "LEITE, Sebasti√£o Uchoa",
    "LIMA, Manoel Ricardo": "LIMA, Manoel Ricardo de",
    "MAIAK√ìVSKI": "MAIAK√ìVSKI, Vlad√≠mir",
    "MAIAK√ìVSKI, Vladimir": "MAIAK√ìVSKI, Vlad√≠mir",
    "MANDELSTAM, √ìssip": "MANDELSTAM, Osip",
    "MORAES, Vin√≠cius de": "MORAES, Vinicius de",
    "MORAIS, Vin√≠cius de": "MORAES, Vinicius de",
    "MOURA, Antonio": "MOURA, Ant√¥nio",
    "M√ÉE, Valter Hugo": "M√ÉE, valter hugo",
    "NEZVAL, Vitezlav": "NEZVAL, V√≠tƒõzslav",
    "PASTERNAK": "PASTERNAK, Boris",
    "PETRARCA": "PETRARCA, Francesco",
    "PLAZA, J√∫lio": "PLAZA, Julio",
    
    # NOVAS REGRAS (LOTE 4)
    "PUSHKIN": "PUSHKIN, Alexander",
    "RODR√çGUEZ, Am√©rico": "RODRIGUES, Am√©rico",
    "ROQUETTE-PINTO, Cl√°udia": "ROQUETTE-PINTO, Claudia",
    "ROSA, Guimar√£es": "ROSA, Jo√£o Guimar√£es",
    "ROSA, Mario Alex": "ROSA, M√°rio Alex",
    "ROTHENBERG, Gerome": "ROTHENBERG, Jerome",
    "SABINSON, Eric": "SABINSON, Eric Mitchell",
    "SALOM√ÉO, Wally": "SALOM√ÉO, Waly",
    "SALVINO, R√¥mullo Valle": "SALVINO, Romulo Valle",
    "SOSA, V√≠ctor": "SOSA, Victor",
    "SOUS√ÇNDRADE, Joaquim de": "SOUS√ÇNDRADE",
    "SOUS√ÇNDRADE, Joaquim de Sousa Andrade": "SOUS√ÇNDRADE",
    "VICU√ëA, Cec√≠lia": "VICU√ëA, Cecilia",
    "WARCHAVCHIK, Gregorio": "WARCHAVCHIK, Gregori",
    "WEBERN, Anton von": "WEBERN, Anton",
    "WOOLF, Virg√≠nia": "WOOLF, Virginia",
    "XAVIER": "XAVIER, Val√™ncio",
    "√ÅVILA, Afonso": "√ÅVILA, Affonso",
}

# Caminhos de arquivos
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FILE_PATH = os.path.join(BASE_DIR, 'catalogo_sibila.json')
DIARIO_PATH = os.path.join(BASE_DIR, 'diario_sibila.json')
BACKUP_DIR = os.path.join(BASE_DIR, 'backups')
LOGO_PATH = os.path.join(BASE_DIR, 'NELIC.png')  # Arquivo de Logo

# Estilos CSS
CSS_STYLES = """
<style>
.main { 
    background: radial-gradient(circle at top left, #f5f7fb 0%, #f1f3f5 40%, #eceff1 100%);
    padding-top: 1rem;
}
.block-container {
    padding-top: 2.2rem;
    max-width: 1300px;
}
.stDeployButton {display: none !important;}
#MainMenu {visibility: hidden !important;}
footer {visibility: hidden !important;}
.viewerBadge_container__1QSob {display: none !important;}
.styles_viewerBadge__1yB5_ {display: none !important;}
h1 {
    color: #1f2933;
    font-weight: 800 !important;
    text-transform: uppercase;
    border-bottom: 3px solid #2f5f98;
    padding-bottom: 10px;
    margin-bottom: 20px;
    font-size: 2rem !important;
    letter-spacing: 1px;
}
h2, h3, h4 { 
    color: #243b53;
    text-transform: uppercase;
    font-weight: 700;
    margin-top: 1.5rem;
    letter-spacing: 0.06em;
}
/* ===== SIDEBAR - FUNDO BRANCO LIMPO ===== */
[data-testid="stSidebar"] {
    background-color: #ffffff !important;
    border-right: 1px solid #e0e0e0;
}

[data-testid="stSidebar"] > div {
    padding-top: 1.5rem;
}

/* Texto da sidebar em azul escuro */
[data-testid="stSidebar"] h1,
[data-testid="stSidebar"] h2,
[data-testid="stSidebar"] h3,
[data-testid="stSidebar"] h4,
[data-testid="stSidebar"] h5,
[data-testid="stSidebar"] h6,
[data-testid="stSidebar"] p,
[data-testid="stSidebar"] label,
[data-testid="stSidebar"] .stMarkdown {
    color: #366092 !important;
}

/* LOGO: Sem invers√£o para fundo branco */
[data-testid="stSidebar"] img {
    filter: none;
    opacity: 1;
}

/* Input de senha - estilo para fundo branco */
[data-testid="stSidebar"] input {
    background-color: #f8f9fa !important;
    color: #366092 !important;
    border: 1px solid #d0d7de !important;
}

[data-testid="stSidebar"] input::placeholder {
    color: #8a9ab0 !important;
}

/* Alinhamento do tooltip (?) ao lado do label */
[data-testid="stSidebar"] label {
    display: flex !important;
    align-items: center !important;
    gap: 0.25rem !important;
}

[data-testid="stSidebar"] .stTooltipIcon {
    margin-left: 0 !important;
    vertical-align: middle !important;
}

.stButton > button, .stDownloadButton > button {
    border-radius: 999px;
    font-weight: 600;
    text-transform: uppercase;
    width: 100%;
    transition: all 0.25s ease;
    border: 1px solid #2f5f98;
    background-color: #2f5f98;
    color: white;
    letter-spacing: 0.06em;
    font-size: 0.78rem;
}
.stButton > button:hover, .stDownloadButton > button:hover {
    transform: translateY(-1px);
    box-shadow: 0 8px 18px rgba(15, 23, 42, 0.18);
    background-color: #23466f;
    border-color: #23466f;
}
.stTextArea textarea {
    font-family: 'Georgia', 'Times New Roman', serif;
    font-size: 0.95rem;
    line-height: 1.6;
    border-radius: 6px;
    padding: 0.75rem;
}
.stTextInput input {
    font-family: 'Georgia', 'Times New Roman', serif;
    font-size: 0.95rem;
    line-height: 1.5;
}
.nelic-card {
    border-radius: 14px;
    padding: 1.1rem 1.2rem;
    margin-bottom: 0.8rem;
    background: #ffffff;
    border: 1px solid rgba(148, 163, 184, 0.35);
    box-shadow: 0 8 20px rgba(15, 23, 42, 0.04);
}
.nelic-card-header {
    font-weight: 700;
    color: #1f2933;
    margin-bottom: 0.35rem;
    font-size: 0.92rem;
    text-transform: uppercase;
    letter-spacing: 0.06em;
}
.nelic-card-subtitle {
    color: #62748a;
    font-size: 0.8rem;
    margin-bottom: 0.35rem;
}
.nelic-tag {
    display: inline-block;
    padding: 0.15rem 0.55rem;
    margin-right: 0.3rem;
    margin-bottom: 0.3rem;
    border-radius: 999px;
    background-color: #e3edff;
    color: #243b53;
    font-size: 0.72rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.06em;
}
.nelic-tag-muted {
    background-color: #e5e7eb;
    color: #4b5563;
}
.nelic-muted {
    color: #6b7b93;
    font-size: 0.8rem;
}
div[data-testid="stMetricValue"] {
    font-size: 1.8rem;
    font-weight: 700;
    color: #1f2933;
}
div[data-testid="stMetricLabel"] {
    font-size: 0.78rem;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    color: #6b7b93;
}
div[data-testid="stDataFrame"] {
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 8 18px rgba(15, 23, 42, 0.06);
    background-color: white;
}
button[data-baseweb="tab"] {
    font-size: 0.78rem !important;
    text-transform: uppercase;
    letter-spacing: 0.08em;
}
.info-box {
    background-color: #e3f2fd;
    border-left: 4px solid #2f5f98;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}
.warning-box {
    background-color: #fff3e0;
    border-left: 4px solid #ff9800;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}
.success-box {
    background-color: #e8f5e9;
    border-left: 4px solid #4caf50;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}
/* Estilos Metodologia S√≥bria */
.metod-section {
    background: #f9fafb;
    padding: 1.5rem;
    border-radius: 8px;
    margin-bottom: 1.5rem;
    border: 1px solid #e5e7eb;
}
.metod-section h4 {
    color: #374151;
    font-size: 1.05rem;
    font-weight: 700;
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid #d1d5db;
}
.metod-section p, .metod-section li {
    color: #4b5563;
    font-size: 0.95rem;
    line-height: 1.7;
}
.metod-section ul {
    margin: 0.75rem 0;
    padding-left: 1.5rem;
}
.metod-section li {
    margin-bottom: 0.5rem;
}
.metod-section strong {
    color: #1f2937;
    font-weight: 600;
}
</style>
"""

st.markdown(CSS_STYLES, unsafe_allow_html=True)

# ==========================================
# 2. CLASSES E M√ìDULOS
# ==========================================

class DataModule:
    """Encapsula dados est√°ticos e fun√ß√µes de normaliza√ß√£o."""
    LISTA_PALAVRAS_CHAVE = sorted(list(set([x.title() for x in [
        "Absurdo", "Adolesc√™ncia", "√Åfrica", "Agricultura", "Alegoria", "Alemanha", "Alimenta√ß√£o", "Amaz√¥nia",
        "Ambival√™ncia", "Am√©rica", "Am√©rica Latina", "Amor", "An√°lise Do Discurso", "Anarquismo", "Antiguidade",
        "Antologia", "Antropologia", "Argentina", "Arqueologia", "Arquitetura", "Arte",
        "Arte Gr√°fica", "Artes Pl√°sticas", "Artesanato", "Astrologia", "√Åustria", "Autonomia", "Autoria",
        "Autoritarismo", "Barroco", "Best Seller", "B√≠blia", "Biblioteca", "Biografia", "Biologia", "Bossa Nova",
        "Brasil", "Bruxaria", "Burguesia", "C√¢mbio", "C√¢none Liter√°rio", "Capitalismo", "Caricatura", "Carnaval",
        "Cartas", "Casamento", "Catolicismo", "Censura", "Chanchada", "Chile", "China", "Cidade", "Ci√™ncia",
        "Cinema", "Cinema Novo", "Classe", "Classe M√©dia", "Colonialismo", "Com√©dia", "C√¥mico", "Compet√™ncia",
        "Comportamento", "Compromisso", "Comunica√ß√£o", "Comunismo", "Coloniza√ß√£o", "Concretismo", "Concurso",
        "Consumo", "Contempor√¢neo", "Conto", "Contra Cultura", "Cren√ßas Populares", "Cria√ß√£o", "Crise",
        "Cr√≠tica", "Cr√¥nica", "Cuba", "Cultura", "Cultura Alternativa", "Cultura Popular", "Dada√≠smo", "Dan√ßa",
        "D√©cada De 20", "D√©cada De 30", "D√©cada De 40", "D√©cada De 50", "D√©cada De 60", "D√©cada De 70",
        "D√©cada De 80", "D√©cada De 90", "Democracia", "Demografia", "Descoloniza√ß√£o", "Desconhecimento",
        "Desconstru√ß√£o", "Design", "Despotismo", "Dial√©tica", "Direito", "Direitos Autorais", "Discos",
        "Discrimina√ß√£o", "Discurso", "Ditadura", "Document√°rio", "Drama", "Dramaturgia", "Drogas", "Ecletismo",
        "Ecologia", "Economia", "Editor", "Educa√ß√£o", "Efem√©ride", "Elite", "Enciclopedismo", "Energia",
        "Engajamento Pol√≠tico", "Ensaio", "Ensino", "Entretenimento", "Epistemologia", "Erotismo",
        "Escola De Frankfurt", "Escravid√£o", "Escritor", "Escritura", "Escultura", "Exoterismo", "Espa√ßo",
        "Espanha", "Esporte", "Estado", "Estado Novo", "Estados Unidos", "Est√©tica", "Estrutura",
        "Estruturalismo", "√âtica", "Etnografia", "Etno-hist√≥ria", "Etnologia", "Europa", "Eventos",
        "Existencialismo", "Experimentalismo", "Expressionismo", "Fant√°stico", "Fascismo", "Feminismo",
        "Fenomenologia", "Fic√ß√£o", "Fic√ß√£o Cient√≠fica", "Filologia", "Filosofia", "F√≠sica", "Folclore",
        "Folhetim", "Formalismo", "Fotografia", "Fran√ßa", "Funcionalismo", "Futebol", "Futurismo", "Genealogia",
        "G√™nero", "Geografia", "Gera√ß√£o De 45", "Gera√ß√£o Marginal", "Globaliza√ß√£o", "Golpe Militar", "Grafite",
        "Gram√°tica", "Guerra", "Guerra Fria", "Hermen√™utica", "Her√≥i", "Heterogeneidade", "Hispano-Am√©rica",
        "Hist√≥ria", "Hist√≥ria Do Brasil", "Hist√≥ria Em Quadrinhos", "Historiografia", "Homossexualidade",
        "Humanismo", "Humor", "Idade M√©dia", "Idealiza√ß√£o", "Identidade", "Ideograma", "Ideologia", "Idioma",
        "Igreja", "Iluminismo", "Imagem", "Imagina√ß√£o", "Imigra√ß√£o", "Imperialismo", "Imprensa",
        "Imprensa Alternativa", "Impressionismo", "Inconfid√™ncia Mineira", "Inconsciente", "Independ√™ncia",
        "√çndia", "Indianismo", "√çndio", "Ind√∫stria Cultural", "Industrializa√ß√£o", "Inf√¢ncia", "Inform√°tica",
        "Informes", "Inglaterra", "Institui√ß√µes", "Intelectual", "Interdisciplinar", "Intelectualidade",
        "Inven√ß√£o", "Ironia", "It√°lia", "Jap√£o", "Jazz", "Jornalismo", "Juda√≠smo", "Justi√ßa", "Kitsch", "Leitor",
        "Liberalismo", "Liberdade", "L√≠ngua", "L√≠ngua Inglesa", "L√≠ngua Portuguesa", "Linguagem", "Lingu√≠stica",
        "L√≠rico", "Lirismo", "Literatura", "Literatura Comparada", "Literatura De Cordel",
        "Literatura Infanto-juvenil", "Literatura Policial", "Livro Did√°tico", "Livros", "L√≥gica", "Loucura",
        "Luta De Classes", "Magia", "Mais-valia", "Manifesto", "Marginalidade", "Marxismo", "Matem√°tica",
        "Mato Grosso", "Medicina", "Mem√≥ria", "Mercado", "Mercado Editorial", "Mercado Fonogr√°fico",
        "Metaf√≠sica", "Met√°fora", "Metalinguagem", "Metodologia De Pesquisa", "M√©trica", "M√©xico", "M√≠dia",
        "Mimesis", "Minas Gerais", "Minoria Sociais", "Misticismo", "Mito", "Mitologia", "Moda", "Modernidade",
        "Modernismo", "Monarquia", "Monop√≥lio", "Moral", "Morte", "Movimento", "Movimento Ideol√≥gico", "MPB",
        "Mulher", "Museu", "M√∫sica", "M√∫sica Erudita", "M√∫sica Popular", "Na√ß√£o", "Nacionalismo", "Narrador",
        "Narrativa", "Naturalismo", "Natureza", "Nazismo", "Negros", "Neoconcretismo", "Neurologia", "Nordeste",
        "Nova Rep√∫blica", "Novela", "Obra", "Obra De Arte", "Ocidente", "Oligarquia", "Ontologia", "√ìpera",
        "Oralidade", "Oriente", "Origem", "Originalidade", "Paran√°", "Parnasianismo", "Par√≥dia",
        "Partido Comunista", "Pastiche", "Patrim√¥nio Cultural", "Pedagogia", "Periferia", "Periodismo",
        "Peronismo", "Personagem", "Pintura", "Pl√°gio", "Pluralismo", "Poder", "Poema √âpico", "Poema Processo",
        "Poema Visual", "Poesia Marginal", "Poesia", "Po√©tica", "Pol√™mica", "Pol√≠cia", "Polifonia", "Pol√≠tica",
        "Pol√¥nia", "Pop Art", "Populismo", "Pornografia", "Portugal", "P√≥s-estruturalismo", "Positivismo",
        "P√≥s-modernidade", "P√≥s Modernismo", "Pr√© Hist√≥ria", "Pr√™mio", "Premio Nobel", "Privatiza√ß√µes",
        "Proletariado", "Prostitui√ß√£o", "Proto-s√°tira", "Psican√°lise", "Psicologia", "Psicoterapia",
        "Psiquiatria", "Publicidade", "Qu√≠mica", "Racismo", "R√°dio", "Raz√£o", "Rea√ß√£o", "Ready-made", "Realismo",
        "Realismo Fant√°stico", "Realismo M√°gico", "Rebeldia", "Reforma Agr√°ria", "Regime Pol√≠tico",
        "Regionalismo", "Rela√ß√µes Internacionais", "Rela√ß√µes Raciais", "Rela√ß√µes Sociais", "Relato", "Religi√£o",
        "Renascimento", "Reportagem", "Representa√ß√£o", "Repress√£o", "Rep√∫blica", "Rep√∫blica Velha", "Ret√≥rica",
        "Revolu√ß√£o", "Revolu√ß√£o De 1930", "Revolu√ß√£o Francesa", "Revolu√ß√£o Industrial", "Rio De Janeiro",
        "Rio Grande Do Sul", "Rito", "Rock And Roll", "Romance", "Romantismo", "Ruptura", "R√∫ssia", "Samba",
        "S√£o Paulo", "S√°tira", "Sa√∫de", "SBPC", "S√©culo XIX", "S√©culo XVI", "S√©culo XVII", "S√©culo XVIII",
        "S√©culo XX", "S√©culo XXI", "Semana De Arte Moderna", "Sem√¢ntica", "Semiologia", "Semi√≥tica", "Servilismo",
        "Sexualidade", "Sil√™ncio", "Simbolismo", "Simbologia", "Sindicalismo", "S√≠nteses", "Socialismo",
        "Sociedade", "Sociedade Industrial", "Sociologia", "Solid√£o", "Stalinismo", "Subdesenvolvimento",
        "Sujeito", "Surrealismo", "Tatuagem", "Teatro", "T√©cnica", "Tecnocracia", "Tecnologia", "Telespectador",
        "Televis√£o", "Tempo", "Teologia", "Teoria", "Teoria Da Linguagem", "Teoria Liter√°ria", "Teoria Social",
        "Terrorismo", "Texto", "Tortura", "Trabalho", "Tradi√ß√£o", "Tradu√ß√£o", "Trag√©dia", "Trai√ß√£o",
        "Transgress√£o", "Tropicalismo", "Umbanda", "Underground", "Unidade", "Universalidade", "Universidade",
        "Urbanismo", "URSS", "Uruguai", "Utopia", "Vanguarda", "Verdade", "Vestibular", "Viagem", "Viol√™ncia"
    ]])))

    LISTA_ICONOGRAFIA = [
        "Cartografia", "Fac-s√≠mile", "Foto", "Fotograma", "Gr√°fico/Tabela",
        "HQ/Charge", "Ilustra√ß√£o", "Publicidade", "Reprodu√ß√£o"
    ]

    # Refer√™ncia ao dicion√°rio global para acesso dentro da classe se necess√°rio
    CANONICAL_AUTHORS = CANONICAL_AUTHORS

    TIPOS_TEXTUAIS = {
        "APRESENTA√á√ÉO": ["Sem especifica√ß√£o", "Literatura"],
        "ARTES PL√ÅSTICAS": ["Sem especifica√ß√£o"],
        "CAPA": ["Sem especifica√ß√£o"],
        "CARTAS DO LEITOR": ["Sem especifica√ß√£o"],
        "CHARGE": ["Sem especifica√ß√£o"],
        "CORRESPOND√äNCIA(S)": ["Sem especifica√ß√£o"],
        "DEBATE": ["Sem especifica√ß√£o"],
        "DEPOIMENTO": ["Sem especifica√ß√£o", "Literatura"],
        "EDITORIAL": ["Sem especifica√ß√£o", "Literatura"],
        "ENSAIO": [
            "Sem especifica√ß√£o", "Antropologia", "Arquitetura", "Bibliologia", "Ci√™ncia",
            "Comunica√ß√£o", "Cultura", "Economia", "Educa√ß√£o", "Esporte", "Filosofia",
            "Fotogr√°fico", "Hist√≥ria", "Lingu√≠stica", "Literatura", "Pol√≠tica",
            "Psican√°lise", "Psicologia", "Sociologia", "Teologia"
        ],
        "ENTREVISTA": ["Sem especifica√ß√£o", "Literatura"],
        "FIC√á√ÉO": ["Sem especifica√ß√£o"],
        "HQ": ["Sem especifica√ß√£o"],
        "HQ/CHARGE": ["Sem especifica√ß√£o"],
        "INFORME": ["Sem especifica√ß√£o", "Literatura"],
        "POEMA(S)": ["Sem especifica√ß√£o"],
        "REPORTAGEM": ["Sem especifica√ß√£o", "Literatura"],
        "RESENHA": [
            "Sem especifica√ß√£o", "Antropologia", "Arquitetura", "Bibliologia", "Ci√™ncia",
            "Comunica√ß√£o", "Cultura", "Economia", "Educa√ß√£o", "Filosofia", "Hist√≥ria",
            "Lingu√≠stica", "Literatura", "Pol√≠tica", "Psican√°lise", "Psicologia", "Sociologia"
        ],
        "VARIEDADES": ["Sem especifica√ß√£o"]
    }

    @staticmethod
    def normalizar_texto(val: str | list) -> str | list:
        """Normaliza texto gen√©rico (palavras-chave etc.) para Title Case."""
        if isinstance(val, list):
            return [i.strip().title() for i in val if str(i).strip()]
        if isinstance(val, str):
            return val.strip().title()
        return val

    @staticmethod
    def format_nome_abnt(nome: str | None) -> str:
        """
        Normaliza nomes pessoais segundo ABNT.
        Ex.: 'Bonvicino, R√©gis' -> 'BONVICINO, R√©gis'
        """
        if nome is None:
            return ""
        if not isinstance(nome, str):
            nome = str(nome)
        
        # 0. Verifica√ß√£o de Autores Can√¥nicos (Normaliza√ß√£o pr√©via)
        # Verifica se o nome exato (ou variante simples) est√° na lista
        if nome.strip() in DataModule.CANONICAL_AUTHORS:
             return DataModule.CANONICAL_AUTHORS[nome.strip()]
        
        # Verifica tamb√©m se variantes comuns est√£o na lista (ex: "Bach" -> "BACH, Johann Sebastian")
        # Mas cuidado para n√£o pegar substrings indevidas. Aqui verifica match exato da string limpa.
        
        s = " ".join(nome.strip().split())
        
        # Check again with standardized spacing
        if s in DataModule.CANONICAL_AUTHORS:
             return DataModule.CANONICAL_AUTHORS[s]

        if not s:
            return ""
        if "," in s:
            ult, resto = s.split(",", 1)
            return f"{ult.strip().upper()}, {resto.strip()}" if resto.strip() else ult.strip().upper()
        partes = s.split()
        if len(partes) >= 2:
            sobrenome = partes[-1].upper()
            prenomes = " ".join(partes[:-1])
            return f"{sobrenome}, {prenomes}"
        return s.upper()

    @staticmethod
    def parse_multiline(texto: str | None) -> list[str]:
        if texto is None:
            return []
        if not isinstance(texto, str):
            texto = str(texto)
        # Split only on newlines to preserve commas in ABNT format names
        linhas = texto.split('\n')
        return [l.strip() for l in linhas if l.strip()]

    @staticmethod
    def normalizar_lista_autores(texto: str | list) -> list[str]:
        nomes = DataModule.parse_multiline(texto)
        return [DataModule.format_nome_abnt(n) for n in nomes]

    @staticmethod
    def get_normalized_series(df: pd.DataFrame, col: str) -> pd.Series:
        """
        Explode coluna, remove vazios. Para campos de autor, aplica formata√ß√£o ABNT
        sem rebaixar para Title Case (preserva SOBRENOME em CAIXA ALTA).
        """
        if col not in df.columns:
            return pd.Series(dtype='object')
        s = (
            df.explode(col)[col]
            .dropna()
            .astype(str)
            .str.strip()
            .replace('', pd.NA)
            .dropna()
        )
        if col in {'autores_colaboradores', 'autores_citados', 'tradutores', 'entidade_coletiva', 'nome_pessoal_como_assunto'}:
            s = s.apply(DataModule.format_nome_abnt)
        return s

# ==========================================
# FUN√á√ÉO DE ROTA√á√ÉO DE BACKUPS
# ==========================================

def limpar_backups_antigos(diretorio, manter=3):
    """
    Remove backups antigos, mantendo apenas os N mais recentes.

    Args:
        diretorio: Caminho do diret√≥rio de backups
        manter: N√∫mero de backups mais recentes a manter (padr√£o: 3)
    """
    try:
        if not os.path.exists(diretorio):
            return

        # Listar todos os arquivos de backup
        backups = []
        for arquivo in os.listdir(diretorio):
            caminho_completo = os.path.join(diretorio, arquivo)
            if os.path.isfile(caminho_completo):
                # Obter tempo de cria√ß√£o do arquivo
                tempo_criacao = os.path.getctime(caminho_completo)
                backups.append((tempo_criacao, caminho_completo, arquivo))

        # Ordenar por data de cria√ß√£o (mais recente primeiro)
        backups.sort(reverse=True, key=lambda x: x[0])

        # Se houver mais de N backups, apagar os antigos
        if len(backups) > manter:
            for _, caminho, nome in backups[manter:]:
                try:
                    os.remove(caminho)
                except Exception as e:
                    print(f"Erro ao remover backup {nome}: {e}")

    except Exception as e:
        print(f"Erro na limpeza de backups: {e}")

class PersistenceModule:
    """Encapsula fun√ß√µes de carregamento e salvamento de dados."""
    @staticmethod
    @st.cache_data(ttl=60)
    def load_data():
        if not os.path.exists(FILE_PATH):
            return []
        try:
            with open(FILE_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erro ao carregar dados: {str(e)}")
            return []

    @staticmethod
    def save_data(data):
        try:
            if os.path.exists(FILE_PATH):
                if not os.path.exists(BACKUP_DIR):
                    os.makedirs(BACKUP_DIR)
                bkp = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                with open(FILE_PATH, 'r', encoding='utf-8') as f:
                    with open(os.path.join(BACKUP_DIR, bkp), 'w', encoding='utf-8') as b:
                        json.dump(json.load(f), b, ensure_ascii=False, indent=2)
                # Limpar backups antigos, mantendo apenas os 3 mais recentes
                limpar_backups_antigos(BACKUP_DIR, manter=3)
            with open(FILE_PATH, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            PersistenceModule.load_data.clear()
            return True
        except Exception as e:
            st.error(f"Erro ao salvar dados: {str(e)}")
            return False

    @staticmethod
    def load_diario():
        if not os.path.exists(DIARIO_PATH):
            return []
        try:
            with open(DIARIO_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Erro ao carregar di√°rio: {str(e)}")
            return []

    @staticmethod
    def save_diario(entries):
        try:
            with open(DIARIO_PATH, 'w', encoding='utf-8') as f:
                json.dump(entries, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            st.error(f"Erro ao salvar di√°rio: {str(e)}")
            return False

class PDFModule:
    """Encapsula fun√ß√µes de gera√ß√£o de PDF."""
    @staticmethod
    def to_latin1(texto):
        if texto is None:
            return ""
        if not isinstance(texto, str):
            texto = str(texto)
        # Mapa de substitui√ß√£o de caracteres problem√°ticos
        replacements = {
            '\u201c': '"',  # Aspas duplas esquerda
            '\u201d': '"',  # Aspas duplas direita
            '\u2018': "'",  # Aspas simples esquerda
            '\u2019': "'",  # Aspas simples direita
            '\u2013': '-',  # Tra√ßo m√©dio
            '\u2014': '-',  # Travess√£o
            '\u2022': '*'   # Bullet point
        }
        for char, repl in replacements.items():
            texto = texto.replace(char, repl)
        
        return texto.encode('latin-1', 'replace').decode('latin-1')

    @staticmethod
    def add_nelic_logo_to_pdf(pdf):
        if os.path.exists(LOGO_PATH):
            try:
                # Logo fixo na direita (x=175, y=8, w=25)
                pdf.image(LOGO_PATH, x=175, y=8, w=25, h=0)
            except Exception:
                pass

    @staticmethod
    def _add_standard_header(pdf, title):
        """
        Cabe√ßalho Padr√£o (Global):
        - Logo: Canto superior direito (via add_nelic_logo_to_pdf)
        - T√≠tulo: Alinhado √† ESQUERDA, negrito, largura controlada.
        - Data: Alinhada √† ESQUERDA, abaixo do t√≠tulo.
        - Linha Divis√≥ria: Obrigat√≥ria.
        """
        PDFModule.add_nelic_logo_to_pdf(pdf)
        
        # T√≠tulo
        pdf.set_xy(10, 10) # Texto come√ßa na esquerda, alinhado ao topo visual do logo
        pdf.set_font("Arial", 'B', 14)
        # Limpeza: Remover prefixos se existirem, embora o ideal seja passar o t√≠tulo limpo
        clean_title = title.replace("ESTAT√çSTICAS - ", "").upper()
        
        # Largura controlada (160) para n√£o cobrir o logo (x=175)
        pdf.multi_cell(160, 8, PDFModule.to_latin1(clean_title), align='L')
        
        # Data
        pdf.set_font("Arial", 'I', 10)
        pdf.set_x(10)
        pdf.cell(160, 6, PDFModule.to_latin1(f"Emiss√£o: {datetime.now().strftime('%d/%m/%Y')}"), ln=True, align='L')
        
        # Linha Divis√≥ria
        # Garante que a linha fique abaixo do texto E do logo (assumindo logo h~25mm -> y_end ~33mm)
        y_line = max(pdf.get_y() + 2, 35)
        pdf.line(10, y_line, 200, y_line)
        pdf.set_y(y_line + 5)

    @staticmethod
    def gerar_pdf_analitico(df, total, crit):
        """Relat√≥rio anal√≠tico gen√©rico (lista de registros) com % na base."""
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule._add_standard_header(pdf, "RELAT√ìRIO ANAL√çTICO - PROJETO SIBILA")
            
            pdf.set_y(pdf.get_y() + 5)
            pdf.set_y(40)
            pdf.set_fill_color(240, 240, 240)
            pdf.rect(10, 45, 190, 25, 'F')
            pdf.set_y(48)
            pdf.set_x(15)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Crit√©rio: {crit}"), ln=True)
            pdf.set_x(15)
            pdf.set_font("Arial", '', 11)
            qtd = len(df)
            pct = (qtd / total * 100) if total > 0 else 0
            pdf.cell(0, 6, PDFModule.to_latin1(f"Registros encontrados: {qtd} de {total} (total da base)"), ln=True)
            pdf.set_x(15)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Percentual da base total: {pct:.2f}%"), ln=True)
            pdf.ln(15)
            for _, r in df.iterrows():
                if pdf.get_y() > 250:
                    pdf.add_page()
                try:
                    tit = PDFModule.to_latin1(r.get('titulo_artigo', ''))
                    tip = PDFModule.to_latin1(r.get('vocabulario_controlado', ''))
                    rev = PDFModule.to_latin1(r.get('n', ''))
                    # Limpeza de p√°ginas para evitar "p. p."
                    raw_pag = str(r.get('paginas', '')).replace('pp.', '').replace('p.', '').strip()
                    pags = PDFModule.to_latin1(raw_pag)
                    pdf.set_font("Arial", 'B', 11)
                    pdf.multi_cell(0, 6, f"[{tip}] REVISTA {rev} / p. {pags}")
                    if tit:
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, tit)
                    aut = r.get('autores_colaboradores', [])
                    if aut:
                        if isinstance(aut, list):
                            s_aut = ', '.join([DataModule.format_nome_abnt(a) for a in aut if a])
                        else:
                            s_aut = DataModule.format_nome_abnt(aut)
                        s_aut = PDFModule.to_latin1(s_aut)
                        # Bloco de autores: R√≥tulo em Negrito, conte√∫do Normal
                        pdf.set_font("Arial", 'B', 10)
                        pdf.write(5, PDFModule.to_latin1("Autores: "))
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, s_aut)
                    nota_ed = r.get('nota_edicao', '')
                    if nota_ed:
                        ne = PDFModule.to_latin1(nota_ed)
                        pdf.set_font("Arial", 'I', 9)
                        pdf.multi_cell(0, 5, f"Nota de edi√ß√£o: {ne}")
                    icons = r.get('iconografias', [])
                    if isinstance(icons, list) and icons:
                        icon_txt = []
                        for ic in icons:
                            t = ic.get('tipo', '')
                            d = ic.get('descricao', '')
                            if t or d:
                                icon_txt.append(f"{t}: {d}")
                        if icon_txt:
                            s_icon = PDFModule.to_latin1(" | ".join(icon_txt))
                            pdf.set_font("Arial", 'I', 9)
                            pdf.set_text_color(100, 100, 100)
                            pdf.multi_cell(0, 5, f"[Iconografia]: {s_icon}")
                            pdf.set_text_color(0, 0, 0)
                    res = r.get('resumo', '')
                    if res:
                        resumo_txt = PDFModule.to_latin1(res)
                        # REMOVIDA LIMITA√á√ÉO: imprime resumo completo sem corte
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, resumo_txt)
                    pdf.ln(5)
                    pdf.line(10, pdf.get_y(), 200, pdf.get_y())
                    pdf.ln(5)
                except Exception:
                    continue
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_busca_analitica(df_reg, total_base, crit, df_citados=None, df_colab=None):
        """
        Relat√≥rio da aba EXPLORAR DADOS, incluindo:
        - Crit√©rios de busca
        - N¬∫ de registros e % na base
        - Resumo de 'Autores citados' e 'Autores colaboradores' (tabelas da sele√ß√£o)
        - Lista de registros
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule._add_standard_header(pdf, "RELAT√ìRIO DE BUSCA - PROJETO SIBILA")

            pdf.set_y(pdf.get_y() + 5)
            pdf.set_fill_color(240, 240, 240)
            pdf.rect(10, 45, 190, 30, 'F')
            pdf.set_y(48)
            pdf.set_x(15)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Crit√©rio(s): {crit}"), ln=True)
            qtd = len(df_reg)
            pct = (qtd / total_base * 100) if total_base > 0 else 0
            pdf.set_x(15)
            pdf.set_font("Arial", '', 11)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Registros encontrados: {qtd} de {total_base} (total da base)"), ln=True)
            pdf.set_x(15)
            pdf.cell(0, 6, PDFModule.to_latin1(f"Percentual da base total: {pct:.2f}%"), ln=True)
            pdf.ln(10)
            if df_citados is not None and not df_citados.empty:
                pdf.set_font("Arial", 'B', 11)
                pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores citados na sele√ß√£o (Top 10)"))
                pdf.set_font("Arial", '', 10)
                for _, row in df_citados.head(10).iterrows():
                    if pdf.get_y() > 260:
                        pdf.add_page()
                        pdf.set_font("Arial", 'B', 11)
                        pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores citados na sele√ß√£o (cont.)"))
                        pdf.set_font("Arial", '', 10)
                    linha = f"- {row['Termo']}: {row['Qtd']} ocorr√™ncia(s) ({row['%']})"
                    pdf.multi_cell(0, 5, PDFModule.to_latin1(linha))
                pdf.ln(6)
            if df_colab is not None and not df_colab.empty:
                pdf.set_font("Arial", 'B', 11)
                pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores colaboradores na sele√ß√£o (Top 10)"))
                pdf.set_font("Arial", '', 10)
                for _, row in df_colab.head(10).iterrows():
                    if pdf.get_y() > 260:
                        pdf.add_page()
                        pdf.set_font("Arial", 'B', 11)
                        pdf.multi_cell(0, 6, PDFModule.to_latin1("Autores colaboradores na sele√ß√£o (cont.)"))
                        pdf.set_font("Arial", '', 10)
                    linha = f"- {row['Termo']}: {row['Qtd']} ocorr√™ncia(s) ({row['%']})"
                    pdf.multi_cell(0, 5, PDFModule.to_latin1(linha))
                pdf.ln(8)
            pdf.set_font("Arial", 'B', 11)
            pdf.multi_cell(0, 6, PDFModule.to_latin1("Registros da sele√ß√£o"))
            pdf.ln(3)
            for _, r in df_reg.iterrows():
                if pdf.get_y() > 250:
                    pdf.add_page()
                try:
                    tit = PDFModule.to_latin1(r.get('titulo_artigo', ''))
                    tip = PDFModule.to_latin1(r.get('vocabulario_controlado', ''))
                    rev = PDFModule.to_latin1(r.get('n', ''))
                    # Limpeza de p√°ginas para evitar "p. p."
                    raw_pag = str(r.get('paginas', '')).replace('pp.', '').replace('p.', '').strip()
                    pags = PDFModule.to_latin1(raw_pag)
                    pdf.set_font("Arial", 'B', 11)
                    pdf.multi_cell(0, 6, f"[{tip}] REVISTA {rev} / p. {pags}")
                    if tit:
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, tit)
                    aut = r.get('autores_colaboradores', [])
                    if aut:
                        if isinstance(aut, list):
                            s_aut = ', '.join([DataModule.format_nome_abnt(a) for a in aut if a])
                        else:
                            s_aut = DataModule.format_nome_abnt(aut)
                        s_aut = PDFModule.to_latin1(s_aut)
                        # Bloco de autores: R√≥tulo em Negrito, conte√∫do Normal
                        pdf.set_font("Arial", 'B', 10)
                        pdf.write(5, PDFModule.to_latin1("Autores: "))
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, s_aut)
                    nota_ed = r.get('nota_edicao', '')
                    if nota_ed:
                        ne = PDFModule.to_latin1(nota_ed)
                        pdf.set_font("Arial", 'I', 9)
                        pdf.multi_cell(0, 5, f"Nota de edi√ß√£o: {ne}")
                    res = r.get('resumo', '')
                    if res:
                        resumo_txt = PDFModule.to_latin1(res)
                        # REMOVIDA LIMITA√á√ÉO: imprime resumo completo sem corte
                        pdf.set_font("Arial", '', 10)
                        pdf.multi_cell(0, 5, resumo_txt)
                    pdf.ln(5)
                    pdf.line(10, pdf.get_y(), 200, pdf.get_y())
                    pdf.ln(5)
                except Exception:
                    continue
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF da busca: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio de busca"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_ficha(registro):
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule._add_standard_header(pdf, "FICHA NELIC ‚Äì PROJETO SIBILA")
            
            pdf.set_y(pdf.get_y() + 5)
            pdf.set_y(40)
            def safe(text):
                return PDFModule.to_latin1(text)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("1. IDENTIFICA√á√ÉO"), ln=True)
            pdf.set_font("Arial", '', 10)
            pdf.multi_cell(0, 5, safe(f"N¬∫ revista: {registro.get('n','')}"))
            pdf.multi_cell(0, 5, safe(f"Registro: {registro.get('registro','')}"))
            
            # Limpeza de p√°ginas para evitar "p. p."
            raw_pag = str(registro.get('paginas', '')).replace('pp.', '').replace('p.', '').strip()
            pdf.multi_cell(0, 5, safe(f"P√°ginas: p. {raw_pag}"))
            
            pdf.multi_cell(0, 5, safe(f"Tipo textual: {registro.get('vocabulario_controlado','')}"))
            pdf.multi_cell(
                0, 5,
                safe(f"Idiomas: {registro.get('idioma_01','')} / {registro.get('idioma_02','')}")
            )
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("2. RESPONSABILIDADE AUTORAL"), ln=True)
            pdf.set_font("Arial", '', 10)
            colab = registro.get('autores_colaboradores', [])
            entidade = registro.get('entidade_coletiva', [])
            trad = registro.get('tradutores', [])
            nome_ass = registro.get('nome_pessoal_como_assunto', [])
            if colab:
                lst = colab if isinstance(colab, list) else [colab]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Colaboradores: {s}"))
            if entidade:
                lst = entidade if isinstance(entidade, list) else [entidade]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Entidade Coletiva: {s}"))
            if trad:
                lst = trad if isinstance(trad, list) else [trad]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Tradutores: {s}"))
            if nome_ass:
                lst = nome_ass if isinstance(nome_ass, list) else [nome_ass]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Nome pessoal como assunto: {s}"))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("3. CONTE√öDO"), ln=True)
            pdf.set_font("Arial", '', 10)
            pdf.multi_cell(0, 5, safe(f"T√≠tulo: {registro.get('titulo_artigo','')}"))
            sub = registro.get('subtitulo_artigo', '')
            if sub:
                pdf.multi_cell(0, 5, safe(f"Subt√≠tulo: {sub}"))
            nota_ed = registro.get('nota_edicao', '')
            if nota_ed:
                pdf.multi_cell(0, 5, safe(f"Nota de edi√ß√£o: {nota_ed}"))
            res = registro.get('resumo', '')
            if res:
                pdf.ln(1)
                pdf.set_font("Arial", '', 10)
                pdf.multi_cell(0, 4, safe(res))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("4. ASSUNTOS"), ln=True)
            pdf.set_font("Arial", '', 10)
            kw = registro.get('palavras_chave', [])
            aut_cit = registro.get('autores_citados', [])
            if kw:
                s = ", ".join(kw) if isinstance(kw, list) else kw
                pdf.multi_cell(0, 5, safe(f"Palavras-chave: {s}"))
            if aut_cit:
                lst = aut_cit if isinstance(aut_cit, list) else [aut_cit]
                s = ", ".join(DataModule.format_nome_abnt(x) for x in lst)
                pdf.multi_cell(0, 5, safe(f"Autores citados: {s}"))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("5. ICONOGRAFIA"), ln=True)
            pdf.set_font("Arial", '', 10)
            icons = registro.get('iconografias', [])
            if icons:
                for ic in icons:
                    linha = f"- {ic.get('tipo','')}: {ic.get('descricao','')}"
                    pdf.multi_cell(0, 5, safe(linha))
            else:
                pdf.multi_cell(0, 5, safe("Sem iconografia registrada."))
            pdf.ln(3)
            pdf.set_font("Arial", 'B', 11)
            pdf.cell(0, 6, safe("6. NOTAS DE PESQUISA"), ln=True)
            pdf.set_font("Arial", '', 10)
            notas = registro.get('notas_pesquisa', [])
            if notas:
                for n in sorted(notas, key=lambda x: x.get('data', ''), reverse=True):
                    data_str = n.get('data', '')[:10]
                    t = n.get('titulo', '')
                    txt = n.get('texto', '')
                    tags = n.get('tags', [])
                    pdf.set_font("Arial", 'B', 9)
                    pdf.multi_cell(0, 4, safe(f"[{data_str}] {t}"))
                    if tags:
                        pdf.set_font("Arial", 'I', 8)
                        pdf.multi_cell(0, 4, safe("Tags: " + ", ".join(tags)))
                    pdf.set_font("Arial", '', 9)
                    pdf.multi_cell(0, 4, safe(txt))
                    pdf.ln(1)
            else:
                pdf.multi_cell(0, 5, safe("Sem notas vinculadas a este registro at√© o momento."))
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar ficha em PDF: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar ficha"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_tabela_estatistica(df_stats, titulo):
        """
        Gera PDF apenas com tabela de estat√≠sticas (campo, num. absoluto, percentual),
        seguindo o modelo dos relat√≥rios de tipos textuais e palavras-chave do sistema original.
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            # T√≠tulo limpo (sem "ESTAT√çSTICAS - " se vier do argumento, mas a fun√ß√£o _add_standard_header j√° trata)
            PDFModule._add_standard_header(pdf, titulo)
            
            cols = list(df_stats.columns)
            n_cols = len(cols)
            available_width = 190
            col_width = available_width / n_cols if n_cols > 0 else available_width
            
            # Cabe√ßalho da Tabela: Azul Escuro (#2f5f98) com texto Branco e Negrito
            pdf.set_fill_color(47, 95, 152) 
            pdf.set_text_color(255, 255, 255)
            pdf.set_font("Arial", 'B', 10)
            for col in cols:
                pdf.cell(col_width, 8, PDFModule.to_latin1(str(col)), border=1, align='C', fill=True)
            pdf.ln()
            
            # Corpo da Tabela
            pdf.set_text_color(0, 0, 0) # Reset para preto
            pdf.set_font("Arial", '', 9)
            
            for i, (_, row) in enumerate(df_stats.iterrows()):
                # Zebra striping: linhas alternadas
                if i % 2 == 0:
                    pdf.set_fill_color(255, 255, 255) # Branco
                else:
                    pdf.set_fill_color(240, 240, 240) # Cinza claro
                
                # Quebra de p√°gina
                if pdf.get_y() > 265:
                    pdf.add_page()
                    # Re-imprimir cabe√ßalho
                    pdf.set_fill_color(47, 95, 152)
                    pdf.set_text_color(255, 255, 255)
                    pdf.set_font("Arial", 'B', 10)
                    for col in cols:
                        pdf.cell(col_width, 8, PDFModule.to_latin1(str(col)), border=1, align='C', fill=True)
                    pdf.ln()
                    pdf.set_text_color(0, 0, 0)
                    pdf.set_font("Arial", '', 9)
                    # Restaurar cor de fundo da linha atual
                    if i % 2 == 0:
                        pdf.set_fill_color(255, 255, 255)
                    else:
                        pdf.set_fill_color(240, 240, 240)

                for col in cols:
                    val = row[col]
                    # Formata√ß√£o num√©rica: 2 casas decimais para floats
                    if isinstance(val, float):
                        txt = f"{val:.2f}"
                    else:
                        txt = str(val)
                    
                    txt = PDFModule.to_latin1(txt)
                    # N√∫meros sempre centralizados
                    pdf.cell(col_width, 6, txt, border=1, align='C', fill=True)
                pdf.ln()
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF de estat√≠sticas: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio de estat√≠sticas"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

    @staticmethod
    def gerar_pdf_duas_tabelas(df1, titulo1, df2, titulo2, titulo_geral):
        """
        Gera PDF contendo duas tabelas sequenciais.
        √ötil para 'Autores como assunto vs colaboradores'.
        """
        try:
            pdf = FPDF()
            pdf.add_page()
            PDFModule._add_standard_header(pdf, titulo_geral)
            
            # Fun√ß√£o auxiliar para desenhar tabela
            def desenhar_tabela(df, titulo_tabela):
                pdf.set_font("Arial", 'B', 12)
                pdf.cell(0, 8, PDFModule.to_latin1(titulo_tabela), ln=True)
                pdf.ln(2)
                
                cols = list(df.columns)
                n_cols = len(cols)
                available_width = 190
                col_width = available_width / n_cols if n_cols > 0 else available_width
                
                # Cabe√ßalho
                pdf.set_fill_color(47, 95, 152) 
                pdf.set_text_color(255, 255, 255)
                pdf.set_font("Arial", 'B', 10)
                for col in cols:
                    pdf.cell(col_width, 8, PDFModule.to_latin1(str(col)), border=1, align='C', fill=True)
                pdf.ln()
                
                # Corpo
                pdf.set_text_color(0, 0, 0)
                pdf.set_font("Arial", '', 9)
                for i, (_, row) in enumerate(df.iterrows()):
                    # Zebra
                    if i % 2 == 0:
                        pdf.set_fill_color(255, 255, 255)
                    else:
                        pdf.set_fill_color(240, 240, 240)
                        
                    # Quebra de p√°gina
                    if pdf.get_y() > 265:
                        pdf.add_page()
                        # Re-imprimir cabe√ßalho
                        pdf.set_fill_color(47, 95, 152)
                        pdf.set_text_color(255, 255, 255)
                        pdf.set_font("Arial", 'B', 10)
                        for col in cols:
                            pdf.cell(col_width, 8, PDFModule.to_latin1(str(col)), border=1, align='C', fill=True)
                        pdf.ln()
                        pdf.set_text_color(0, 0, 0)
                        pdf.set_font("Arial", '', 9)
                        # Restaurar zebra
                        if i % 2 == 0:
                            pdf.set_fill_color(255, 255, 255)
                        else:
                            pdf.set_fill_color(240, 240, 240)

                    for col in cols:
                        val = row[col]
                        # Formata√ß√£o num√©rica
                        if isinstance(val, float):
                            txt = f"{val:.2f}"
                        else:
                            txt = str(val)
                        txt = PDFModule.to_latin1(txt)
                        pdf.cell(col_width, 6, txt, border=1, align='C', fill=True)
                    pdf.ln()
            
            # Desenha Tabela 1
            desenhar_tabela(df1, titulo1)
            
            pdf.ln(10)
            
            # Verifica espa√ßo para Tabela 2 (estimativa grosseira de cabe√ßalho + algumas linhas)
            if pdf.get_y() > 200:
                pdf.add_page()
                
            # Desenha Tabela 2
            desenhar_tabela(df2, titulo2)
            
            return pdf.output(dest='S').encode('latin-1', 'replace')
        except Exception as e:
            st.error(f"Erro ao gerar PDF de duas tabelas: {str(e)}")
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", '', 12)
            pdf.cell(0, 10, PDFModule.to_latin1("Erro ao gerar relat√≥rio"), ln=True)
            return pdf.output(dest='S').encode('latin-1', 'replace')

class UtilsModule:
    """Encapsula fun√ß√µes utilit√°rias."""
    @staticmethod
    def sanitizar_dataframe(df):
        colunas_lista = [
            'iconografias',
            'autores_colaboradores',
            'tradutores',
            'autores_citados',
            'palavras_chave',
            'nome_pessoal_como_assunto',
            'notas_pesquisa'
        ]
        if df.empty:
            return df
        for col in colunas_lista:
            if col in df.columns:
                df[col] = df[col].apply(lambda x: x if isinstance(x, list) else [])
        return df

    @staticmethod
    def calculate_stats_with_percentage(series):
        if series.empty:
            return pd.DataFrame(columns=['Termo', 'Qtd', '%'])
        counts = series.value_counts().reset_index()
        counts.columns = ['Termo', 'Qtd']
        total = counts['Qtd'].sum()
        counts['%'] = (counts['Qtd'] / total * 100).map('{:.2f}%'.format)
        return counts

    @staticmethod
    def get_registro_by_id(dados, reg_id):
        for r in dados:
            if r.get('_id') == reg_id:
                return r
        return None

    @staticmethod
    def is_bilingue(registro):
        """
        Identifica publica√ß√£o bil√≠ngue procurando 'bil√≠ngue/bilingue'
        tanto em nota de edi√ß√£o quanto no resumo (colchetes, aspas etc.).
        """
        nota = str(registro.get('nota_edicao', '') or '')
        resu = str(registro.get('resumo', '') or '')
        texto = (nota + " " + resu).lower()
        return ('bil√≠ngue' in texto) or ('bilingue' in texto)

    @staticmethod
    def format_list_field(reg, field):
        raw = reg.get(field)
        itens = []
        if isinstance(raw, list):
            for v in raw:
                if v is None:
                    continue
                if isinstance(v, float) and pd.isna(v):
                    continue
                s = str(v).strip()
                if s:
                    itens.append(s)
        elif isinstance(raw, str):
            s = raw.strip()
            if s:
                itens.append(s)
        elif raw is not None and not (isinstance(raw, float) and pd.isna(raw)):
            s = str(raw).strip()
            if s:
                itens.append(s)
        if field in {'autores_colaboradores', 'autores_citados', 'tradutores', 'nome_pessoal_como_assunto'}:
            itens = [DataModule.format_nome_abnt(i) for i in itens]
        return ', '.join(itens) if itens else '‚Äî'

    @staticmethod
    def construir_tipo_textual(tipo_principal: str, subtipo: str | None) -> str:
        """Monta o r√≥tulo completo, ignorando o placeholder 'Sem especifica√ß√£o'."""
        if subtipo and subtipo.strip() and subtipo != "Sem especifica√ß√£o":
            return f"{tipo_principal} - {subtipo.strip()}"
        return tipo_principal

    @staticmethod
    def parse_tipo_textual(valor: str) -> tuple[str, str | None]:
        """Separa o r√≥tulo salvo em principal e subtipo para preencher o formul√°rio.
        Aceita tanto ' - ' quanto ' | ' como separadores."""
        if not valor:
            return "", None
        # Aceitar tanto " - " quanto " | " como separadores
        if " | " in valor:
            partes = valor.split(" | ", 1)
            return partes[0].strip(), partes[1].strip()
        if " - " in valor:
            partes = valor.split(" - ", 1)
            return partes[0].strip(), partes[1].strip()
        return valor.strip(), "Sem especifica√ß√£o"

    @staticmethod
    def converter_excel(df):
        try:
            o = BytesIO()
            with pd.ExcelWriter(o, engine='xlsxwriter') as w:
                df_export = df.copy()
                for col in df_export.columns:
                    df_export[col] = df_export[col].apply(
                        lambda x: json.dumps(x, ensure_ascii=False) if isinstance(x, (list, dict)) else x
                    )
                df_export.to_excel(w, index=False, sheet_name='Dados')
            return o.getvalue()
        except Exception as e:
            st.error(f"Erro ao gerar Excel: {str(e)}")
            o = BytesIO()
            pd.DataFrame({'Erro': ['Erro ao gerar planilha']}).to_excel(o, index=False)
            return o.getvalue()

# ==========================================
# 3. COMPONENTES REUTILIZ√ÅVEIS
# ==========================================

class CatalogacaoForm:
    def __init__(self, dados, df):
        self.dados = dados
        self.df = df

    def render(self, rec=None, mode="NOVO REGISTRO"):
        # Inicializa session_state
        if 'loaded_json' not in st.session_state:
            st.session_state.loaded_json = None
        if 'clear_json_input' not in st.session_state:
            st.session_state.clear_json_input = False
        if 'form_clear_counter' not in st.session_state:
            st.session_state.form_clear_counter = 0

        # Carregamento R√°pido via JSON/Excel - APENAS em NOVO REGISTRO
        if mode == "NOVO REGISTRO":
            with st.expander("üì• CARREGAMENTO R√ÅPIDO (JSON ou EXCEL)", expanded=False):
                tipo_import = st.radio("Formato:", ["JSON", "EXCEL"], horizontal=True, key="tipo_import")

                if tipo_import == "JSON":
                    c_txt, c_btn = st.columns([4, 1])
                    with c_txt:
                        json_value = "" if st.session_state.clear_json_input else None
                        j_txt = st.text_area("Cole o JSON:", height=100, key="json_input", value=json_value if json_value is not None else "")
                    with c_btn:
                        st.write(""); st.write("")
                        b_load = st.button("PROCESSAR JSON")

                    if st.session_state.clear_json_input:
                        st.session_state.clear_json_input = False

                    # L√≥gica de Carregamento JSON
                    if b_load and j_txt:
                        try:
                            l = json.loads(j_txt)
                            st.session_state.force_form_update = True
                            loaded_rec = l[0] if isinstance(l, list) else l
                            st.session_state.loaded_json = loaded_rec
                            st.success("‚úÖ JSON carregado!")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Erro ao processar JSON: {str(e)}")
                            st.session_state.loaded_json = None
                else:
                    uploaded_file = st.file_uploader("Escolha um arquivo Excel", type=['xlsx', 'xls'])
                    if uploaded_file and st.button("PROCESSAR EXCEL"):
                        try:
                            df_excel = pd.read_excel(uploaded_file)
                            if len(df_excel) > 0:
                                loaded_rec = df_excel.iloc[0].to_dict()
                                st.session_state.loaded_json = loaded_rec
                                st.success(f"‚úÖ Excel carregado! {len(df_excel)} registro(s) encontrado(s). Carregando o primeiro.")
                                st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå Erro ao processar Excel: {str(e)}")

        # Prioridade: loaded_json > rec passado como par√¢metro
        if st.session_state.loaded_json is not None:
            rec = st.session_state.loaded_json
            col_info, col_btn = st.columns([3, 1])
            with col_info:
                st.info("üìã Dados carregados via importa√ß√£o.")
            with col_btn:
                if st.button("üóëÔ∏è Limpar dados", use_container_width=True):
                    st.session_state.loaded_json = None
                    st.session_state.selected_record = None
                    st.session_state.clear_json_input = True
                    st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
                    # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                    st.session_state.form_clear_counter += 1
                    # Limpar todos os campos do formul√°rio E campos de busca
                    for key in list(st.session_state.keys()):
                        if key.startswith('form_') or key.startswith('busca_') or key.startswith('confirm_delete_') or key.startswith('icon_'):
                            del st.session_state[key]
                    st.rerun()
        elif rec and mode == "EDITAR EXISTENTE":
            # Se rec foi passado como par√¢metro (da busca), mostrar info
            col_info, col_btn = st.columns([3, 1])
            with col_info:
                st.info(f"üìã Editando: **{rec.get('titulo_artigo', '[sem t√≠tulo]')}**")
            with col_btn:
                if st.button("üßπ Limpar formul√°rio", use_container_width=True):
                    st.session_state.selected_record = None
                    st.session_state.loaded_json = None
                    st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
                    # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                    st.session_state.form_clear_counter += 1
                    # Limpar todos os campos do formul√°rio e campos de busca
                    for key in list(st.session_state.keys()):
                        if key.startswith('form_') or key.startswith('busca_') or key.startswith('icon_'):
                            del st.session_state[key]
                    st.rerun()

        # L√≥gica de Editar Existente (chamada externamente)
        # --- SELE√á√ÉO DE TIPO TEXTUAL (FORA DO FORMUL√ÅRIO) ---
        st.markdown("---")
        st.markdown("#### TIPO TEXTUAL (Vocabul√°rio Controlado)")

        tipo_atual = (rec or {}).get('vocabulario_controlado', '')
        tipo_principal_atual, subtipo_atual = UtilsModule.parse_tipo_textual(tipo_atual) if tipo_atual else (None, None)

        col_tipo1, col_tipo2 = st.columns(2)
        with col_tipo1:
            tipos_principais = sorted(DataModule.TIPOS_TEXTUAIS.keys())

            # Encontrar o √≠ndice correto
            idx_tipo = 0  # default
            if tipo_principal_atual and tipo_principal_atual in tipos_principais:
                idx_tipo = tipos_principais.index(tipo_principal_atual)

            # Gerar key √∫nico baseado no valor atual para for√ßar atualiza√ß√£o do selectbox
            key_tipo = f"sel_tipo_principal_{tipo_atual}_{rec.get('_id', 'novo') if rec else 'novo'}"
            tipo_principal_selecionado = st.selectbox(
                "TIPO PRINCIPAL*",
                tipos_principais,
                index=idx_tipo,
                key=key_tipo,
                help="Selecione o tipo textual principal."
            )
        with col_tipo2:
            subtipos_disponiveis = DataModule.TIPOS_TEXTUAIS.get(tipo_principal_selecionado, ["Sem especifica√ß√£o"])
            idx_subtipo = subtipos_disponiveis.index(subtipo_atual) if subtipo_atual in subtipos_disponiveis else 0
            # Gerar key √∫nico baseado no valor atual para for√ßar atualiza√ß√£o
            key_subtipo = f"sel_subtipo_{tipo_atual}_{rec.get('_id', 'novo') if rec else 'novo'}"
            subtipo_selecionado = st.selectbox(
                "SUBTIPO (Campo disciplinar)",
                subtipos_disponiveis,
                index=idx_subtipo,
                key=key_subtipo,
                help="Especifique o campo disciplinar."
            )

        tipo_textual_final = UtilsModule.construir_tipo_textual(tipo_principal_selecionado, subtipo_selecionado)
        st.info(f"Ser√° registrado como: **{tipo_textual_final}**")

        # -----------------------------------------------------
        st.markdown("---")
        # --- IN√çCIO DO FORMUL√ÅRIO ---
        # ‚ö†Ô∏è CORRE√á√ÉO DO BUG DE PERSIST√äNCIA:
        # S√≥ atualizar session_state quando o registro REALMENTE mudar
        # Isso evita sobrescrever as edi√ß√µes do usu√°rio a cada rerun

        # Identificar o registro atual
        rec_id_atual = rec.get('_id', 'novo') if rec else 'novo'

        # Verificar se √© um registro diferente do anterior
        if 'current_editing_record_id' not in st.session_state:
            st.session_state.current_editing_record_id = None

        registro_mudou = (st.session_state.current_editing_record_id != rec_id_atual)

        # S√ì atualizar os campos quando:
        # 1. O registro mudou (carregou um diferente) OU
        # 2. Foi solicitado force_form_update (ao clicar em "Carregar Registro")
        should_update_form = registro_mudou or st.session_state.get('force_form_update', False)

        if should_update_form:
            # Atualizar o ID do registro atual
            st.session_state.current_editing_record_id = rec_id_atual

            # Resetar flag de force_form_update
            if 'force_form_update' in st.session_state:
                st.session_state.force_form_update = False

            # Fun√ß√£o auxiliar para converter listas em texto
            def lt(x): return "\n".join(x) if isinstance(x, list) else str(x)

            if rec:
                # Carregar dados do registro
                st.session_state.form_n_rev = str(rec.get('n', ''))
                st.session_state.form_registro = str(rec.get('registro', ''))
                st.session_state.form_paginas = str(rec.get('paginas', ''))
                st.session_state.form_ordem = int(rec.get('ordem_exibicao', 0))
                st.session_state.form_i1 = rec.get('idioma_01', 'POR')
                st.session_state.form_i2 = rec.get('idioma_02', '')

                # Carregar Iconografias para lista din√¢mica
                icon_data = rec.get('iconografias', [])
                rows = []
                for item in icon_data:
                    row_id = str(uuid.uuid4())
                    rows.append(row_id)
                    st.session_state[f"icon_tipo_{row_id}"] = item.get('tipo', DataModule.LISTA_ICONOGRAFIA[0])
                    st.session_state[f"icon_desc_{row_id}"] = item.get('descricao', '')
                st.session_state.iconografias_rows = rows
                st.session_state.form_titulo = rec.get('titulo_artigo', '')
                st.session_state.form_sub = rec.get('subtitulo_artigo', '')
                st.session_state.form_nota = rec.get('nota_edicao', '')
                st.session_state.form_autores = lt(rec.get('autores_colaboradores', []))
                st.session_state.form_entidade = lt(rec.get('entidade_coletiva', []))
                st.session_state.form_tradutores = lt(rec.get('tradutores', []))
                st.session_state.form_citados = lt(rec.get('autores_citados', []))
                st.session_state.form_kw = lt(rec.get('palavras_chave', []))
                st.session_state.form_pessoal = lt(rec.get('nome_pessoal_como_assunto', []))
                st.session_state.form_resumo = rec.get('resumo', '')
            else:
                # Formul√°rio vazio (novo registro sem dados)
                st.session_state.form_n_rev = ''
                st.session_state.form_registro = ''
                st.session_state.form_paginas = ''
                st.session_state.form_ordem = 0
                st.session_state.form_i1 = 'POR'
                st.session_state.form_i2 = ''
                st.session_state.form_titulo = ''
                st.session_state.form_sub = ''
                st.session_state.form_nota = ''
                st.session_state.form_autores = ''
                st.session_state.form_entidade = ''
                st.session_state.form_tradutores = ''
                st.session_state.form_citados = ''
                st.session_state.form_kw = ''
                st.session_state.form_pessoal = ''
                st.session_state.form_resumo = ''

        # Usar chave din√¢mica para for√ßar recria√ß√£o do formul√°rio quando registro mudar OU quando limpar
        rec_id = rec.get('_id', 'novo') if rec else 'novo'
        # form_key = f"form_{rec_id}_v{st.session_state.form_clear_counter}"
        
        # REMOVIDO st.form PARA PERMITIR BOT√ïES DIN√ÇMICOS
        # with st.form(form_key):
        if True: # Manter indenta√ß√£o visual ou remover indenta√ß√£o abaixo (vou remover indenta√ß√£o)
            c_form1, c_form2, c_form3, c_form4 = st.columns(4)
            n_rev = c_form1.text_input("N¬∫ REVISTA*", key="form_n_rev")
            reg_txt = c_form2.text_input("REGISTRO*", key="form_registro")
            pag = c_form3.text_input("P√ÅGINAS", key="form_paginas")
            # Verifica√ß√£o de Duplicidade
            if n_rev and reg_txt:
                duplicado = False
                for r in self.dados:
                    if mode == "EDITAR EXISTENTE" and (rec or {}).get('_id') == r.get('_id'): continue
                    if str(r.get('n')) == str(n_rev) and str(r.get('registro')) == str(reg_txt):
                        duplicado = True
                        break
                if duplicado:
                    st.warning(f"‚ö†Ô∏è ATEN√á√ÉO: J√° existe o registro '{reg_txt}' na Revista {n_rev}!", icon="üö®")
            ordem = c_form4.number_input("ORDEM", key="form_ordem", min_value=0, step=1, format="%d")

            c5, c6, c7 = st.columns(3)
            langs = ["POR", "ING", "ESP", "FRA", "ITA", "ALE", "RUS", "CAT", "GRE", "JAP"]
            # Idiomas usam session_state para valores padr√£o
            i1 = c5.selectbox("IDIOMA 1", langs, key="form_i1")
            i2 = c6.selectbox("IDIOMA 2", [""] + langs, key="form_i2")
            st.markdown("---")

            regra_help = "Se sem t√≠tulo: insira o primeiro verso entre aspas..."
            tit = st.text_input("T√çTULO*", help=regra_help, key="form_titulo")
            sub = st.text_input("SUBT√çTULO", key="form_sub")
            nota_ed = st.text_input("NOTA DE EDI√á√ÉO", key="form_nota")

            st.markdown("---")
            st.markdown("#### RESPONSABILIDADE AUTORAL")
            c8, c9, c10 = st.columns(3)
            aut = c8.text_area("COLABORADORES", key="form_autores")
            entidade = c9.text_area("ENTIDADE COLETIVA", key="form_entidade", help="Responsabilidade institucional quando n√£o h√° autor individual")
            trad = c10.text_area("TRADUTORES", key="form_tradutores")

            st.markdown("---")
            st.markdown("#### ASSUNTOS")
            c10, c11 = st.columns(2)
            cit = c10.text_area("AUTORES CITADOS", key="form_citados")
            kw = c11.text_area("PALAVRAS-CHAVE", key="form_kw")
            nome_pessoal = st.text_area("NOME PESSOAL COMO ASSUNTO", key="form_pessoal")

            st.markdown("---")
            st.markdown("#### RESUMO ANAL√çTICO")
            tipo_base = tipo_principal_selecionado.upper().replace(" ", "")
            requer_resumo = tipo_base not in TIPOS_SEM_RESUMO
            label_resumo = "RESUMO" + (" (OBRIGAT√ìRIO)" if requer_resumo else " (OPCIONAL)")
            resumo = st.text_area(label_resumo, height=200, key="form_resumo")

            st.markdown("---")
            st.markdown("#### ICONOGRAFIA")

            # --- ICONOGRAFIA (REFATORADO) ---
            if 'iconografias_rows' not in st.session_state:
                st.session_state.iconografias_rows = []

            # Bot√£o de Adicionar
            col_add_icon, _ = st.columns([3, 4])
            if col_add_icon.button("‚ûï ADICIONAR ICONOGRAFIA"):
                new_row_id = str(uuid.uuid4())
                st.session_state.iconografias_rows.append(new_row_id)
                # Valores padr√£o
                st.session_state[f"icon_tipo_{new_row_id}"] = DataModule.LISTA_ICONOGRAFIA[0]
                st.session_state[f"icon_desc_{new_row_id}"] = ""
                st.rerun()

            # Renderizar linhas
            rows_to_remove = []
            for idx, row_id in enumerate(st.session_state.iconografias_rows):
                st.markdown(f"**Iconografia {idx+1}**")
                c_tipo, c_desc, c_del = st.columns([2, 5, 0.5])
                
                with c_tipo:
                    st.selectbox(
                        "Tipo",
                        DataModule.LISTA_ICONOGRAFIA,
                        key=f"icon_tipo_{row_id}",
                        label_visibility="collapsed"
                    )
                with c_desc:
                    st.text_input(
                        "Descri√ß√£o",
                        key=f"icon_desc_{row_id}",
                        placeholder="Descri√ß√£o da iconografia...",
                        label_visibility="collapsed"
                    )
                with c_del:
                    if st.button("üóëÔ∏è", key=f"del_icon_{row_id}", help="Remover iconografia"):
                        rows_to_remove.append(row_id)

            # Processar remo√ß√µes
            if rows_to_remove:
                for rid in rows_to_remove:
                    if rid in st.session_state.iconografias_rows:
                        st.session_state.iconografias_rows.remove(rid)
                    # Limpar chaves do session_state
                    if f"icon_tipo_{rid}" in st.session_state: del st.session_state[f"icon_tipo_{rid}"]
                    if f"icon_desc_{rid}" in st.session_state: del st.session_state[f"icon_desc_{rid}"]
                st.rerun()

            # Informa√ß√£o visual
            if not st.session_state.iconografias_rows:
                st.info("‚ÑπÔ∏è Nenhuma iconografia cadastrada.")
                st.caption(f"üí° Dica: Aumente o n√∫mero acima para adicionar mais iconografias, diminua para remover.")

            st.markdown("---")
            # BOT√ÉO SALVAR (AGORA FORA DO FORM)
            submit_btn = st.button("üíæ SALVAR", type="primary")

        # L√ìGICA DE SALVAMENTO (FORA DO FORM, MAS GATILHADA PELO BOT√ÉO)
        if submit_btn:
            if not n_rev or not reg_txt:
                st.error("‚ùå Campos obrigat√≥rios: N¬∫ REVISTA e REGISTRO!")
                st.stop()
            if requer_resumo and not resumo.strip():
                st.error(f"‚ùå O tipo textual '{tipo_textual_final}' exige RESUMO ANAL√çTICO!")
                st.stop()

            # Construir lista de iconografias a partir do session_state
            icon_list = []
            if 'iconografias_rows' in st.session_state:
                for row_id in st.session_state.iconografias_rows:
                    t = st.session_state.get(f"icon_tipo_{row_id}")
                    d = st.session_state.get(f"icon_desc_{row_id}", "").strip()
                    if t and d:
                        icon_list.append({"tipo": t, "descricao": d})

            new = {
                "n": n_rev,
                "registro": reg_txt,
                "ordem_exibicao": ordem,
                "idioma_01": i1,
                "idioma_02": i2 if i2 else "",
                "vocabulario_controlado": tipo_textual_final,
                "titulo_artigo": tit,
                "subtitulo_artigo": sub,
                "paginas": pag,
                "resumo": resumo,
                "nota_edicao": nota_ed,
                "autores_colaboradores": DataModule.normalizar_lista_autores(aut),
                "entidade_coletiva": DataModule.normalizar_lista_autores(entidade),
                "tradutores": DataModule.normalizar_lista_autores(trad),
                "autores_citados": DataModule.normalizar_lista_autores(cit),
                "palavras_chave": DataModule.normalizar_texto(kw.replace(',', '\n').split('\n')),
                "nome_pessoal_como_assunto": DataModule.normalizar_lista_autores(nome_pessoal),
                "iconografias": icon_list,
                "_timestamp": datetime.now().isoformat()
            }
            # Preservar notas de pesquisa do registro original, se existir
            if 'notas_pesquisa' in (rec or {}):
                new['notas_pesquisa'] = (rec or {}).get('notas_pesquisa', [])

            # L√ìGICA APRIMORADA: Buscar registro existente por Revista + Registro
            # Isso evita duplicatas mesmo quando n√£o h√° _id no rec
            registro_existente = None
            indice_existente = None

            for i, d in enumerate(self.dados):
                if str(d.get('n')) == str(n_rev) and str(d.get('registro')) == str(reg_txt):
                    # Encontrou registro com mesma Revista + Registro
                    registro_existente = d
                    indice_existente = i
                    break

            if mode == "EDITAR EXISTENTE":
                # Modo EDITAR: Verificar se h√° registro para substituir
                if registro_existente:
                    # Substituir o registro existente, preservando o _id original
                    new['_id'] = registro_existente.get('_id', str(int(datetime.now().timestamp() * 1000)))
                    # Preservar notas de pesquisa do registro original
                    if 'notas_pesquisa' in registro_existente:
                        new['notas_pesquisa'] = registro_existente.get('notas_pesquisa', [])
                    self.dados[indice_existente] = new
                    st.info(f"‚ÑπÔ∏è Registro existente (ID: {new['_id']}) foi ATUALIZADO.")
                elif '_id' in (rec or {}):
                    # Tem _id mas n√£o encontrou por revista+registro (usu√°rio pode ter mudado esses campos)
                    # Buscar pelo _id original
                    new['_id'] = (rec or {})['_id']
                    for i, d in enumerate(self.dados):
                        if d.get('_id') == new['_id']:
                            self.dados[i] = new
                            st.info(f"‚ÑπÔ∏è Registro (ID: {new['_id']}) foi ATUALIZADO.")
                            break
                else:
                    # Est√° em modo EDITAR mas n√£o encontrou registro existente - criar novo
                    new['_id'] = str(int(datetime.now().timestamp() * 1000))
                    new.setdefault('notas_pesquisa', [])
                    self.dados.append(new)
                    st.warning("‚ö†Ô∏è N√£o foi encontrado registro existente para editar. Criado NOVO registro.")
            else:
                # Modo NOVO REGISTRO
                if registro_existente:
                    # ATEN√á√ÉO: J√° existe um registro com essa Revista + Registro!
                    st.error(f"‚ùå ERRO: J√° existe um registro com Revista {n_rev} e Registro {reg_txt} (ID: {registro_existente.get('_id')})")
                    st.error("üí° Use o modo 'EDITAR EXISTENTE' para modificar este registro ou altere os campos Revista/Registro.")
                    st.stop()
                else:
                    # Criar novo registro normalmente
                    new['_id'] = str(int(datetime.now().timestamp() * 1000))
                    new.setdefault('notas_pesquisa', [])
                    self.dados.append(new)

            if PersistenceModule.save_data(self.dados):
                st.success("‚úÖ Registro salvo com sucesso!")
                st.balloons()

                # Limpar automaticamente o formul√°rio ap√≥s salvar
                st.session_state.loaded_json = None
                st.session_state.selected_record = None
                st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
                # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                st.session_state.form_clear_counter += 1

                # Limpar todos os campos do formul√°rio
                for key in list(st.session_state.keys()):
                    if key.startswith('form_') or key.startswith('busca_') or key.startswith('confirm_delete_') or key.startswith('icon_'):
                        del st.session_state[key]

                # Recarregar a p√°gina para mostrar formul√°rio limpo
                st.rerun()


class FichasNotasView:
    def __init__(self, df, dados):
        self.df = df
        self.dados = dados

    def render(self):
        st.title("üìá FICHAS & NOTAS NELIC")
        if self.df.empty:
            st.warning("Base de dados vazia. Cadastre registros na aba CATALOGA√á√ÉO.")
            return

        st.markdown("### üîç Navega√ß√£o por Revista")
        # Garante ordena√ß√£o correta das revistas
        revistas_disponiveis = sorted(
            self.df['n'].astype(str).unique(),
            key=lambda x: ORDEM_SIBILA.index(x) if x in ORDEM_SIBILA else 999
        )
        revista_selecionada = st.selectbox(
            "Selecione a revista:",
            ["Todas as revistas"] + revistas_disponiveis,
            help="Filtre os registros por n√∫mero da revista para facilitar a navega√ß√£o"
        )

        if revista_selecionada == "Todas as revistas":
            df_filtrado = self.df
        else:
            df_filtrado = self.df[self.df['n'].astype(str) == revista_selecionada]

        st.markdown("---")
        opcoes = [
            f"{r.get('n','?')} | Reg: {r.get('registro','?')} | {r.get('titulo_artigo','[sem t√≠tulo]')}"
            for _, r in df_filtrado.iterrows()
        ]
        if not opcoes:
            st.warning(f"‚ö†Ô∏è Nenhum registro encontrado para a revista {revista_selecionada}")
            return

        escolha = st.selectbox("Selecione o registro espec√≠fico:", opcoes)
        idx = opcoes.index(escolha)
        reg_sel = df_filtrado.iloc[idx].to_dict()
        reg_id = reg_sel.get('_id')

        c_esq, c_dir = st.columns([2, 1])
        with c_esq:
            st.markdown(
                f"""
                <div class="nelic-card">
                    <div class="nelic-card-header">FICHA NELIC ‚Äì REGISTRO {reg_sel.get('registro','')}</div>
                    <div class="nelic-card-subtitle">
                        n. {reg_sel.get('n','?')} ¬∑ Tipo {reg_sel.get('vocabulario_controlado','')} ¬∑ pp. {reg_sel.get('paginas','')}
                    </div>
                    <div>
                        <strong>T√≠tulo:</strong> {reg_sel.get('titulo_artigo','[sem t√≠tulo]')}<br>
                        <strong>Subt√≠tulo:</strong> {reg_sel.get('subtitulo_artigo','')}<br>
                        <strong>Autores:</strong> {UtilsModule.format_list_field(reg_sel, 'autores_colaboradores')}<br>
                        <strong>Tradutores:</strong> {UtilsModule.format_list_field(reg_sel, 'tradutores')}<br>
                        <strong>Entidade Coletiva:</strong> {UtilsModule.format_list_field(reg_sel, 'entidade_coletiva')}
                    </div>
                    <div style="margin-top:0.4rem;">
                        <span class="nelic-tag">Idioma 1: {reg_sel.get('idioma_01','')}</span>
                        <span class="nelic-tag nelic-tag-muted">Idioma 2: {reg_sel.get('idioma_02','')}</span>
                    </div>
                </div>
                """,
                unsafe_allow_html=True
            )

            st.markdown("#### Conte√∫do e Assuntos")
            with st.expander("üìå Conte√∫do", expanded=True):
                st.markdown(f"**Nota de edi√ß√£o:** {reg_sel.get('nota_edicao','‚Äî')}")
                st.markdown("**Resumo:**")
                st.write(reg_sel.get('resumo', '‚Äî'))

            with st.expander("üéØ Assuntos e autores citados", expanded=False):
                st.markdown(f"**Palavras-chave:** {UtilsModule.format_list_field(reg_sel, 'palavras_chave')}")
                st.markdown(f"**Autores citados:** {UtilsModule.format_list_field(reg_sel, 'autores_citados')}")
                st.markdown(f"**Nomes pessoais como assunto:** {UtilsModule.format_list_field(reg_sel, 'nome_pessoal_como_assunto')}")

            with st.expander("üñºÔ∏è Iconografia", expanded=False):
                icons = reg_sel.get('iconografias', [])
                if icons:
                    for ic in icons:
                        st.markdown(f"- **{ic.get('tipo','')}** ¬∑ {ic.get('descricao','')}")
                else:
                    st.markdown("Nenhuma iconografia registrada.")

        with c_dir:
            st.markdown("#### Exportar Ficha")
            pdf_ficha = PDFModule.gerar_pdf_ficha(reg_sel)
            st.download_button(
                "üìÑ BAIXAR FICHA EM PDF",
                pdf_ficha,
                f"ficha_sibila_{reg_sel.get('registro','')}.pdf",
                "application/pdf",
                width='stretch'
            )

            st.markdown("---")
            st.markdown("#### Notas de Pesquisa")
            # Carregamos o di√°rio aqui para garantir atualiza√ß√£o
            diario = PersistenceModule.load_diario()
            notas = reg_sel.get('notas_pesquisa', []) or []
            with st.form("form_nota_registro"):
                titulo_nota = st.text_input("T√≠tulo da nota")
                texto_nota = st.text_area("Texto da nota", height=120)
                tags_nota = st.text_input("Tags (separadas por v√≠rgula)")
                if st.form_submit_button("‚ûï Adicionar nota a este registro"):
                    if texto_nota.strip():
                        nova_nota = {
                            "id": str(int(datetime.now().timestamp() * 1000)),
                            "data": datetime.now().isoformat(),
                            "titulo": titulo_nota.strip() or "[sem t√≠tulo]",
                            "texto": texto_nota.strip(),
                            "tags": [t.strip() for t in tags_nota.split(',') if t.strip()],
                            "registro_id": reg_id
                        }
                        # Precisamos buscar o registro na lista original 'dados' para salvar
                        reg_real = UtilsModule.get_registro_by_id(self.dados, reg_id)
                        if reg_real is not None:
                            reg_real.setdefault('notas_pesquisa', [])
                            reg_real['notas_pesquisa'].append(nova_nota)
                            if PersistenceModule.save_data(self.dados):
                                st.success("Nota adicionada ao registro.")
                                st.rerun() # Recarrega para mostrar a nota nova
                        else:
                            st.error("Erro ao vincular nota.")
                    else:
                        st.warning("O texto da nota n√£o pode estar vazio.")

            if notas:
                st.markdown("##### Notas j√° cadastradas")
                for n in sorted(notas, key=lambda x: x.get('data', ''), reverse=True):
                    dt = n.get('data', '')[:16].replace("T", " ")
                    st.markdown(
                        f"""
                        <div class="nelic-card">
                            <div class="nelic-card-header">{n.get('titulo','[sem t√≠tulo]')}</div>
                            <div class="nelic-card-subtitle">Data: {dt}</div>
                            <div class="nelic-muted">{n.get('texto','')}</div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    tags = n.get('tags', [])
                    if tags:
                        st.markdown(" ".join([f"<span class='nelic-tag nelic-tag-muted'>{t}</span>" for t in tags]), unsafe_allow_html=True)
            else:
                st.info("Nenhuma nota vinculada.")

# ==========================================
# 4. FUN√á√ïES DE RELAT√ìRIOS
# ==========================================

def relatorio_mapa_colaboracao(df):
    st.markdown("#### Volume de itens por revista")
    def itens_por_revista(df_local):
        rows = []
        for rev, sub in df_local.groupby('n'):
            rows.append({"n.": str(rev), "Quantidade de itens": len(sub)})
        return pd.DataFrame(rows)
    
    df_rel = itens_por_revista(df)
    # Garante ordena√ß√£o correta no gr√°fico
    if 'n.' in df_rel.columns:
        df_rel['n.'] = pd.Categorical(df_rel['n.'], categories=ORDEM_SIBILA, ordered=True)
        df_rel = df_rel.sort_values('n.')
    
    df_rel.index = df_rel.index + 1
    st.dataframe(df_rel, width='stretch')
    fig = px.bar(df_rel, x="n.", y="Quantidade de itens", text="Quantidade de itens")
    fig.update_layout(height=380, title="Volume de itens por n√∫mero da revista")
    fig.update_xaxes(type='category', tickmode='linear')
    st.plotly_chart(fig, width='stretch')
    
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    
    excel_rel = UtilsModule.converter_excel(df_rel)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_mapa_colaboracao_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = df_rel.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_mapa_colaboracao_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_analitico(df, len(df), "Volume de itens por revista")
    col3.download_button(
        "üìÑ PDF (lista completa)",
        pdf_rel,
        f"rel_mapa_colaboracao_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_bilinguismo(df):
    st.markdown("#### √çndice de publica√ß√µes bil√≠ngues por n√∫mero da revista")
    df_local = df.copy()
    df_local['bilingue'] = df_local.apply(UtilsModule.is_bilingue, axis=1)
    resumo = (
        df_local.groupby('n')['bilingue']
        .agg(total='count', bil='sum')
        .reset_index()
    )
    resumo['% bil√≠ngue'] = resumo.apply(
        lambda r: (r['bil'] / r['total'] * 100) if r['total'] > 0 else 0, axis=1
    )
    resumo['n'] = resumo['n'].astype(str)
    
    # Garante ordena√ß√£o correta no gr√°fico
    if 'n' in resumo.columns:
        resumo['n'] = pd.Categorical(resumo['n'], categories=ORDEM_SIBILA, ordered=True)
        resumo = resumo.sort_values('n')

    resumo.index = resumo.index + 1
    st.dataframe(resumo, width='stretch')
    fig = px.bar(
        resumo,
        x='n',
        y='% bil√≠ngue',
        text=resumo['% bil√≠ngue'].map(lambda x: f"{x:.1f}%")
    )
    fig.update_layout(
        height=380,
        title="% de registros bil√≠ngues (nota ou resumo) por revista",
        xaxis_title="n.",
        yaxis_title="% bil√≠ngue"
    )
    fig.update_xaxes(type='category', tickmode='linear')
    st.plotly_chart(fig, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(resumo)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_bilinguismo_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = resumo.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_bilinguismo_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(resumo, "√çndice de publica√ß√µes bil√≠ngues")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_bilinguismo_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_iconografia(df):
    st.markdown("#### Iconografia por n√∫mero da revista")
    df_local = df.copy()
    
    # Nova L√≥gica: Contar n√∫mero de itens na lista de iconografias
    df_local['qtd_imagens'] = df_local['iconografias'].apply(
        lambda x: len(x) if isinstance(x, list) else 0
    )
    
    resumo = (
        df_local.groupby('n')['qtd_imagens']
        .agg(total_imagens='sum')
        .reset_index()
    )
    
    resumo['n'] = resumo['n'].astype(str)

    # Garante ordena√ß√£o correta no gr√°fico
    if 'n' in resumo.columns:
        resumo['n'] = pd.Categorical(resumo['n'], categories=ORDEM_SIBILA, ordered=True)
        resumo = resumo.sort_values('n')

    resumo.index = resumo.index + 1
    
    # Renomear coluna para exibi√ß√£o
    resumo_display = resumo.rename(columns={'total_imagens': 'Total de Imagens'})
    
    st.dataframe(resumo_display, width='stretch')
    
    fig = px.bar(
        resumo,
        x='n',
        y='total_imagens',
        text=resumo['total_imagens'].map(lambda x: f"{x}")
    )
    fig.update_layout(
        height=380,
        title="Total de Imagens por Revista",
        xaxis_title="n.",
        yaxis_title="Quantidade de Imagens"
    )
    fig.update_xaxes(type='category', tickmode='linear')
    st.plotly_chart(fig, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(resumo)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_iconografia_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = resumo.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_iconografia_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(resumo_display, "Iconografia por revista")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_iconografia_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_autores_assunto_colab(df):
    st.markdown("#### Autores como assunto vs colaboradores")
    s_colab = DataModule.get_normalized_series(df, 'autores_colaboradores')
    s_ass = DataModule.get_normalized_series(df, 'nome_pessoal_como_assunto')
    df_colab = UtilsModule.calculate_stats_with_percentage(s_colab)
    df_ass = UtilsModule.calculate_stats_with_percentage(s_ass)
    
    # Ajuste visual do √≠ndice para come√ßar em 1
    df_colab.index = df_colab.index + 1
    df_ass.index = df_ass.index + 1
    
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**Colaboradores (top 20)**")
        st.dataframe(df_colab.head(20), width='stretch')
    with c2:
        st.markdown("**Nomes pessoais como assunto (top 20)**")
        st.dataframe(df_ass.head(20), width='stretch')
    intersect = set(df_colab['Termo']).intersection(set(df_ass['Termo']))
    st.markdown("---")
    st.markdown("##### Interse√ß√µes (quem √© autor e tema)")
    if intersect:
        st.write(", ".join(sorted(list(intersect))))
    else:
        st.write("Nenhuma interse√ß√£o encontrada.")
        
    st.markdown("##### Exportar")
    col1, col2 = st.columns(2)
    
    # Exportar Tabelas Completas (Top 20 apenas para visualiza√ß√£o, mas exporta√ß√£o pode ser completa ou top 20. 
    # O usu√°rio pediu "Autores Colaboradores (Top 20)" e "Nomes Pessoais como Assunto (Top 20)" no PDF.
    # Vamos exportar o Top 20 no PDF conforme solicitado.
    
    pdf_duplo = PDFModule.gerar_pdf_duas_tabelas(
        df_colab.head(20), "Autores Colaboradores (Top 20)",
        df_ass.head(20), "Nomes Pessoais como Assunto (Top 20)",
        "Autores como Assunto vs Colaboradores"
    )
    
    col1.download_button(
        "üìÑ PDF (Top 20 de ambos)",
        pdf_duplo,
        f"rel_autores_assunto_colab_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_tipos_textuais(df):
    st.markdown("#### An√°lise por tipos textuais")
    df_local = df.copy()
    df_local['tipo_base'] = df_local['vocabulario_controlado'].astype(str).apply(
        lambda x: 'Manifesto' if 'manifesto' in x.lower() else x.split(' - ')[0]
    )
    counts = df_local['tipo_base'].value_counts().reset_index()
    counts.columns = ['Tipo textual', 'Num. Absoluto']
    total = counts['Num. Absoluto'].sum()
    counts['Percentual'] = (counts['Num. Absoluto'] / total * 100).map(lambda x: f"{x:.2f}%")
    counts.index = counts.index + 1
    st.dataframe(counts, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(counts)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_tipos_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = counts.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_tipos_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(counts, "Tipos textuais")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_tipos_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_manifesto(df):
    st.markdown("#### Textos relacionados a 'Manifesto' (tipo textual, palavra-chave ou t√≠tulo)")
    df_local = df.copy()
    def verificar_manifesto(registro):
        locais = []
        tipo = str(registro.get('vocabulario_controlado', '')).lower()
        if 'manifesto' in tipo:
            locais.append('Tipo textual')
        kw = registro.get('palavras_chave', [])
        if isinstance(kw, list):
            for palavra in kw:
                if palavra and 'manifesto' in str(palavra).lower():
                    locais.append('Palavra-chave')
                    break
        titulo = str(registro.get('titulo_artigo', '')).lower()
        if 'manifesto' in titulo:
            locais.append('T√≠tulo')
        resumo = str(registro.get('resumo', '')).lower()
        if 'manifesto' in resumo:
            locais.append('Resumo')
        return locais

    df_local['locais_manifesto'] = df_local.apply(verificar_manifesto, axis=1)
    df_man = df_local[df_local['locais_manifesto'].apply(lambda x: len(x) > 0)].copy()
    st.write(f"Registros encontrados: {len(df_man)} de {len(df)} (total da base)")
    if not df_man.empty:
        df_man['onde_encontrado'] = df_man['locais_manifesto'].apply(lambda x: ', '.join(x))
        
        # Preparar dataframe para exibi√ß√£o com √≠ndice come√ßando em 1
        df_display = df_man[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo', 'onde_encontrado']].copy()
        df_display.reset_index(drop=True, inplace=True)
        df_display.index = df_display.index + 1
        
        st.dataframe(
            df_display,
            column_config={
                'n': 'Revista',
                'registro': 'Registro',
                'vocabulario_controlado': 'Tipo',
                'titulo_artigo': 'T√≠tulo',
                'onde_encontrado': 'Encontrado em'
            },
            width='stretch'
        )
        st.markdown("##### Exportar")
        col1, col2, col3 = st.columns(3)
        df_export = df_man[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo', 'palavras_chave', 'onde_encontrado']].copy()
        excel_rel = UtilsModule.converter_excel(df_export)
        col1.download_button(
            "üìä EXCEL",
            excel_rel,
            f"rel_manifesto_{datetime.now().strftime('%Y%m%d')}.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            width='stretch'
        )
        csv_rel = df_export.to_csv(index=False, encoding='utf-8-sig')
        col2.download_button(
            "üìã CSV",
            csv_rel,
            f"rel_manifesto_{datetime.now().strftime('%Y%m%d')}.csv",
            "text/csv",
            width='stretch'
        )
        pdf_rel = PDFModule.gerar_pdf_analitico(df_man, len(df), "Manifesto")
        col3.download_button(
            "üìÑ PDF",
            pdf_rel,
            f"rel_manifesto_{datetime.now().strftime('%Y%m%d')}.pdf",
            "application/pdf",
            width='stretch'
        )
    else:
        st.info("Nenhum registro relacionado a 'Manifesto' foi encontrado na base.")

def relatorio_sibila(df):
    st.markdown("#### Textos relacionados a 'Sibila' (tipo textual, palavra-chave ou t√≠tulo)")
    df_local = df.copy()
    def verificar_sibila(registro):
        locais = []
        tipo = str(registro.get('vocabulario_controlado', '')).lower()
        if 'sibil' in tipo:
            locais.append('Tipo textual')
        kw = registro.get('palavras_chave', [])
        if isinstance(kw, list):
            for palavra in kw:
                if palavra and 'sibil' in str(palavra).lower():
                    locais.append('Palavra-chave')
                    break
        titulo = str(registro.get('titulo_artigo', '')).lower()
        if 'sibil' in titulo:
            locais.append('T√≠tulo')
        resumo = str(registro.get('resumo', '')).lower()
        if 'sibil' in resumo:
            locais.append('Resumo')
        return locais

    df_local['locais_sibila'] = df_local.apply(verificar_sibila, axis=1)
    df_sib = df_local[df_local['locais_sibila'].apply(lambda x: len(x) > 0)].copy()
    st.write(f"Registros encontrados: {len(df_sib)} de {len(df)} (total da base)")
    if not df_sib.empty:
        df_sib['onde_encontrado'] = df_sib['locais_sibila'].apply(lambda x: ', '.join(x))
        
        # Preparar dataframe para exibi√ß√£o com √≠ndice come√ßando em 1
        df_display = df_sib[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo', 'onde_encontrado']].copy()
        df_display.reset_index(drop=True, inplace=True)
        df_display.index = df_display.index + 1
        
        st.dataframe(
            df_display,
            column_config={
                'n': 'Revista',
                'registro': 'Registro',
                'vocabulario_controlado': 'Tipo',
                'titulo_artigo': 'T√≠tulo',
                'onde_encontrado': 'Encontrado em'
            },
            width='stretch'
        )
        st.markdown("##### Exportar")
        col1, col2, col3 = st.columns(3)
        df_export = df_sib[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo', 'palavras_chave', 'onde_encontrado']].copy()
        excel_rel = UtilsModule.converter_excel(df_export)
        col1.download_button(
            "üìä EXCEL",
            excel_rel,
            f"rel_sibila_{datetime.now().strftime('%Y%m%d')}.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            width='stretch'
        )
        csv_rel = df_export.to_csv(index=False, encoding='utf-8-sig')
        col2.download_button(
            "üìã CSV",
            csv_rel,
            f"rel_sibila_{datetime.now().strftime('%Y%m%d')}.csv",
            "text/csv",
            width='stretch'
        )
        pdf_rel = PDFModule.gerar_pdf_analitico(df_sib, len(df), "Sibila")
        col3.download_button(
            "üìÑ PDF",
            pdf_rel,
            f"rel_sibila_{datetime.now().strftime('%Y%m%d')}.pdf",
            "application/pdf",
            width='stretch'
        )
    else:
        st.info("Nenhum registro relacionado a 'Sibila' foi encontrado na base.")

def relatorio_palavras_chave(df):
    st.markdown("#### Estat√≠sticas de palavras-chave (vocabul√°rio controlado)")
    s = DataModule.get_normalized_series(df, 'palavras_chave')
    counts = UtilsModule.calculate_stats_with_percentage(s)
    df_stats = counts.rename(
        columns={'Termo': 'Palavra-chave', 'Qtd': 'Num. Absoluto', '%': 'Percentual'}
    )
    df_stats.index = df_stats.index + 1
    st.dataframe(df_stats, width='stretch')
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    excel_rel = UtilsModule.converter_excel(df_stats)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_palavras_chave_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    csv_rel = df_stats.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_palavras_chave_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(df_stats, "Palavras-chave")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_palavras_chave_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

def relatorio_densidade_paginas(df):
    st.markdown("#### Densidade de Imagens por P√°ginas")
    
    def obter_ultima_pagina_revista(df_revista):
        # Encontra o maior n√∫mero de p√°gina citado em toda a edi√ß√£o
        max_pag = 0
        for pag in df_revista['paginas']:
            try:
                # Extrai todos os n√∫meros e pega o √∫ltimo (ex: "10-25" -> 25)
                nums = [int(n) for n in re.findall(r'\d+', str(pag))]
                if nums:
                    local_max = max(nums)
                    if local_max > max_pag:
                        max_pag = local_max
            except:
                continue
        return max_pag if max_pag > 0 else 1 # Evita divis√£o por zero

    def contar_imagens(row):
        # Conta o n√∫mero de itens na lista de iconografias
        icons = row.get('iconografias', [])
        if isinstance(icons, list):
            return len(icons)
        return 0

    rows = []
    # Agrupa por n√∫mero da revista
    for rev, sub in df.groupby('n'):
        # Denominator: √öltima p√°gina f√≠sica da revista
        total_paginas_revista = obter_ultima_pagina_revista(sub)
        
        # Numerator: Soma da quantidade de itens de iconografia
        soma_imagens = 0
        for _, row in sub.iterrows():
            soma_imagens += contar_imagens(row)
            
        # Densidade: Imagens por p√°gina (ou % de ocupa√ß√£o conforme solicitado, mas a l√≥gica agora √© Imagens / P√°ginas)
        # O usu√°rio pediu: "Numerador (Ocupa√ß√£o): Soma itens iconografia", "Denominador: √öltima p√°gina"
        # O t√≠tulo original era "% da revista ocupada por ilustra√ß√µes".
        # Se tivermos 50 imagens em 100 p√°ginas, a densidade √© 0.5 imagens/p√°gina.
        # Se multiplicarmos por 100, seria "50%".
        # Vou manter a l√≥gica de porcentagem/densidade mas com os novos valores.
        
        pct = (soma_imagens / total_paginas_revista * 100)
        
        rows.append({
            "n.": str(rev),
            "Total de Imagens": soma_imagens,
            "Total P√°ginas Revista": total_paginas_revista,
            "Densidade (Img/P√°g %)": pct
        })
        
    df_rel = pd.DataFrame(rows)
    # Garante ordena√ß√£o correta no gr√°fico
    if 'n.' in df_rel.columns:
        df_rel['n.'] = pd.Categorical(df_rel['n.'], categories=ORDEM_SIBILA, ordered=True)
        df_rel = df_rel.sort_values('n.')

    df_rel.index = df_rel.index + 1
    
    st.dataframe(df_rel, width='stretch')
    
    # Gr√°fico
    fig = px.bar(
        df_rel, 
        x="n.", 
        y="Densidade (Img/P√°g %)", 
        text=df_rel["Densidade (Img/P√°g %)"].map(lambda x: f"{x:.1f}")
    )
    fig.update_layout(
        height=380, 
        title="Densidade de Imagens (Volume de Imagens / Total de P√°ginas)",
        xaxis_title="n.",
        yaxis_title="Densidade"
    )
    fig.update_xaxes(type='category', tickmode='linear')
    st.plotly_chart(fig, width='stretch')
    
    # Exportar
    st.markdown("##### Exportar")
    col1, col2, col3 = st.columns(3)
    
    excel_rel = UtilsModule.converter_excel(df_rel)
    col1.download_button(
        "üìä EXCEL",
        excel_rel,
        f"rel_densidade_imagens_{datetime.now().strftime('%Y%m%d')}.xlsx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        width='stretch'
    )
    
    csv_rel = df_rel.to_csv(index=False, encoding='utf-8-sig')
    col2.download_button(
        "üìã CSV",
        csv_rel,
        f"rel_densidade_imagens_{datetime.now().strftime('%Y%m%d')}.csv",
        "text/csv",
        width='stretch'
    )
    
    pdf_rel = PDFModule.gerar_pdf_tabela_estatistica(df_rel, "Densidade de Imagens por P√°ginas")
    col3.download_button(
        "üìÑ PDF",
        pdf_rel,
        f"rel_densidade_imagens_{datetime.now().strftime('%Y%m%d')}.pdf",
        "application/pdf",
        width='stretch'
    )

# ==========================================
# 5. MAIN APP LOGIC
# ==========================================

def main():
    # ===== LOGO NELIC =====
    with st.sidebar:
        try:
            st.image("Nelic-imagem.png", use_container_width=True)
        except:
            st.error("Imagem n√£o encontrada no caminho especificado.")
            st.markdown("## NELIC")  # Fallback
        st.write("")  # Espa√ßamento

    # ==================================================
    # SISTEMA DE AUTENTICA√á√ÉO
    # ==================================================

    # Campo de senha na sidebar
    with st.sidebar:
        senha_digitada = st.text_input(
            "üîê √Årea Restrita (Catalogadores)",
            type="password",
            placeholder="Digite a senha..."
        )

    # Verificar autentica√ß√£o
    usuario_autenticado = False
    senha_correta = None

    # Tenta pegar a senha dos secrets
    try:
        if "SENHA_ADMIN" in st.secrets:
            senha_correta = st.secrets["SENHA_ADMIN"]
    except:
        pass

    # Se n√£o encontrou nos secrets, exibe aviso
    if senha_correta is None:
        if senha_digitada:
            st.sidebar.error("‚ö†Ô∏è Configure SENHA_ADMIN em .streamlit/secrets.toml")
    # Verifica se a senha est√° correta
    elif senha_digitada == senha_correta:
        usuario_autenticado = True
        st.sidebar.success("‚úÖ Modo Editor: ATIVADO")

        # Detecta se est√° rodando no Streamlit Cloud
        is_cloud = os.environ.get('STREAMLIT_SHARING_MODE') or os.environ.get('STREAMLIT_SERVER_HEADLESS')

        if is_cloud:
            st.sidebar.warning("‚ö†Ô∏è **Aten√ß√£o**: Dados inseridos online n√£o s√£o salvos permanentemente. Para cataloga√ß√£o segura, use o sistema local no seu computador.")
    elif senha_digitada:
        st.sidebar.error("‚ùå Senha incorreta")

    st.sidebar.markdown("---")

    # ==================================================
    # MENU ADAPTATIVO (baseado na autentica√ß√£o)
    # ==================================================

    # Menu completo para usu√°rios autenticados
    if usuario_autenticado:
        opcoes_menu = [
            "NELIC",
            "CATALOGA√á√ÉO",
            "FICHAS & NOTAS",
            "EXPLORAR DADOS",
            "RELAT√ìRIOS",
            "AN√ÅLISE COMPARATIVA",
            "AN√ÅLISE AVAN√áADA",  # Nova aba para Humanidades Digitais
            "DI√ÅRIO DE PESQUISA",
            "METODOLOGIA",
            "MAIS DADOS",
            "EXPORTAR",
            "QUALIDADE DOS DADOS"
        ]
        icones_menu = [
            "house-fill",
            "pencil-square",
            "file-text",
            "search",
            "graph-up",
            "diagram-3",
            "lightbulb",  # √çcone para An√°lise Avan√ßada
            "journal-text",
            "book",
            "database",
            "download",
            "shield-check"
        ]
    else:
        # Menu p√∫blico (apenas visualiza√ß√£o)
        opcoes_menu = [
            "NELIC",
            "FICHAS & NOTAS",
            "EXPLORAR DADOS",
            "RELAT√ìRIOS",
            "AN√ÅLISE COMPARATIVA",
            "AN√ÅLISE AVAN√áADA",  # Nova aba para Humanidades Digitais
            "METODOLOGIA",
            "MAIS DADOS",
            "QUALIDADE DOS DADOS"
        ]
        icones_menu = [
            "house-fill",
            "file-text",
            "search",
            "graph-up",
            "diagram-3",
            "lightbulb",  # √çcone para An√°lise Avan√ßada
            "book",
            "database",
            "shield-check"
        ]

    # ===== MENU DE NAVEGA√á√ÉO LIMPO =====
    with st.sidebar:
        menu = option_menu(
            menu_title=None,  # Remove o t√≠tulo "NAVEGA√á√ÉO"
            options=opcoes_menu,
            icons=icones_menu,
            default_index=0,
            orientation="vertical",
            styles={
                "container": {
                    "padding": "0!important",
                    "background-color": "#ffffff"  # Fundo Branco
                },
                "icon": {
                    "color": "#366092",  # √çcones Azul
                    "font-size": "14px"
                },
                "nav-link": {
                    "color": "#366092",  # Texto Azul
                    "font-size": "15px",
                    "text-align": "left",
                    "margin": "0px",
                    "padding": "10px 12px",
                    "border-radius": "6px",
                    "font-weight": "bold",  # Negrito
                    "--hover-color": "#f0f2f6"
                },
                "nav-link-selected": {
                    "background-color": "#366092",  # Fundo Azul quando selecionado
                    "color": "white"  # Texto Branco quando selecionado
                }
            }
        )

    st.sidebar.markdown("---")

    # Status do sistema
    if usuario_autenticado:
        st.sidebar.markdown("üîì **Modo Catalogador**")
    else:
        st.sidebar.markdown("üëÅÔ∏è **Modo Visitante**")
        st.sidebar.info("üí° Digite a senha acima para catalogar")

    dados = PersistenceModule.load_data()
    df = pd.DataFrame(dados)
    df = UtilsModule.sanitizar_dataframe(df)

    # --- CORRE√á√ÉO ESTRUTURAL: ORDENA√á√ÉO DE REVISTAS ---
    # Converte a coluna 'n' para categ√≥rica com ordem definida
    if 'n' in df.columns:
        df['n'] = df['n'].astype(str)
        df['n'] = pd.Categorical(df['n'], categories=ORDEM_SIBILA, ordered=True)

    # --- NELIC ---
    if menu == "NELIC":
        st.title("N√öCLEO DE ESTUDOS LITER√ÅRIOS & CULTURAIS")
        st.markdown("---")

        # Introdu√ß√£o
        st.markdown("""
        O **N√∫cleo de Estudos Liter√°rios e Culturais (NELIC)**, sediado no Departamento de L√≠ngua e
        Literatura Vern√°culas da UFSC, consolidou-se desde meados dos anos 1990 como um dos principais
        laborat√≥rios de pesquisa sobre **periodismo liter√°rio e cultural**, **forma√ß√£o de c√¢nones** e
        **arquivo no Brasil**, articulando cr√≠tica liter√°ria, teoria cultural, estudos de poesia e
        reflex√£o sobre o contempor√¢neo.

        Seu eixo estruturante √© o estudo de revistas, jornais e suplementos culturais (sobretudo da
        segunda metade do s√©culo XX) e a constru√ß√£o de um amplo arquivo e base de dados, a partir dos
        quais se interrogam a modernidade, a mem√≥ria, o anacronismo e a pr√≥pria ideia de literatura.
        """)

        st.markdown("---")

        # Origem e perfil institucional
        st.markdown("## 1. Origem e Perfil Institucional")
        st.markdown("""
        O NELIC nasce em **1996**, no CCE/UFSC, vinculado ao Departamento de L√≠ngua e Literatura
        Vern√°culas (DLLV), a partir do projeto integrado **"Po√©ticas Contempor√¢neas"**, coordenado
        por **Maria Lucia de Barros Camargo**.

        Desde sua cria√ß√£o, se define como **laborat√≥rio de forma√ß√£o de pesquisadores** (gradua√ß√£o e
        p√≥s-gradua√ß√£o) em cr√≠tica textual e cr√≠tica cultural, dedicando-se ao mapeamento da cr√≠tica
        liter√°ria e cultural brasileira a partir dos anos 1970, por meio da indexa√ß√£o e estudo de
        peri√≥dicos liter√°rios e/ou culturais em circula√ß√£o no pa√≠s.

        O trabalho √© descrito como uma leitura do peri√≥dico como **"tecido sem√¢ntico"**, cuja
        inteligibilidade depende de leitura retrospectiva e de cruzamentos de dados, bem como uma
        proposta de **"ciclo de leitura da cr√≠tica liter√°ria e cultural"**, que vai do texto cr√≠tico
        √† cr√≠tica da cr√≠tica, produzindo uma metacr√≠tica do campo.
        """)

        st.markdown("---")

        # Acervo e Base de Dados
        st.markdown("## 2. Acervo e Base de Dados")

        col_acervo1, col_acervo2 = st.columns([3, 2])

        with col_acervo1:
            st.markdown("""
            O NELIC mant√©m um amplo **acervo f√≠sico de peri√≥dicos liter√°rios e culturais** ‚Äì
            revistas, jornais e suplementos, nacionais e estrangeiros ‚Äì aberto √† consulta e pesquisa local.

            Esse acervo √© complementado pela **Base de Dados "Periodismo Liter√°rio e Cultural"**, que:

            - üìä Re√∫ne mais de **46 mil artigos indexados**
            - üì∞ Cobre cerca de **70 revistas, jornais e suplementos**
            - üîç Permite busca por palavras-chave, autores colaboradores, autores citados, resumos
            """)

        with col_acervo2:
            st.info("""
            **Peri√≥dicos Mapeados:**

            ‚Ä¢ Revista Civiliza√ß√£o Brasileira
            ‚Ä¢ Folhetim e Mais! (Folha de S.Paulo)
            ‚Ä¢ Revista do Livro
            ‚Ä¢ Cult
            ‚Ä¢ Argumento
            ‚Ä¢ Opini√£o
            ‚Ä¢ Versus
            ‚Ä¢ Revista USP
            ‚Ä¢ Almanaque
            ‚Ä¢ Revista Brasileira de Poesia
            ‚Ä¢ Jos√©
            ‚Ä¢ 34 Letras
            ‚Ä¢ Entre outros
            """)

        st.markdown("---")

        # Boletim de Pesquisa NELIC
        st.markdown("## 3. Boletim de Pesquisa NELIC")
        st.markdown("""
        O **Boletim de Pesquisa NELIC** √© o peri√≥dico cient√≠fico semestral do n√∫cleo, voltado √†
        publica√ß√£o de textos acad√™micos nas √°reas de literatura e cultura contempor√¢neas, com √™nfase
        em produ√ß√£o brasileira e latino-americana.

        **Dados Institucionais:**
        - üìÖ In√≠cio da publica√ß√£o: **1997**
        - üî¢ ISSN (online): **1984-784X**
        - üåê Indexado em: DOAJ, Latindex, OpenAlex, ROAD, CariNiana
        """)

        st.markdown("---")

        # Pesquisadores Principais
        st.markdown("## 4. Pesquisadores Principais")

        # Maria Lucia de Barros Camargo
        with st.expander("**Maria Lucia de Barros Camargo** - Fundadora e Pesquisadora S√™nior"):
            st.markdown("""
            **Bolsista de Produtividade em Pesquisa do CNPq - N√≠vel 1B**
            
            Endere√ßo para acessar o Lattes: http://lattes.cnpq.br/7854330137879524

            **Trajet√≥ria:**
            - Doutora em Letras (Teoria Liter√°ria e Literatura Comparada) pela USP (1990)
            - Tese sobre a poesia de **Ana Cristina Cesar**
            - Professora titular de Teoria Liter√°ria (aposentada em 2019)
            - Criadora do NELIC e do projeto "Po√©ticas Contempor√¢neas" (1996)
            - Vice-presidente da ABRALIC (1996-1998)
            - Pr√≥-Reitora de P√≥s-Gradua√ß√£o da UFSC (2008-2012)
            - Coordenadora do PPG em Literatura (2013-2018)

            **√Åreas de Pesquisa:**
            - Periodismo cultural
            - Revistas liter√°rias
            - Poesia contempor√¢nea
            - Anos 70
            - Cr√≠tica cultural

            **Obra Principal:**
            *Atr√°s dos olhos pardos: uma leitura da poesia de Ana Cristina Cesar* (Editora Argos, 2003)
            """)

        # Carlos Eduardo Schmidt Capela
        with st.expander("**Carlos Eduardo Schmidt Capela** - Coordenador Atual"):
            st.markdown("""
            **Bolsista de Produtividade em Pesquisa do CNPq - N√≠vel 1D**
            
            Endere√ßo para acessar o Lattes: http://lattes.cnpq.br/6619827107636765

            **Coordena√ß√£o:**
            - Coordenador docente do NELIC
            - Editor do Boletim de Pesquisa NELIC

            **Projetos de Pesquisa:**
            - *Heran√ßas de andan√ßas de Ahasverus pela Am√©rica Latina* (2023‚Äìatual)
            - *Ahasverus (heran√ßas : err√¢ncias : hi√¢ncias)* (2019‚Äì2023)
            - *A gesta entre n√≥s, tal gesto: disposi√ß√µes e dispositivos* (2013‚Äì2019)

            **Linha de Pesquisa:**
            Literaturas comparadas, estudos de arquivos ficcionais e figura√ß√µes da err√¢ncia e da estrangeiridade
            """)

        # Ra√∫l Antelo
        with st.expander("**Ra√∫l Antelo** - Pesquisador S√™nior"):
            st.markdown("""
            Endere√ßo para acessar o Lattes: http://lattes.cnpq.br/4828668706498888

            **Trajet√≥ria:**
            - Cr√≠tico e te√≥rico argentino-brasileiro (n. 1950)
            - Professor titular de Literatura Brasileira na UFSC (aposentado)
            - Pesquisador do CNPq
            - Guggenheim Fellow
            - Ex-presidente da ABRALIC
            - Doutorado *honoris causa* pela Universidad Nacional de Cuyo

            **Projeto Atual:**
            *Por uma conceitua√ß√£o da bioest√©tica: arquivo e diagramas do vivente na Am√©rica Latina* (2018‚Äìatual)

            **Obras Principais:**
            - *Literatura em revista*
            - *Jo√£o do Rio: o d√¢ndi e a especula√ß√£o*
            - *Maria com Marcel. Duchamp nos tr√≥picos*
            - *Archifilolog√≠as latinoamericanas*
            - *Cr√≠tica ac√©fala*
            - *A m√°quina afilol√≥gica*
            - *A ruinologia*
            """)

        st.markdown("---")

        # Outros pesquisadores e linhas de pesquisa
        st.markdown("## 5. Outros Pesquisadores e Linhas de Pesquisa no NELIC")

        st.markdown("""
        Atuando em projetos que articulam **cr√≠tica e cria√ß√£o na modernidade**, **po√©ticas da Am√©rica Latina**,
        **autografias e escritas de si**, **literatura**, **cinema**, **cultura**, e **contracultura**.
        """)

        # Pesquisadores por categoria
        with st.expander("üë• **Pesquisadores do NELIC** (expandir para ver lista completa)"):
            st.markdown("""
            **Docentes:**
            Carlos Eduardo Schmidt Capela, Maria Lucia de Barros Camargo, Ra√∫l Antelo, Jorge Hoffmann Wolff,
            Artur de Vargas Giorgi, Andr√© Fiorussi, Jair Tadeu da Fonseca, La√≠se Ribas Bastos,
            Luz Maria Luisa Rodriguez, Manoel Ricardo de Lima, J√∫lia Vasconcelos Studart, Renata Telles,
            Valentina da Silva Nunes, Jeferson Candido, Fernando Floriani Petry.

            **Doutorado:**
            Joaqu√≠n Emanuel Correa, Adner De Almeida Sena, Alessandra Guterres Deifeld, Allende Renck Pereira,
            Andr√© Vichara Barcellos, Arthur Katrein Mora, Carlos Speck Pereira, Dennis Lauro Rad√ºnz,
            Denise Rogenski Raizel, Diogo Araujo Da Silva, Gabriela Cristina Carvalho Gon√ßalves Dos Santos,
            Isabel Cristina Costa Louzada, Jo√£o Paulo Zarelli Rocha, Julio Aied Passos, Karoline Zampiva Corr√™a,
            Lisbeth Juliana Monroy Ortiz, Lucas De Mello Schlemper, Lucas Garcia Nunes, Luci√©le Bernardi De Souza,
            Mar√≠a Mercedes Rodriguez, Patr√≠cia Galelli, Raquel de Figueredo Eltermann, Renato Bradbury De Oliveira,
            S√©rgio Leite Barboza, Sinval Soares Paulino, William Fernandes Rabelo Da Silva, Wilson Sousa Oliveira.

            **Mestrado:**
            Carolina Maria Cardoso Pilati, Clara Padial Lucas, Clareana Moreira De Castro Eug√™nio,
            Emmanuele Amaral Santos, Matheus Reiser Muller, Renato Rodrigues, Zulmar Dustin Ribeiro Anchieta.

            **Gradua√ß√£o:**
            Nycolas Gomes Correia, Vivianne Oliveira Rodrigues.
            """)

        st.info("""
        **Nota:** O NELIC funciona como rede de pesquisadores associados e ex‚Äëorientandos.
        Nesse sentido, listamos La√≠se Ribas Bastos, Jeferson Candido, Simone Dias, Fernando Floriani Petry,
        Renata Telles, Valentina Nunes, J√∫lia Studart, Manoel Ricardo de Lima, que hoje atuam em outras
        institui√ß√µes e continuam vinculados a projetos ou publica√ß√µes do n√∫cleo.
        """)

        st.markdown("---")

        # Forma√ß√£o de Pesquisadores: Teses e Disserta√ß√µes
        st.markdown("## 6. Forma√ß√£o de Pesquisadores: Teses e Disserta√ß√µes")
        st.markdown("""
        O **NELIC** mant√©m listas extensas de **teses e disserta√ß√µes** defendidas sob sua √©gide,
        sobretudo no **Programa de P√≥s-Gradua√ß√£o em Literatura (PPGLit/UFSC)**, abrangendo temas
        centrais do n√∫cleo com forte inser√ß√£o nacional e latino‚Äëamericana.

        O n√∫cleo integra o PPGLit/UFSC, atuando na forma√ß√£o de mestres e doutores com foco em:

        - Literatura Brasileira Contempor√¢nea
        - Teoria Liter√°ria e Cr√≠tica Cultural
        - Pr√°ticas de Arquivo e Mem√≥ria Liter√°ria
        - Metodologia NELIC de cataloga√ß√£o e an√°lise de peri√≥dicos
        - Periodismo Liter√°rio e Cultural

        Al√©m disso, desde sua funda√ß√£o, o n√∫cleo incorpora estudantes de **gradua√ß√£o** (bolsistas de
        Inicia√ß√£o Cient√≠fica PIBIC/CNPq e volunt√°rios) em suas atividades de cataloga√ß√£o, digitaliza√ß√£o e
        pesquisa, promovendo a forma√ß√£o completa do pesquisador acad√™mico.
        """)

        st.markdown("---")

        # Contato
        st.markdown("## üìß Contato e Informa√ß√µes")

        col_contato1, col_contato2 = st.columns(2)

        with col_contato1:
            st.markdown("""
            **Website:**
            [nelic.ufsc.br](http://nelic.ufsc.br)

            **Boletim de Pesquisa NELIC:**
            [periodicos.ufsc.br/index.php/nelic](https://periodicos.ufsc.br/index.php/nelic)

            **Base de Dados:**
            Acesso via site do NELIC
            """)

        with col_contato2:
            st.markdown("""
            **Endere√ßo:**
            Universidade Federal de Santa Catarina
            Centro de Comunica√ß√£o e Express√£o
            Departamento de L√≠ngua e Literatura Vern√°culas
            Campus Universit√°rio - Trindade
            88040-900 - Florian√≥polis - SC
            """)

        st.markdown("---")

        st.info("""
        üí° **Mais Informa√ß√µes:** O NELIC est√° aberto √† colabora√ß√£o com pesquisadores, projetos
        interinstitucionais e consultas ao acervo f√≠sico mediante agendamento. Entre em contato
        para mais detalhes sobre o acesso √† Base de Dados, possibilidades de pesquisa conjunta ou
        orienta√ß√µes acad√™micas na √°rea de periodismo liter√°rio e cultural.
        """)

    # --- CATALOGA√á√ÉO ---
    elif menu == "CATALOGA√á√ÉO":
        st.title("EDITOR DE REGISTROS")
        form = CatalogacaoForm(dados, df)

        # Sele√ß√£o de Modo com Bot√£o de Limpeza
        col_mode1, col_mode2, col_mode3 = st.columns([2, 3, 5])
        with col_mode1:
            st.markdown("**Modo:**")
        with col_mode2:
            mode = st.radio("Selecione:", ["NOVO REGISTRO", "EDITAR EXISTENTE"], key="mode_radio", horizontal=True, label_visibility="collapsed")
        with col_mode3:
            # Bot√£o LIMPAR TUDO - s√≥ aparece e funciona em NOVO REGISTRO
            if 'mode_radio' in st.session_state and st.session_state.mode_radio == "NOVO REGISTRO":
                if st.button("üóëÔ∏è LIMPAR TUDO", help="Limpa todos os campos do formul√°rio"):
                    # Limpar TUDO no session_state relacionado ao formul√°rio
                    st.session_state.selected_record = None
                    st.session_state.loaded_json = None
                    st.session_state.clear_json_input = True
                    st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento

                    # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
                    if 'form_clear_counter' not in st.session_state:
                        st.session_state.form_clear_counter = 0
                    st.session_state.form_clear_counter += 1

                    # Limpar TODOS os campos do formul√°rio e busca
                    keys_to_delete = [key for key in st.session_state.keys()
                                      if key.startswith('form_') or key.startswith('busca_') or
                                      key.startswith('confirm_delete_') or key.startswith('sel_tipo_') or
                                      key.startswith('sel_subtipo_') or key.startswith('icon_')]
                    for key in keys_to_delete:
                        del st.session_state[key]
                    
                    # Limpar lista de linhas de iconografia
                    if 'iconografias_rows' in st.session_state:
                        st.session_state.iconografias_rows = []

                    st.success("‚úÖ Formul√°rio limpo!")
                    time.sleep(0.3)
                    st.rerun()

        # Inicializar session_state para registro selecionado
        if 'selected_record' not in st.session_state:
            st.session_state.selected_record = None

        # Limpar registro selecionado e formul√°rio ao mudar de modo
        if 'previous_mode' not in st.session_state:
            st.session_state.previous_mode = mode
        if st.session_state.previous_mode != mode:
            st.session_state.selected_record = None
            st.session_state.loaded_json = None
            st.session_state.previous_mode = mode
            st.session_state.current_editing_record_id = None  # ‚ö†Ô∏è CORRE√á√ÉO: Resetar rastreamento
            # Incrementar contador para for√ßar recria√ß√£o do formul√°rio
            if 'form_clear_counter' not in st.session_state:
                st.session_state.form_clear_counter = 0
            st.session_state.form_clear_counter += 1
            # Limpar TODOS os campos do formul√°rio ao mudar de modo
            for key in list(st.session_state.keys()):
                if key.startswith('form_') or key.startswith('busca_') or key.startswith('confirm_delete_') or key.startswith('icon_'):
                    del st.session_state[key]
            # IMPORTANTE: Recarregar a p√°gina para aplicar a limpeza
            st.rerun()

        rec = {}

        # No modo NOVO REGISTRO, garantir que rec seja vazio se n√£o houver registro carregado
        if mode == "NOVO REGISTRO":
            # Se selected_record for None, garantir que rec seja vazio
            if st.session_state.selected_record is None:
                rec = {}
            else:
                rec = st.session_state.selected_record

        # L√≥gica de Editar Existente
        elif mode == "EDITAR EXISTENTE" and dados:
            st.markdown("---")
            st.markdown("### üîç BUSCAR REGISTRO PARA EDITAR")

            # Campos de busca
            col1, col2, col3 = st.columns(3)
            with col1:
                # Listar todas as revistas √∫nicas
                # Ordena√ß√£o correta na lista de sele√ß√£o manual
                revs_existentes = list(set([str(d.get('n', '')) for d in dados if d.get('n')]))
                revistas_disponiveis = sorted(
                    revs_existentes,
                    key=lambda x: ORDEM_SIBILA.index(x) if x in ORDEM_SIBILA else 999
                )
                revista_busca = st.selectbox("N¬∫ REVISTA", [""] + revistas_disponiveis, key="busca_revista")

            with col2:
                # Filtrar registros por revista selecionada e criar lista com t√≠tulos
                if revista_busca:
                    registros_filtrados = [d for d in dados if str(d.get('n', '')) == revista_busca]
                else:
                    registros_filtrados = dados

                # Criar dicion√°rio: "registro - t√≠tulo" -> dados completos
                registros_opcoes = {}
                for d in registros_filtrados:
                    if d.get('registro'):
                        titulo = d.get('titulo_artigo', '[sem t√≠tulo]')
                        # Limitar t√≠tulo a 60 caracteres
                        titulo_curto = titulo[:60] + "..." if len(titulo) > 60 else titulo
                        chave = f"{d.get('registro')} - {titulo_curto}"
                        registros_opcoes[chave] = d

                # Ordenar por n√∫mero de registro (extrair parte num√©rica para ordena√ß√£o correta)
                def extrair_numero(chave):
                    try:
                        # Extrair "10 de 23" -> 10
                        parte_reg = chave.split(' - ')[0]  # "10 de 23"
                        numero = parte_reg.split(' ')[0]   # "10"
                        return int(numero)
                    except:
                        return 0
                opcoes_ordenadas = sorted(registros_opcoes.keys(), key=extrair_numero)

                registro_busca = st.selectbox("REGISTRO (t√≠tulo)", [""] + opcoes_ordenadas, key="busca_registro")

            with col3:
                # Bot√£o de busca
                st.write("")
                st.write("")
                buscar = st.button("üîé CARREGAR REGISTRO", type="primary", use_container_width=True)

            # Encontrar e carregar o registro
            if registro_busca and registro_busca in registros_opcoes:
                # Registro selecionado diretamente do dropdown com t√≠tulo
                novo_rec = registros_opcoes[registro_busca]
                # Verificar se √© um registro diferente do atual
                if st.session_state.selected_record is None or st.session_state.selected_record.get('_id') != novo_rec.get('_id'):
                    st.session_state.selected_record = novo_rec
                    st.session_state.force_form_update = True
                    st.rerun()
                rec = novo_rec
                st.success(f"‚úÖ Registro carregado: **{rec.get('titulo_artigo', '[sem t√≠tulo]')}**")
            elif buscar and (revista_busca or registro_busca):
                st.warning("‚ö†Ô∏è Por favor, selecione um registro da lista.")

            # Usar registro do session_state se existir
            if st.session_state.selected_record is not None:
                rec = st.session_state.selected_record

        form.render(rec=rec, mode=mode)

    # --- FICHAS & NOTAS ---
    elif menu == "FICHAS & NOTAS":
        view = FichasNotasView(df, dados)
        view.render()

    # --- EXPLORAR DADOS ---
    elif menu == "EXPLORAR DADOS":
        st.title("üîé EXPLORAR DADOS")
        if not df.empty:
            # Linha de filtros com bot√£o de reset
            st.markdown("### üîç FILTROS DE BUSCA")

            # GERA√á√ÉO DE TODOS OS TIPOS TEXTUAIS POSS√çVEIS (do TIPOS_TEXTUAIS)
            # Incluindo TODAS as combina√ß√µes de tipo + subtipo
            tipos_completos = []
            for tipo, subtipos in DataModule.TIPOS_TEXTUAIS.items():
                for subtipo in subtipos:
                    if subtipo == "Sem especifica√ß√£o":
                        # Tipo sem subtipo espec√≠fico
                        tipos_completos.append(tipo)
                    else:
                        # Tipo com subtipo (formato: "TIPO - Subtipo")
                        tipos_completos.append(f"{tipo} - {subtipo}")
            tipos_clean = sorted(list(set(tipos_completos)))

            # Preparar listas para os filtros
            revs = sorted(
                df['n'].astype(str).unique(),
                key=lambda x: ORDEM_SIBILA.index(x) if x in ORDEM_SIBILA else 999
            )

            # FILTROS
            col_filtros1, col_filtros2 = st.columns(2)

            with col_filtros1:
                termo = st.text_input("üîç Busca Livre (T√≠tulo/Resumo):", key="explorar_termo")

            with col_filtros2:
                # Selectbox para revista
                revista_sel = st.selectbox(
                    "üìñ Revista",
                    ["Todas"] + revs,
                    key="explorar_revista_select"
                )
                f_rev = [revista_sel] if revista_sel != "Todas" else []

            # Filtro de Tipo Textual - TODOS os tipos e subtipos!
            with st.expander("üìù Tipo Textual (clique para expandir e selecionar)", expanded=False):
                st.caption(f"üí° {len(tipos_clean)} tipos textuais dispon√≠veis (incluindo todos os subtipos)")

                # Campo de busca para filtrar tipos
                busca_tipo = st.text_input(
                    "üîç Filtrar tipos:",
                    key="busca_tipo_textual",
                    placeholder="Digite para filtrar a lista..."
                )

                # Filtrar tipos conforme a busca
                if busca_tipo:
                    tipos_exibir = [t for t in tipos_clean
                                   if busca_tipo.lower() in t.lower()]
                    st.caption(f"‚úÖ {len(tipos_exibir)} tipos encontrados")
                else:
                    tipos_exibir = tipos_clean

                # Mostrar TODOS os tipos (filtrados ou n√£o)
                f_tipo = []
                cols_tipo = st.columns(3)
                for idx, tipo in enumerate(tipos_exibir):
                    with cols_tipo[idx % 3]:
                        if st.checkbox(tipo, key=f"tipo_check_{tipo}"):
                            f_tipo.append(tipo)

            # Filtro de Palavras-chave - TODAS AS 461!
            with st.expander("üè∑Ô∏è Palavras-Chave (clique para expandir e selecionar)", expanded=False):
                st.caption(f"üí° {len(DataModule.LISTA_PALAVRAS_CHAVE)} palavras-chave dispon√≠veis")

                # Campo de busca para filtrar palavras
                busca_palavra = st.text_input(
                    "üîç Filtrar palavras:",
                    key="busca_palavra_chave",
                    placeholder="Digite para filtrar a lista..."
                )

                # Filtrar palavras conforme a busca
                if busca_palavra:
                    palavras_exibir = [p for p in DataModule.LISTA_PALAVRAS_CHAVE
                                      if busca_palavra.lower() in p.lower()]
                    st.caption(f"‚úÖ {len(palavras_exibir)} palavras encontradas")
                else:
                    palavras_exibir = DataModule.LISTA_PALAVRAS_CHAVE

                # Mostrar TODAS as palavras (filtradas ou n√£o)
                f_kw = []
                cols_kw = st.columns(4)
                for idx, palavra in enumerate(palavras_exibir):
                    with cols_kw[idx % 4]:
                        if st.checkbox(palavra, key=f"kw_check_{palavra}"):
                            f_kw.append(palavra)

            # Bot√£o de reset
            if st.button("üîÑ Limpar Todos os Filtros", help="Desmarca todos os filtros e recarrega"):
                # Limpar TODOS os checkboxes e filtros
                for key in list(st.session_state.keys()):
                    if key.startswith('tipo_check_') or key.startswith('kw_check_') or key.startswith('explorar_'):
                        del st.session_state[key]
                st.rerun()

            # Aplicar filtros
            res = df.copy()
            criterios = []

            if f_rev:
                res = res[res['n'].astype(str).isin(f_rev)]
                criterios.append(f"Revistas: {', '.join(f_rev)}")

            if f_tipo:
                # Filtro que compara o valor COMPLETO (tipo + subtipo) do vocabulario_controlado
                def filtro_tipo(valor):
                    if pd.isna(valor) or not valor:
                        return False
                    valor_completo = str(valor).strip()
                    # Verificar se o valor completo est√° nos tipos selecionados
                    return valor_completo in f_tipo

                res = res[res['vocabulario_controlado'].apply(filtro_tipo)]
                criterios.append(f"Tipos: {', '.join(f_tipo)}")

            if f_kw:
                res = res[
                    res['palavras_chave'].apply(
                        lambda x: any(
                            k.lower() in [i.lower() for i in (x if isinstance(x, list) else [])]
                            for k in f_kw
                        )
                    )
                ]
                criterios.append(f"Palavras-chave: {', '.join(f_kw)}")

            if termo:
                res = res[
                    res.astype(str).apply(lambda x: x.str.contains(termo, case=False, na=False)).any(axis=1)
                ]
                criterios.append(f"Termo livre: '{termo}'")

            # Estat√≠sticas dos resultados
            str_criterios = " | ".join(criterios) if criterios else "Toda a base de dados"
            total_base = len(df)
            qtd_res = len(res)
            pct_res = (qtd_res / total_base * 100) if total_base > 0 else 0

            st.markdown("---")
            col_info1, col_info2 = st.columns(2)
            with col_info1:
                st.metric("Registros Encontrados", f"{qtd_res} de {total_base}", f"{pct_res:.1f}% da base")
            with col_info2:
                if criterios:
                    st.info(f"üîç Filtros ativos: {str_criterios}")
                else:
                    st.info("üìä Mostrando todos os registros")

            # Tabela de resultados com configura√ß√£o aprimorada
            st.markdown("### üìã RESULTADOS")

            # Configura√ß√£o de colunas vis√≠veis
            if 'colunas_visiveis' not in st.session_state:
                st.session_state.colunas_visiveis = ['n', 'registro', 'titulo_artigo', 'autores_colaboradores', 'vocabulario_controlado']

            with st.expander("‚öôÔ∏è Configurar Colunas Vis√≠veis", expanded=False):
                todas_colunas = list(res.columns)
                colunas_recomendadas = ['n', 'registro', 'titulo_artigo', 'autores_colaboradores', 'vocabulario_controlado', 'palavras_chave', 'paginas']

                col_config1, col_config2 = st.columns([4, 1])
                with col_config1:
                    st.session_state.colunas_visiveis = st.multiselect(
                        "Selecione as colunas a exibir:",
                        todas_colunas,
                        default=st.session_state.colunas_visiveis if st.session_state.colunas_visiveis else colunas_recomendadas,
                        key="multiselect_colunas"
                    )
                with col_config2:
                    if st.button("‚Üª Reset", help="Mostrar colunas padr√£o", use_container_width=True):
                        st.session_state.colunas_visiveis = colunas_recomendadas
                        st.rerun()

            # Preparar DataFrame para exibi√ß√£o
            res_prepared = res.copy()

            # Remover coluna _timestamp se existir
            if '_timestamp' in res_prepared.columns:
                res_prepared = res_prepared.drop(columns=['_timestamp'])

            # Formatar iconografias para mostrar dados reais
            if 'iconografias' in res_prepared.columns:
                def formatar_iconografias(icon_list):
                    if not icon_list or not isinstance(icon_list, list):
                        return ""
                    itens = []
                    for icon in icon_list:
                        if isinstance(icon, dict):
                            tipo = icon.get('tipo', '')
                            desc = icon.get('descricao', '')
                            if tipo:
                                itens.append(f"{tipo}: {desc}" if desc else tipo)
                    return " | ".join(itens) if itens else ""

                res_prepared['iconografias'] = res_prepared['iconografias'].apply(formatar_iconografias)

            # Reordenar colunas: mover entidade_coletiva perto de autores
            # e nota_edicao para o final
            colunas_ordenadas = []
            for col in res_prepared.columns:
                if col not in ['entidade_coletiva', 'nota_edicao']:
                    colunas_ordenadas.append(col)
                    # Inserir entidade_coletiva ap√≥s tradutores
                    if col == 'tradutores' and 'entidade_coletiva' in res_prepared.columns:
                        colunas_ordenadas.append('entidade_coletiva')

            # Adicionar nota_edicao no final
            if 'nota_edicao' in res_prepared.columns:
                colunas_ordenadas.append('nota_edicao')

            res_prepared = res_prepared[colunas_ordenadas]

            # Atualizar colunas vis√≠veis se necess√°rio
            if st.session_state.colunas_visiveis:
                colunas_disponiveis = [col for col in st.session_state.colunas_visiveis if col in res_prepared.columns]
                res_display = res_prepared[colunas_disponiveis]
            else:
                res_display = res_prepared

            # Ajuste visual do √≠ndice para come√ßar em 1
            res_display = res_display.copy()
            res_display.reset_index(drop=True, inplace=True)
            res_display.index = res_display.index + 1

            st.dataframe(
                res_display,
                column_config={
                    "n": "n.",
                    "registro": "Registro",
                    "titulo_artigo": "T√≠tulo",
                    "subtitulo_artigo": "Subt√≠tulo",
                    "autores_colaboradores": "Autores",
                    "entidade_coletiva": "Entidade Coletiva",
                    "tradutores": "Tradutores",
                    "autores_citados": "Autores Citados",
                    "vocabulario_controlado": "Tipo Textual",
                    "palavras_chave": "Palavras-Chave",
                    "nome_pessoal_como_assunto": "Nome Pessoal Como Assunto",
                    "paginas": "P√°ginas",
                    "resumo": "Resumo",
                    "iconografias": "Iconografias",
                    "nota_edicao": "Nota da Edi√ß√£o",
                    "notas_pesquisa": "Notas de Pesquisa",
                    "idioma_01": "Idioma 01",
                    "idioma_02": "Idioma 02",
                    "ordem_exibicao": "Ordem de Exibi√ß√£o"
                },
                use_container_width=True,
                height=400
            )

            df_citados = None
            df_colab = None
            if not res.empty:
                st.markdown("---")
                st.subheader("üìä AN√ÅLISE COM BASE NA SELE√á√ÉO DOS DADOS")
                s_citados = DataModule.get_normalized_series(res, 'autores_citados')
                c_stat1, c_stat2 = st.columns(2)
                with c_stat1:
                    if not s_citados.empty:
                        df_citados = UtilsModule.calculate_stats_with_percentage(s_citados)
                        st.markdown("üìå **AUTORES MAIS CITADOS**")
                        df_citados.index = df_citados.index + 1
                        st.dataframe(df_citados.head(10), width='stretch')
                    else:
                        st.info("Nenhum autor citado nestes registros.")

                with c_stat2:
                    s_colab = DataModule.get_normalized_series(res, 'autores_colaboradores')
                    if not s_colab.empty:
                        df_colab = UtilsModule.calculate_stats_with_percentage(s_colab)
                        st.markdown("‚úçÔ∏è **AUTORES COLABORADORES**")
                        df_colab.index = df_colab.index + 1
                        st.dataframe(df_colab.head(10), width='stretch')
                    else:
                        st.info("Nenhum colaborador listado nestes registros.")

            st.markdown("---")
            st.markdown("### üì• EXPORTAR RESULTADOS DA BUSCA")

            # Layout melhorado para bot√µes de exporta√ß√£o com espa√ßamento adequado
            col_export1, col_export2, col_export3 = st.columns([1, 1, 1])

            excel_busca = UtilsModule.converter_excel(res)
            pdf_busca = PDFModule.gerar_pdf_busca_analitica(res, len(df), str_criterios, df_citados, df_colab)

            with col_export1:
                st.download_button(
                    "üìä BAIXAR EXCEL",
                    excel_busca,
                    f"busca_sibila_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    help="Exportar resultados para Excel"
                )

            with col_export2:
                st.download_button(
                    "üìÑ BAIXAR PDF",
                    pdf_busca,
                    f"relatorio_sibila_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                    "application/pdf",
                    use_container_width=True,
                    help="Exportar relat√≥rio para PDF"
                )

            with col_export3:
                # Informa√ß√£o sobre o que ser√° exportado
                st.info(f"üìä Exportando {qtd_res} registro(s)")

        else:
            st.warning("‚ö†Ô∏è Base de dados vazia. Cadastre registros na aba CATALOGA√á√ÉO.")

    # --- RELAT√ìRIOS ---
    elif menu == "RELAT√ìRIOS":
        st.title("üìë RELAT√ìRIOS NELIC")
        if df.empty:
            st.warning("Base vazia.")
        else:
            tipo_rel = st.selectbox(
                "Selecione o relat√≥rio:",
                [
                    "Volume de itens por revista",
                    "√çndice de publica√ß√µes bil√≠ngues",
                    "Iconografia por revista",
                    "Autores como assunto vs colaboradores",
                    "An√°lise por tipos textuais",
                    "Manifesto",
                    "Sibila",
                    "Palavras-chave",
                    "Densidade de Imagens por P√°ginas"
                ]
            )
            if tipo_rel == "Volume de itens por revista":
                relatorio_mapa_colaboracao(df)
            elif tipo_rel == "√çndice de publica√ß√µes bil√≠ngues":
                relatorio_bilinguismo(df)
            elif tipo_rel == "Iconografia por revista":
                relatorio_iconografia(df)
            elif tipo_rel == "Autores como assunto vs colaboradores":
                relatorio_autores_assunto_colab(df)
            elif tipo_rel == "An√°lise por tipos textuais":
                relatorio_tipos_textuais(df)
            elif tipo_rel == "Manifesto":
                relatorio_manifesto(df)
            elif tipo_rel == "Sibila":
                relatorio_sibila(df)
            elif tipo_rel == "Palavras-chave":
                relatorio_palavras_chave(df)
            elif tipo_rel == "Densidade de Imagens por P√°ginas":
                relatorio_densidade_paginas(df)

    # --- AN√ÅLISE COMPARATIVA ---
    elif menu == "AN√ÅLISE COMPARATIVA":
        st.title("üìä AN√ÅLISE COMPARATIVA")
        if df.empty:
            st.warning("Base vazia.")
        else:
            st.markdown("Compare dois conjuntos de registros a partir de filtros NELIC.")

            def aplicar_filtros(df_base, prefix):
                c1, c2, c3, c4 = st.columns(4)
                termo = c1.text_input(f"{prefix} ¬∑ termo livre (t√≠tulo/resumo)", key=f"termo_{prefix}")
                revs_local = sorted(
                    df_base['n'].astype(str).unique(),
                    key=lambda x: ORDEM_SIBILA.index(x) if x in ORDEM_SIBILA else 999
                )
                f_rev = c2.multiselect(f"{prefix} ¬∑ revistas", revs_local, key=f"rev_{prefix}")
                tipos_raw_local = df_base['vocabulario_controlado'].astype(str).unique()
                tipos_clean_local = sorted(list(set([t.split(' - ')[0] for t in tipos_raw_local])))
                f_tipo = c3.multiselect(f"{prefix} ¬∑ tipos textuais", tipos_clean_local, key=f"tipo_{prefix}")
                f_bil = c4.selectbox(
                    f"{prefix} ¬∑ bil√≠ngue",
                    ["Todos", "Apenas bil√≠ngues", "Apenas n√£o bil√≠ngues"],
                    key=f"bil_{prefix}"
                )
                res_local = df_base.copy()
                if f_rev:
                    res_local = res_local[res_local['n'].astype(str).isin(f_rev)]
                if f_tipo:
                    res_local = res_local[
                        res_local['vocabulario_controlado'].apply(lambda x: str(x).split(' - ')[0] in f_tipo)
                    ]
                res_local = res_local.copy()
                res_local['__bil'] = res_local.apply(UtilsModule.is_bilingue, axis=1)
                if f_bil == "Apenas bil√≠ngues":
                    res_local = res_local[res_local['__bil']]
                elif f_bil == "Apenas n√£o bil√≠ngues":
                    res_local = res_local[~res_local['__bil']]
                if termo:
                    res_local = res_local[
                        res_local.astype(str).apply(lambda x: x.str.contains(termo, case=False)).any(axis=1)
                    ]
                return res_local.drop(columns=['__bil'], errors='ignore')

            st.markdown("#### Conjunto A")
            df_A = aplicar_filtros(df, "A")
            st.markdown(f"Conjunto A: {len(df_A)} registros.")

            st.markdown("#### Conjunto B")
            df_B = aplicar_filtros(df, "B")
            st.markdown(f"Conjunto B: {len(df_B)} registros.")

            if not df_A.empty or not df_B.empty:
                st.markdown("---")
                st.subheader("üî¨ M√©tricas comparadas")
                def metricas(df_sub):
                    s_colab = DataModule.get_normalized_series(df_sub, 'autores_colaboradores')
                    s_cit = DataModule.get_normalized_series(df_sub, 'autores_citados')
                    ic = df_sub['iconografias'].apply(
                        lambda x: isinstance(x, list) and len(x) > 0
                    ).sum()
                    df_tmp = df_sub.copy()
                    df_tmp['__bil'] = df_tmp.apply(UtilsModule.is_bilingue, axis=1)
                    bil = df_tmp['__bil'].sum()
                    total = len(df_tmp)
                    return {
                        "registros": total,
                        "colab_distintos": s_colab.nunique(),
                        "cit_distintos": s_cit.nunique(),
                        "pct_iconografia": (ic / total * 100) if total > 0 else 0,
                        "pct_bilingue": (bil / total * 100) if total > 0 else 0
                    }

                mA = metricas(df_A) if not df_A.empty else None
                mB = metricas(df_B) if not df_B.empty else None
                cA, cB = st.columns(2)
                with cA:
                    st.markdown("##### Conjunto A")
                    if mA:
                        st.metric("Registros", mA["registros"])
                        st.metric("Colaboradores distintos", mA["colab_distintos"])
                        st.metric("Autores citados distintos", mA["cit_distintos"])
                        st.metric("% com iconografia", f"{mA['pct_iconografia']:.1f}%")
                        st.metric("% bil√≠ngue", f"{mA['pct_bilingue']:.1f}%")
                    else:
                        st.info("Sem registros no conjunto A.")

                with cB:
                    st.markdown("##### Conjunto B")
                    if mB:
                        st.metric("Registros", mB["registros"])
                        st.metric("Colaboradores distintos", mB["colab_distintos"])
                        st.metric("Autores citados distintos", mB["cit_distintos"])
                        st.metric("% com iconografia", f"{mB['pct_iconografia']:.1f}%")
                        st.metric("% bil√≠ngue", f"{mB['pct_bilingue']:.1f}%")
                    else:
                        st.info("Sem registros no conjunto B.")

    # --- QUALIDADE DOS DADOS ---
    elif menu == "QUALIDADE DOS DADOS":
        st.title("üß™ QUALIDADE DOS DADOS")
        if df.empty:
            st.warning("Base vazia.")
        else:
            st.markdown(
                "Monitoramento de consist√™ncia e lacunas conforme as exig√™ncias metodol√≥gicas do NELIC."
            )
            df_local = df.copy()
            sem_pag = df_local[
                df_local['paginas'].isna() |
                (df_local['paginas'].astype(str).str.strip() == '')
            ]
            sem_tit = df_local[
                df_local['titulo_artigo'].isna() |
                (df_local['titulo_artigo'].astype(str).str.strip() == '')
            ]
            df_local['tipo_base'] = df_local['vocabulario_controlado'].astype(str).apply(
                lambda x: x.split(' - ')[0]
            )
            precisa_resumo = ~df_local['tipo_base'].isin(TIPOS_SEM_RESUMO)
            sem_resumo = df_local[
                precisa_resumo &
                (
                    df_local['resumo'].isna() |
                    (df_local['resumo'].astype(str).str.strip() == '')
                )
            ]
            t1, t2, t3, t4, t5 = st.tabs(
                ["Sem p√°ginas", "Sem t√≠tulo", "Sem resumo (quando exigido)", "Duplicidade de registro", "Autores Similares"]
            )
            with t1:
                st.markdown("#### Registros sem informa√ß√£o de p√°ginas")
                st.write(f"Total: {len(sem_pag)}")
                df_sem_pag = sem_pag[['n', 'registro', 'titulo_artigo', 'paginas']].copy()
                df_sem_pag.reset_index(drop=True, inplace=True)
                df_sem_pag.index = df_sem_pag.index + 1
                st.dataframe(df_sem_pag, width='stretch')
            with t2:
                st.markdown("#### Registros sem t√≠tulo")
                st.write(f"Total: {len(sem_tit)}")
                df_sem_tit = sem_tit[['n', 'registro', 'paginas']].copy()
                df_sem_tit.reset_index(drop=True, inplace=True)
                df_sem_tit.index = df_sem_tit.index + 1
                st.dataframe(df_sem_tit, width='stretch')
            with t3:
                st.markdown("#### Registros sem resumo em tipos que demandam resumo anal√≠tico")
                st.write(f"Total: {len(sem_resumo)}")
                df_sem_resumo = sem_resumo[['n', 'registro', 'vocabulario_controlado', 'titulo_artigo']].copy()
                df_sem_resumo.reset_index(drop=True, inplace=True)
                df_sem_resumo.index = df_sem_resumo.index + 1
                st.dataframe(
                    df_sem_resumo,
                    width='stretch'
                )
            with t4:
                st.markdown("#### Duplicidade potencial de campo REGISTRO")
                df_local['chave_unica'] = df_local['n'].astype(str) + '_' + df_local['registro'].astype(str)
                duplicatas = df_local[df_local.duplicated(subset=['chave_unica'], keep=False)]
                if not duplicatas.empty:
                    st.write(f"Total: {len(duplicatas)} registros com potencial duplicidade")

                    if usuario_autenticado:
                        st.warning("‚ö†Ô∏è Use os bot√µes üóëÔ∏è para excluir registros duplicados. Esta a√ß√£o √© IRREVERS√çVEL!")
                    else:
                        st.info("‚ÑπÔ∏è Para excluir registros duplicados, fa√ßa login com a senha de editor.")

                    for chave in duplicatas['chave_unica'].unique():
                        grupo = duplicatas[duplicatas['chave_unica'] == chave]
                        st.markdown(f"**üî¥ Duplicata encontrada: Revista {grupo.iloc[0]['n']} - Registro {grupo.iloc[0]['registro']}**")

                        # Mostrar cada registro duplicado com bot√£o de exclus√£o
                        for idx, row in grupo.iterrows():
                            if usuario_autenticado:
                                col1, col2 = st.columns([5, 1])
                                with col1:
                                    st.write(f"**ID:** {row['_id']} | **T√≠tulo:** {row['titulo_artigo']} | **P√°ginas:** {row['paginas']}")
                                with col2:
                                    if st.button(f"üóëÔ∏è Excluir", key=f"delete_{row['_id']}"):
                                        # Confirmar exclus√£o
                                        if f"confirm_delete_{row['_id']}" not in st.session_state:
                                            st.session_state[f"confirm_delete_{row['_id']}"] = True
                                            st.warning(f"‚ö†Ô∏è Clique novamente para CONFIRMAR a exclus√£o do registro ID: {row['_id']}")
                                            st.rerun()
                                        else:
                                            # Excluir o registro
                                            dados_novos = [d for d in dados if d.get('_id') != row['_id']]
                                            if PersistenceModule.save_data(dados_novos):
                                                st.success(f"‚úÖ Registro ID {row['_id']} exclu√≠do com sucesso!")
                                                del st.session_state[f"confirm_delete_{row['_id']}"]
                                                st.rerun()
                                            else:
                                                st.error("‚ùå Erro ao salvar os dados ap√≥s exclus√£o.")
                            else:
                                st.write(f"**ID:** {row['_id']} (login necess√°rio para excluir)")


                else:
                    st.success("‚úÖ Nenhuma duplicidade detectada! Todos os registros possuem combina√ß√µes √∫nicas de Revista + Registro.")
                df_local = df_local.drop(columns=['chave_unica'])

            with t5:
                st.markdown("#### üïµÔ∏è Potenciais Duplicatas de Autores")
                st.info("Esta aba agrupa autores pelo SOBRENOME para ajudar a identificar varia√ß√µes de grafia (ex: 'SILVA, Jose' e 'SILVA, J.').")

                # 1. Coletar todos os autores normalizados
                all_authors = DataModule.get_normalized_series(df, 'autores_colaboradores')
                # Adicionar autores citados tamb√©m? O usu√°rio pediu "mesmos autores", geralmente refere-se a colaboradores, mas citados tamb√©m importa.
                all_cited = DataModule.get_normalized_series(df, 'autores_citados')
                
                # Unir e pegar √∫nicos
                unique_authors = sorted(list(set(all_authors.tolist() + all_cited.tolist())))
                
                # 2. Agrupar por sobrenome (primeira palavra antes da v√≠rgula ou espa√ßo)
                groups = {}
                for auth in unique_authors:
                    if not auth: continue
                    # Assumindo formato ABNT "SOBRENOME, Nome"
                    sobrenome = auth.split(',')[0].strip()
                    if sobrenome not in groups:
                        groups[sobrenome] = []
                    groups[sobrenome].append(auth)
                
                # 3. Filtrar apenas grupos com > 1 varia√ß√£o
                potential_dupes = []
                for surname, names in groups.items():
                    if len(names) > 1:
                        potential_dupes.append({
                            "Sobrenome": surname,
                            "Varia√ß√µes Encontradas": ", ".join(sorted(names)),
                            "Qtd": len(names)
                        })
                
                if potential_dupes:
                    df_dupes = pd.DataFrame(potential_dupes).sort_values("Sobrenome")
                    st.write(f"Total de grupos suspeitos: {len(df_dupes)}")
                    st.dataframe(df_dupes, width='stretch', hide_index=True)
                    
                    st.markdown("""
                    **Como corrigir?**
                    Se identificar autores que s√£o a mesma pessoa (ex: "BACH" e "BACH, J.S."), anote esses casos e me informe para que eu adicione √† regra de unifica√ß√£o autom√°tica (`CANONICAL_AUTHORS`).
                    """)
                else:
                    st.success("Nenhuma duplicata √≥bvia baseada em sobrenome encontrada.")

    # ==========================================
    # --- AN√ÅLISE AVAN√áADA (Humanidades Digitais) ---
    # ==========================================
    elif menu == "AN√ÅLISE AVAN√áADA":
        st.title("üî¨ AN√ÅLISE AVAN√áADA")
        st.markdown("""
        Ferramentas de an√°lise para **Humanidades Digitais**: an√°lise de redes,
        processamento de linguagem natural e correla√ß√µes entre dados do cat√°logo.
        """)

        if df.empty:
            st.warning("‚ö†Ô∏è Base de dados vazia. Adicione registros primeiro.")
        else:
            # Sub-abas dentro da An√°lise Avan√ßada
            tab_redes, tab_nlp, tab_correlacao, tab_dna = st.tabs([
                "üï∏Ô∏è An√°lise de Redes",
                "üìù An√°lise Textual (NLP)",
                "üìä Matriz de Correla√ß√£o",
                "üß¨ DNA das Edi√ß√µes"
            ])

            # ========================================
            # TAB 1: AN√ÅLISE DE REDES
            # ========================================
            with tab_redes:
                st.markdown("### üï∏Ô∏è An√°lise de Redes: Autores e Cita√ß√µes")
                st.markdown("""
                Visualize as rela√ß√µes entre **autores colaboradores** e **autores citados**.
                Esta an√°lise permite identificar padr√µes de cita√ß√£o e redes de influ√™ncia.
                """)

                if not NETWORKX_AVAILABLE:
                    st.error("‚ùå Biblioteca `networkx` n√£o dispon√≠vel. Instale com: `pip install networkx`")
                else:
                    try:
                        # Extrair dados para o grafo
                        edges_autor_citacao = []
                        for _, row in df.iterrows():
                            autores = row.get('autores_colaboradores', [])
                            citados = row.get('autores_citados', [])
                            if isinstance(autores, list) and isinstance(citados, list):
                                for autor in autores:
                                    for citado in citados:
                                        if autor and citado:
                                            edges_autor_citacao.append((autor.strip(), citado.strip()))

                        if not edges_autor_citacao:
                            st.info("‚ÑπÔ∏è N√£o h√° dados suficientes para gerar o grafo. Verifique se existem registros com autores colaboradores E autores citados.")
                        else:
                            # Criar grafo
                            G = nx.DiGraph()
                            G.add_edges_from(edges_autor_citacao)

                            # M√©tricas do grafo
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Autores", G.number_of_nodes())
                            with col2:
                                st.metric("Cita√ß√µes", G.number_of_edges())
                            with col3:
                                densidade = nx.density(G)
                                st.metric("Densidade", f"{densidade:.4f}", help="Indica o qu√£o conectada √© a rede. Se fosse 1.0, todos os autores citariam todos os outros. Valor baixo indica rede esparsa.")
                            with col4:
                                componentes = nx.number_weakly_connected_components(G)
                                st.metric("Componentes", componentes, help="N√∫mero de grupos isolados de autores. Se for 1, todos est√£o conectados. Se for maior, existem 'ilhas' de cita√ß√£o separadas.")

                            st.markdown("---")

                            # Top autores mais citados
                            st.markdown("#### üìä Autores Mais Citados")
                            in_degree = sorted(G.in_degree(), key=lambda x: x[1], reverse=True)[:15]
                            if in_degree:
                                df_in = pd.DataFrame(in_degree, columns=['Autor', 'Vezes Citado'])
                                fig_in = px.bar(df_in, x='Vezes Citado', y='Autor', orientation='h',
                                               title='15 Autores Mais Citados')
                                fig_in.update_layout(yaxis={'categoryorder': 'total ascending'})
                                st.plotly_chart(fig_in, use_container_width=True)

                            # Top autores que mais citam
                            st.markdown("#### üìä Autores que Mais Citam")
                            out_degree = sorted(G.out_degree(), key=lambda x: x[1], reverse=True)[:15]
                            if out_degree:
                                df_out = pd.DataFrame(out_degree, columns=['Autor', 'Cita√ß√µes Feitas'])
                                fig_out = px.bar(df_out, x='Cita√ß√µes Feitas', y='Autor', orientation='h',
                                                title='15 Autores que Mais Citam Outros')
                                fig_out.update_layout(yaxis={'categoryorder': 'total ascending'})
                                st.plotly_chart(fig_out, use_container_width=True)

                            st.markdown("---")

                            # Exporta√ß√£o
                            st.markdown("#### üíæ Exportar Dados da Rede")
                            col_exp1, col_exp2, col_exp3 = st.columns(3)

                            with col_exp1:
                                # Exportar GEXF (para Gephi)
                                try:
                                    import io
                                    gexf_buffer = io.BytesIO()
                                    nx.write_gexf(G, gexf_buffer)
                                    gexf_data = gexf_buffer.getvalue()
                                    st.download_button(
                                        "üì• Baixar GEXF (Gephi)",
                                        data=gexf_data,
                                        file_name="rede_autores_citacoes.gexf",
                                        mime="application/gexf+xml",
                                        key="btn_gexf"
                                    )
                                except Exception as e:
                                    st.warning(f"Erro ao gerar GEXF: {e}")

                            with col_exp2:
                                # CSV de n√≥s
                                nodes_data = []
                                for node in G.nodes():
                                    nodes_data.append({
                                        'id': node,
                                        'label': node,
                                        'in_degree': G.in_degree(node),
                                        'out_degree': G.out_degree(node)
                                    })
                                df_nodes = pd.DataFrame(nodes_data)
                                csv_nodes = df_nodes.to_csv(index=False)
                                st.download_button(
                                    "üì• Baixar N√≥s (CSV)",
                                    data=csv_nodes,
                                    file_name="autores_nos.csv",
                                    mime="text/csv",
                                    key="btn_nodes_csv"
                                )

                            with col_exp3:
                                # CSV de arestas
                                edges_data = [{'source': e[0], 'target': e[1]} for e in G.edges()]
                                df_edges = pd.DataFrame(edges_data)
                                csv_edges = df_edges.to_csv(index=False)
                                st.download_button(
                                    "üì• Baixar Arestas (CSV)",
                                    data=csv_edges,
                                    file_name="citacoes_arestas.csv",
                                    mime="text/csv",
                                    key="btn_edges_csv"
                                )

                    except Exception as e:
                        st.error(f"‚ùå Erro na an√°lise de redes: {str(e)}")

                    # ==========================================
                    # VIZ INTERATIVA PYVIS
                    # ==========================================
                    st.markdown("#### üï∏Ô∏è VISUALIZA√á√ÉO INTERATIVA") # (PYVIS)
                    st.markdown("Clique no bot√£o abaixo para gerar o grafo. *Para grandes volumes de dados, isso pode levar alguns segundos.*")
                    
                    if not PYVIS_AVAILABLE:
                        st.warning("‚ö†Ô∏è Biblioteca `pyvis` n√£o instalada. Instale com `pip install pyvis` para ver o grafo interativo.")
                    elif 'G' in locals() and G.number_of_nodes() > 0:
                        # Fun√ß√£o de scroll (no-op se n√£o for usada)
                        def _scroll_to_pyvis():
                            try:
                                st.markdown(
                                    "<div id='pyvis_anchor'></div>",
                                    unsafe_allow_html=True
                                )
                            except Exception:
                                pass

                        def _reset_pyvis_state():
                            # Limpa estados corrompidos (ex.: bool) para evitar erros de itera√ß√£o
                            cache_state = st.session_state.get("_pyvis_cache")
                            last_state = st.session_state.get("_pyvis_last")

                            if not isinstance(cache_state, dict):
                                st.session_state["_pyvis_cache"] = {}
                            else:
                                st.session_state["_pyvis_cache"] = {
                                    k: v for k, v in cache_state.items() if isinstance(v, str)
                                }

                            if not isinstance(last_state, dict):
                                st.session_state["_pyvis_last"] = {}
                            else:
                                # Mant√©m apenas se render_html for string e graph for nx.Graph
                                graph_ok = isinstance(last_state.get("graph"), nx.Graph)
                                html_ok = isinstance(last_state.get("render_html"), str)
                                st.session_state["_pyvis_last"] = last_state if graph_ok and html_ok else {}

                        _reset_pyvis_state()

                        # ========== CONTROLES SIMPLIFICADOS ==========
                        st.markdown("##### üéØ Selecione um autor para destacar:")
                        try:
                            autor_options = ["(nenhum)"] + sorted(G.nodes())
                        except Exception:
                            autor_options = ["(nenhum)"] + [str(n) for n in G.nodes()]

                        autor_pref_label = st.selectbox(
                            "Autor",
                            autor_options,
                            index=0,
                            key="pyvis_autor_select"
                        )
                        autor_pref = None if autor_pref_label == "(nenhum)" else autor_pref_label

                        # Mostrar rela√ß√µes do autor IMEDIATAMENTE ao selecionar
                        if autor_pref and autor_pref in G.nodes():
                            st.success(f"**Autor selecionado:** {autor_pref}")

                            # Calcular cita√ß√µes - ordenadas alfabeticamente
                            # REGRA: Excluir o pr√≥prio autor (n√£o pode citar/ser citado por si mesmo)
                            # NOTA: O grafo n√£o armazena cita√ß√µes m√∫ltiplas, ent√£o cada rela√ß√£o aparece 1 vez
                            try:
                                # Quem o autor cita - lista alfab√©tica
                                citas_raw = [v for _, v in G.out_edges(autor_pref) if v != autor_pref]
                                citas_lista = sorted(list(set(citas_raw)))

                                # Quem cita o autor - lista alfab√©tica
                                citado_raw = [u for u, _ in G.in_edges(autor_pref) if u != autor_pref]
                                citado_lista = sorted(list(set(citado_raw)))
                            except:
                                citas_lista = []
                                citado_lista = []

                            col_cita, col_citado = st.columns(2)

                            with col_cita:
                                st.markdown(f"**‚Üí Cita ({len(citas_lista)} autores):**")
                                if citas_lista:
                                    # Mostrar os 15 primeiros (ordem alfab√©tica)
                                    for autor_c in citas_lista[:15]:
                                        st.write(f"‚Ä¢ {autor_c}")

                                    # Se houver mais, mostrar expander
                                    if len(citas_lista) > 15:
                                        with st.expander(f"üìã Ver todos os {len(citas_lista)} autores citados"):
                                            st.markdown("**Lista completa (ordem alfab√©tica):**")
                                            for i, autor_c in enumerate(citas_lista, 1):
                                                st.write(f"{i}. {autor_c}")

                                            # Gerar PDF para download
                                            try:
                                                pdf_cita = FPDF()
                                                pdf_cita.add_page()
                                                pdf_cita.set_font("Arial", 'B', 14)
                                                pdf_cita.cell(0, 10, f"Autores citados por {autor_pref}", ln=1)
                                                pdf_cita.set_font("Arial", '', 10)
                                                pdf_cita.cell(0, 8, f"Total: {len(citas_lista)} autores (ordem alfabetica)", ln=1)
                                                pdf_cita.ln(5)
                                                for i, autor_c in enumerate(citas_lista, 1):
                                                    texto = f"{i}. {autor_c}"
                                                    texto_safe = texto.encode('latin-1', 'replace').decode('latin-1')
                                                    pdf_cita.cell(0, 6, texto_safe, ln=1)
                                                pdf_bytes_cita = pdf_cita.output(dest='S').encode('latin-1', 'replace')

                                                st.download_button(
                                                    "üì• Exportar lista (PDF)",
                                                    data=pdf_bytes_cita,
                                                    file_name=f"citados_por_{autor_pref.replace(' ', '_')}.pdf",
                                                    mime="application/pdf",
                                                    key="btn_pdf_cita"
                                                )
                                            except Exception as e:
                                                st.caption(f"Erro ao gerar PDF: {e}")
                                else:
                                    st.write("_Nenhum_")

                            with col_citado:
                                st.markdown(f"**‚Üê Citado por ({len(citado_lista)} autores):**")
                                if citado_lista:
                                    # Mostrar os 15 primeiros (ordem alfab√©tica)
                                    for autor_c in citado_lista[:15]:
                                        st.write(f"‚Ä¢ {autor_c}")

                                    # Se houver mais, mostrar expander
                                    if len(citado_lista) > 15:
                                        with st.expander(f"üìã Ver todos os {len(citado_lista)} autores que citam"):
                                            st.markdown("**Lista completa (ordem alfab√©tica):**")
                                            for i, autor_c in enumerate(citado_lista, 1):
                                                st.write(f"{i}. {autor_c}")

                                            # Gerar PDF para download
                                            try:
                                                pdf_citado = FPDF()
                                                pdf_citado.add_page()
                                                pdf_citado.set_font("Arial", 'B', 14)
                                                pdf_citado.cell(0, 10, f"Autores que citam {autor_pref}", ln=1)
                                                pdf_citado.set_font("Arial", '', 10)
                                                pdf_citado.cell(0, 8, f"Total: {len(citado_lista)} autores (ordem alfabetica)", ln=1)
                                                pdf_citado.ln(5)
                                                for i, autor_c in enumerate(citado_lista, 1):
                                                    texto = f"{i}. {autor_c}"
                                                    texto_safe = texto.encode('latin-1', 'replace').decode('latin-1')
                                                    pdf_citado.cell(0, 6, texto_safe, ln=1)
                                                pdf_bytes_citado = pdf_citado.output(dest='S').encode('latin-1', 'replace')

                                                st.download_button(
                                                    "üì• Exportar lista (PDF)",
                                                    data=pdf_bytes_citado,
                                                    file_name=f"citam_{autor_pref.replace(' ', '_')}.pdf",
                                                    mime="application/pdf",
                                                    key="btn_pdf_citado"
                                                )
                                            except Exception as e:
                                                st.caption(f"Erro ao gerar PDF: {e}")
                                else:
                                    st.write("_Nenhum_")

                        st.markdown("---")
                        st.markdown("##### üõ†Ô∏è Configura√ß√µes do Grafo")

                        col_cfg1, col_cfg2 = st.columns(2)
                        with col_cfg1:
                            top_n_nodes = st.slider(
                                "Principais autores",
                                10, 200, 50,
                                key="pyvis_top_n"
                            )
                        with col_cfg2:
                            spacing_distance = st.slider(
                                "Dist√¢ncia visual",
                                20, 150, 50,
                                key="pyvis_spacing"
                            )

                        col_cfg3, col_cfg4 = st.columns(2)
                        with col_cfg3:
                            use_community = st.checkbox("Colorir por comunidade", value=True, key="pyvis_community")
                            show_arrows = st.checkbox("Mostrar setas", value=True, key="pyvis_arrows")
                        with col_cfg4:
                            disable_physics = st.checkbox("Layout fixo", value=True, key="pyvis_physics")
                            small_node_mode = st.checkbox("Fontes menores", value=False, key="pyvis_compact")

                        # Bot√£o de gerar grafo
                        if st.button("üîÑ GERAR GRAFO", key="btn_gerar_grafo_main", type="primary", use_container_width=True):
                            st.session_state["_pyvis_cache"] = {}
                            st.session_state["_pyvis_last"] = {}
                            st.session_state["_pyvis_params"] = {
                                "autor_pref": autor_pref,
                                "top_n_nodes": top_n_nodes,
                                "spacing_distance": spacing_distance,
                                "use_community": use_community,
                                "show_arrows": show_arrows,
                                "disable_physics": disable_physics,
                                "small_node_mode": small_node_mode
                            }
                            try:
                                with st.spinner("Gerando visualiza√ß√£o..."):
                                    if not isinstance(G, nx.Graph):
                                        raise TypeError(f"G esperado como Graph, recebeu {type(G)}")

                                    G_viz = G.copy()
                                    node_degrees = dict(G_viz.degree())
                                    sorted_nodes = sorted(node_degrees.items(), key=lambda item: item[1], reverse=True)

                                    # Manter TOP N n√≥s + autor selecionado (se houver)
                                    nodes_to_keep = set([n[0] for n in sorted_nodes[:top_n_nodes]])

                                    # Sempre incluir autor selecionado e seus vizinhos diretos
                                    if autor_pref and autor_pref in G_viz.nodes():
                                        nodes_to_keep.add(autor_pref)
                                        # Adicionar vizinhos do autor selecionado
                                        if G_viz.is_directed():
                                            for _, v in G_viz.out_edges(autor_pref):
                                                nodes_to_keep.add(v)
                                            for u, _ in G_viz.in_edges(autor_pref):
                                                nodes_to_keep.add(u)
                                        else:
                                            for neighbor in G_viz.neighbors(autor_pref):
                                                nodes_to_keep.add(neighbor)

                                    G_viz = G_viz.subgraph(list(nodes_to_keep)).copy()

                                    if G_viz.number_of_nodes() == 0:
                                        st.warning("Nenhum autor encontrado com os filtros atuais.")
                                    else:
                                        stabilization_iterations = 200

                                        current_controls = {
                                            "top_n": top_n_nodes,
                                            "use_community": use_community,
                                            "show_arrows": show_arrows,
                                            "disable_physics": disable_physics,
                                            "stabilization_iterations": stabilization_iterations,
                                            "small_node_mode": small_node_mode,
                                            "spacing_distance": spacing_distance,
                                            "autor_pref": autor_pref,
                                        }
                                        prev_controls = st.session_state.get("_pyvis_controls")
                                        if prev_controls != current_controls:
                                            st.session_state["_pyvis_controls"] = current_controls
                                            st.session_state["_pyvis_last"] = {}

                                        render_html = None

                                        # Exporta√ß√µes do subgrafo filtrado
                                        try:
                                            gexf_buffer = BytesIO()
                                            nx.write_gexf(G_viz, gexf_buffer)
                                            gexf_data_viz = gexf_buffer.getvalue()
                                        except Exception:
                                            gexf_data_viz = b""

                                        nodes_data_viz = []
                                        for node in G_viz.nodes():
                                            nodes_data_viz.append({
                                                'id': node,
                                                'label': node,
                                                'in_degree': G_viz.in_degree(node),
                                                'out_degree': G_viz.out_degree(node)
                                            })
                                        df_nodes_viz = pd.DataFrame(nodes_data_viz)
                                        csv_nodes_viz = df_nodes_viz.to_csv(index=False)

                                        edges_data_viz = [{'source': e[0], 'target': e[1]} for e in G_viz.edges()]
                                        df_edges_viz = pd.DataFrame(edges_data_viz)
                                        csv_edges_viz = df_edges_viz.to_csv(index=False)

                                        def _safe_text(txt: str) -> str:
                                            try:
                                                return str(txt).encode("latin-1", "replace").decode("latin-1")
                                            except Exception:
                                                return str(txt)

                                        try:
                                            pdf = FPDF()
                                            pdf.add_page()
                                            pdf.set_font("Arial", 'B', 14)
                                            pdf.cell(0, 10, _safe_text("Rede de Autores - Visualiza√ß√£o Filtrada"), ln=1)
                                            pdf.set_font("Arial", '', 11)
                                            pdf.cell(0, 8, _safe_text(f"Autores: {G_viz.number_of_nodes()} | Cita√ß√µes: {G_viz.number_of_edges()}"), ln=1)
                                            pdf.cell(0, 8, _safe_text(f"Dist√¢ncia entre n√≥s: {spacing_distance}"), ln=1)
                                            pdf.cell(0, 8, _safe_text(f"Comunidades coloridas: {'Sim' if use_community else 'N√£o'}"), ln=1)
                                            pdf.ln(4)
                                            pdf.set_font("Arial", 'B', 12)
                                            pdf.cell(0, 8, _safe_text("Top autores mais citados"), ln=1)
                                            pdf.set_font("Arial", '', 11)
                                            for autor, val in sorted(G_viz.in_degree(), key=lambda x: x[1], reverse=True)[:10]:
                                                pdf.cell(0, 7, _safe_text(f"{autor}: {val}"), ln=1)
                                            pdf_output = pdf.output(dest="S").encode("latin-1", "replace")
                                        except Exception:
                                            pdf_output = b""

                                        if True:  # Sempre gerar novo grafo
                                            # 2. ESTILIZA√á√ÉO PROFISSIONAL (Clean & Clear)
                                            sub_degrees = dict(G_viz.degree())
                                            nx.set_node_attributes(
                                                G_viz,
                                                {n: max(6, min(26, 8 + (d * 2))) for n, d in sub_degrees.items()},
                                                'size'
                                            )

                                            if use_community:
                                                try:
                                                    from networkx.algorithms import community
                                                    communities = list(community.greedy_modularity_communities(G_viz))
                                                    colors = [
                                                        '#E6194B', '#3CB44B', '#FFE119', '#4363D8', '#F58231',
                                                        '#911EB4', '#46F0F0', '#F032E6', '#BCF60C', '#FABEBE',
                                                        '#008080', '#E6BEFF', '#9A6324', '#FFFAC8', '#800000',
                                                        '#AAFFC3', '#808000', '#FFD8B1', '#000075', '#808080'
                                                    ]
                                                    color_map = {}
                                                    for i, comm in enumerate(communities):
                                                        c = colors[i % len(colors)]
                                                        for node in comm:
                                                            color_map[node] = c
                                                    nx.set_node_attributes(G_viz, color_map, 'color')
                                                except Exception:
                                                    nx.set_node_attributes(G_viz, '#4e79a7', 'color')
                                            else:
                                                nx.set_node_attributes(G_viz, '#59a14f', 'color')

                                            # 3. CONFIGURA√á√ÉO PYVIS - Layout com dist√¢ncia configur√°vel
                                            node_font_size = 11 if small_node_mode or G_viz.number_of_nodes() > 300 else 13
                                            base_bg_color = "#ffffff" if small_node_mode else "#f7f9fb"
                                            label_color = "#0f172a"

                                            # k controla a dist√¢ncia ideal entre n√≥s (maior k = mais espa√ßo)
                                            # Escala: 20->0.3, 60->0.9, 150->2.25
                                            k_value = spacing_distance / 66.0
                                            pos = nx.spring_layout(G_viz, k=k_value, iterations=80, seed=42)

                                            # Multiplicador de escala para visualiza√ß√£o (maior spacing = mais spread)
                                            scale_factor = 400 + (spacing_distance * 8)
                                            for node_id, (x_pos, y_pos) in pos.items():
                                                G_viz.nodes[node_id]['x'] = float(x_pos * scale_factor)
                                                G_viz.nodes[node_id]['y'] = float(y_pos * scale_factor)

                                            net = Network(height="700px", width="100%", bgcolor="#ffffff", font_color="#000000", directed=show_arrows)
                                            net.from_nx(G_viz)

                                            # Garante r√≥tulo vis√≠vel em cada n√≥
                                            for n in net.nodes:
                                                n["label"] = str(n.get("label") or n.get("id"))

                                            for n in net.nodes:
                                                node_border = n.get("color", "#4e79a7")
                                                n.update({
                                                    "shape": "box",
                                                    "color": {
                                                        "background": base_bg_color,
                                                        "border": node_border,
                                                        "highlight": {"background": "#ffffff", "border": "#111827"}
                                                    },
                                                    "font": {"size": node_font_size, "face": "Helvetica", "color": label_color},
                                                    "shadow": False,
                                                })

                                            physics_options = {
                                                "solver": "repulsion",
                                                "repulsion": {
                                                    "nodeDistance": spacing_distance,
                                                    "centralGravity": 0.035,
                                                    "springLength": max(60, int(spacing_distance * 0.85)),
                                                    "springConstant": 0.02,
                                                    "damping": 0.1
                                                },
                                                "minVelocity": 0.2,
                                                "stabilization": {
                                                    "enabled": True,
                                                    "iterations": stabilization_iterations
                                                }
                                            }

                                            physics_config = json.dumps({"enabled": False}) if disable_physics else json.dumps(physics_options)

                                            edge_smooth_config = False

                                            full_options = f"""
                                            var options = {{
                                              "physics": {physics_config},
                                              "nodes": {{
                                                "shape": "box",
                                                "font": {{"size": {node_font_size}, "face": "Helvetica", "color": "{label_color}"}},
                                                "borderWidth": 1
                                              }},
                                          "edges": {{
                                            "color": {{"color": "#7aa4d8", "highlight": "#1d4ed8", "opacity": 0.65}},
                                            "smooth": {json.dumps(edge_smooth_config)},
                                            "arrows": {{"to": {{"enabled": {str(show_arrows).lower()}, "scaleFactor": 0.6, "type": "arrow"}}}},
                                            "width": 1.0
                                          }},
                                              "interaction": {{
                                                "hover": true,
                                                "tooltipDelay": 200,
                                                "hideEdgesOnDrag": true,
                                                "navigationButtons": true,
                                                "zoomView": true
                                              }}
                                            }}
                                            """
                                            net.set_options(full_options)

                                            try:
                                                if use_community and G_viz.number_of_nodes() > 300:
                                                    from networkx.algorithms import community as nx_comm
                                                    comms = list(nx_comm.greedy_modularity_communities(G_viz))
                                                    for i, comm in enumerate(comms):
                                                        if len(comm) > 25:
                                                            nodes_list = list(comm)
                                                            try:
                                                                net.cluster(nodes=nodes_list)
                                                            except Exception:
                                                                pass
                                            except Exception:
                                                pass

                                            path = os.path.join(os.getcwd(), "pyvis_graph.html")
                                            net.save_graph(path)

                                            try:
                                                with open(path, 'r', encoding='utf-8') as f:
                                                    source_code = f.read()
                                            except Exception:
                                                with open(path, 'r', encoding='utf-8') as f:
                                                    source_code = f.read()

                                            render_html = source_code

                                        if render_html:
                                            autor_focus = autor_pref if autor_pref in G_viz.nodes() else None
                                            viz_state = {
                                                "graph": G_viz,
                                                "render_html": render_html,
                                                "gexf": gexf_data_viz,
                                                "nodes_csv": csv_nodes_viz,
                                                "edges_csv": csv_edges_viz,
                                                "pdf": pdf_output,
                                                "spacing": spacing_distance,
                                                "use_community": use_community,
                                                "show_arrows": show_arrows,
                                                "autor_focus": autor_focus,
                                            }
                                            st.session_state["_pyvis_last"] = viz_state
                                            # Renderiza imediatamente para evitar nova intera√ß√£o
                                            components.html(render_html, height=710, scrolling=True)
                                            st.stop()
                                    
                            except Exception as e:
                                import traceback
                                st.error(f"Erro ao gerar viz PyVis: {e}")
                                st.code("".join(traceback.format_exc()))
                    
                    # Exibir √∫ltima visualiza√ß√£o salva
                    viz_state = st.session_state.get("_pyvis_last") if PYVIS_AVAILABLE else None
                    if viz_state is not None and not isinstance(viz_state, dict):
                        viz_state = None
                    if viz_state is not None and viz_state.get("render_html") and not isinstance(viz_state.get("render_html"), str):
                        viz_state = None
                    if viz_state is not None and not isinstance(viz_state.get("graph"), nx.Graph):
                        viz_state = None

                    if viz_state and viz_state.get("render_html"):
                        render_html = viz_state["render_html"]

                        st.markdown("---")
                        st.markdown("##### üìä Grafo de Rela√ß√µes")

                        # Injetar bot√µes de controle funcionais em azul no HTML
                        control_buttons_html = """
                        <div style="margin-bottom: 10px; display: flex; gap: 8px; flex-wrap: wrap;">
                            <button onclick="if(window.network){window.network.moveTo({scale: window.network.getScale() * 1.3});}"
                                    style="background: #2563eb; color: white; border: none; padding: 8px 16px; border-radius: 6px; cursor: pointer; font-weight: bold;">
                                üîç+ Zoom In
                            </button>
                            <button onclick="if(window.network){window.network.moveTo({scale: window.network.getScale() * 0.7});}"
                                    style="background: #2563eb; color: white; border: none; padding: 8px 16px; border-radius: 6px; cursor: pointer; font-weight: bold;">
                                üîç- Zoom Out
                            </button>
                            <button onclick="if(window.network){window.network.fit();}"
                                    style="background: #2563eb; color: white; border: none; padding: 8px 16px; border-radius: 6px; cursor: pointer; font-weight: bold;">
                                üîÑ Ajustar Tela
                            </button>
                            <button onclick="if(window.network){window.network.moveTo({position: {x: 0, y: 0}});}"
                                    style="background: #2563eb; color: white; border: none; padding: 8px 16px; border-radius: 6px; cursor: pointer; font-weight: bold;">
                                üéØ Centralizar
                            </button>
                        </div>
                        """

                        # Injetar os bot√µes no HTML do grafo
                        if "<body>" in render_html:
                            render_html = render_html.replace("<body>", f"<body>{control_buttons_html}")
                        else:
                            render_html = control_buttons_html + render_html

                        # Exibir o grafo
                        components.html(render_html, height=750, scrolling=True)

                        # Bot√µes de download
                        st.markdown("##### üì• Exportar dados")
                        col_dl1, col_dl2, col_dl3, col_dl4 = st.columns(4)
                        with col_dl1:
                            st.download_button(
                                "PDF",
                                data=viz_state.get("pdf", b""),
                                file_name="rede_autores.pdf",
                                mime="application/pdf",
                                key="btn_pdf_dl"
                            )
                        with col_dl2:
                            st.download_button(
                                "GEXF",
                                data=viz_state.get("gexf", b""),
                                file_name="rede_autores.gexf",
                                mime="application/gexf+xml",
                                key="btn_gexf_dl"
                            )
                        with col_dl3:
                            st.download_button(
                                "N√≥s CSV",
                                data=viz_state.get("nodes_csv", ""),
                                file_name="autores_nos.csv",
                                mime="text/csv",
                                key="btn_nodes_dl"
                            )
                        with col_dl4:
                            st.download_button(
                                "Arestas CSV",
                                data=viz_state.get("edges_csv", ""),
                                file_name="citacoes_arestas.csv",
                                mime="text/csv",
                                key="btn_edges_dl"
                            )
                    else:
                        st.info("Clique em 'GERAR GRAFO' para visualizar a rede de autores.")

            # ========================================
            # TAB 2: AN√ÅLISE TEXTUAL (NLP)
            # ========================================
            with tab_nlp:
                st.markdown("### üìù An√°lise Textual dos Resumos")
                st.markdown("""
                Visualize as palavras mais frequentes nos resumos do cat√°logo.
                As palavras comuns sem valor sem√¢ntico s√£o automaticamente removidas.
                """)

                if not NLP_AVAILABLE:
                    st.error("‚ùå M√≥dulo de NLP n√£o dispon√≠vel.")
                else:
                    try:
                        # Coletar todos os resumos
                        resumos = df['resumo'].dropna().astype(str).tolist()
                        resumos = [r for r in resumos if r.strip() and r.strip() not in ['', 'nan', 'None']]

                        if not resumos:
                            st.info("‚ÑπÔ∏è N√£o h√° resumos dispon√≠veis para an√°lise.")
                        else:
                            # st.success(f"‚úÖ Analisando **{len(resumos)}** resumos...") # Removido para limpar a UI se desejar, mas vou manter o feedback de contagem simples se n√£o foi pedido para tirar.
                            # O usu√°rio pediu para retirar a info do spacy.
                            
                            # Juntar texto
                            texto_completo = ' '.join(resumos)
                            
                            # Ordem importa: substituir frases maiores primeiro
                            replacements = [
                                (r'\b[Rr][√©√®e]gis\s+[Bb]onvicino\b', 'R√©gis_Bonvicino'), 
                                (r'\b[Rr][√©√®e]gis\b', 'R√©gis_Bonvicino'), 
                                (r'\b[Bb]onvicino\b', 'R√©gis_Bonvicino'),
                                (r'\b[Cc]harles\s+[Bb]ernstein\b', 'Charles_Bernstein'),
                                (r'\b[Cc]harles\b', 'Charles_Bernstein'),
                                (r'\b[Bb]ernstein\b', 'Charles_Bernstein'),
                                (r'\b[Oo]dile\s+[Cc]isneros\b', 'Odile_Cisneros'),
                                (r'\b[Oo]dile\b', 'Odile_Cisneros'),
                                (r'\b[Cc]isneros\b', 'Odile_Cisneros'),
                                (r'\b[Pp]oetas?\b', 'poeta(s)'),     
                                (r'\b[Pp]oemas?\b', 'poema(s)'),
                                (r'\b[Ss]ibila\b', 'Sibila'),             
                                (r'\b[Hh]aarlem\b', 'Haarlem'),
                            ]
                            
                            # Palavras a EXCLUIR explicitamente (Regras do Usu√°rio)
                            EXCLUSOES = {
                                'sobre', 'se√ß√£o', 'destacando', 'destaca', 'apresenta', 'traz', 
                                'autor', 'autores', 'autora', 'autoras', 'texto', 'textos', 'revista', 'obra', 'obras',
                                'parte', 'partes', 'forma', 'formas', 'ser', 'ter', 'estar', 'haver',
                                'artigo', 'ensaio', 'resumo', 'publica√ß√£o', 'bil√≠ngue', 'paulo',
                                'produ√ß√£o', 'anos', 'apresenta√ß√£o', 'entrevista', 'papel',
                                'carlos', 'livro', 'escrita', 'edi√ß√£o', 'leitura', 'editorial', 'n√∫mero', 'meio'
                            }

                            final_tokens = []

                            if SPACY_AVAILABLE:
                                # Processamento com Spacy
                                nlp_spacy.max_length = len(texto_completo) + 100000
                                doc = nlp_spacy(texto_completo)
                                
                                for token in doc:
                                    if token.pos_ not in ['NOUN', 'PROPN', 'ADJ']:
                                        continue
                                    
                                    word = token.text.strip()
                                    word_lower = word.lower()
                                    
                                    if word_lower in STOP_WORDS_PT or word_lower in EXCLUSOES or len(word) < 3:
                                        continue
                                        
                                    if word_lower in ['r√©gis', 'regis', 'bonvicino']:
                                        final_tokens.append('R√©gis Bonvicino')
                                        continue

                                    if word_lower in ['charles', 'bernstein']:
                                        final_tokens.append('Charles Bernstein')
                                        continue
                                        
                                    if word_lower in ['odile', 'cisneros']:
                                        final_tokens.append('Odile Cisneros')
                                        continue

                                    if word_lower in ['poeta', 'poetas']:
                                        final_tokens.append('poeta(s)')
                                        continue

                                    if word_lower in ['poema', 'poemas']:
                                        final_tokens.append('poema(s)')
                                        continue

                                    if word_lower == 'sibila':
                                        final_tokens.append('Sibila')
                                        continue
                                        
                                    if word_lower == 'poesia':
                                        final_tokens.append('poesia')
                                        continue

                                    if word_lower == 'arte':
                                        final_tokens.append('arte')
                                        continue

                                    if token.pos_ == 'PROPN' or list(word)[0].isupper():
                                        final_tokens.append(word)
                                    else:
                                        final_tokens.append(word.lower())

                            else:
                                # Fallback NLTK
                                texto_proc = texto_completo
                                for pattern, repl in replacements:
                                    import re
                                    texto_proc = re.sub(pattern, repl, texto_proc, flags=re.IGNORECASE)
                                
                                tokens = texto_proc.split()
                                for t in tokens:
                                    t_clean = t.strip(string.punctuation)
                                    if not t_clean: continue
                                    
                                    t_lower = t_clean.lower()
                                    
                                    if t_lower in STOP_WORDS_PT or t_lower in EXCLUSOES or len(t_clean) < 3:
                                        continue
                                        
                                    final_tokens.append(t_clean.replace('_', ' '))

                            # Contar frequ√™ncias
                            freq = Counter(final_tokens)

                            # Controle de quantidade
                            n_palavras = st.slider("N√∫mero de palavras a exibir:", 10, 50, 25)

                            # Top palavras
                            top_palavras = freq.most_common(n_palavras)

                            if top_palavras:
                                df_freq = pd.DataFrame(top_palavras, columns=['Palavra', 'Frequ√™ncia'])

                                # Gr√°fico de barras
                                fig_freq = px.bar(
                                    df_freq,
                                    x='Frequ√™ncia',
                                    y='Palavra',
                                    orientation='h',
                                    title='Palavras mais frequentes nos resumos',
                                    color='Frequ√™ncia',
                                    color_continuous_scale='Blues'
                                )
                                fig_freq.update_layout(yaxis={'categoryorder': 'total ascending'})
                                st.plotly_chart(fig_freq, use_container_width=True)

                                # Tabela de frequ√™ncias
                                with st.expander("üìã Ver tabela completa de frequ√™ncias"):
                                    st.dataframe(df_freq, use_container_width=True)

                                # Estat√≠sticas
                                st.markdown("#### üìä Estat√≠sticas")
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("Palavras √∫nicas (Conceitos)", len(freq))
                                with col2:
                                    st.metric("Total Considerado", len(final_tokens))

                                # Download
                                csv_freq = df_freq.to_csv(index=False)
                                st.download_button(
                                    "üì• Baixar frequ√™ncias (CSV)",
                                    data=csv_freq,
                                    file_name="frequencia_conceitos_resumos.csv",
                                    mime="text/csv",
                                    key="btn_freq_csv"
                                )
                            else:
                                st.warning("N√£o foi poss√≠vel extrair palavras significativas dos resumos.")

                    except Exception as e:
                        st.error(f"‚ùå Erro na an√°lise textual: {str(e)}")
                        # Debug em caso de erro no Spacy
                        import traceback
                        st.code(traceback.format_exc())

            # ========================================
            # TAB 3: MATRIZ DE CORRELA√á√ÉO
            # ========================================
            with tab_correlacao:
                st.markdown("### üìä Matriz de Correla√ß√£o: G√™neros √ó Palavras-chave")
                st.markdown("""
                Visualiza√ß√£o: tipos textuais (vocabul√°rio controlado) associados √†s palavras-chave
                """)

                if not SEABORN_AVAILABLE or not MATPLOTLIB_AVAILABLE:
                    st.error("‚ùå Bibliotecas `seaborn` e/ou `matplotlib` n√£o dispon√≠veis.")
                else:
                    try:
                        # Construir matriz de co-ocorr√™ncia
                        generos = []
                        palavras_chave_todas = []

                        for _, row in df.iterrows():
                            genero = row.get('vocabulario_controlado', '')
                            pcs = row.get('palavras_chave', [])
                            if genero and isinstance(pcs, list) and pcs:
                                for pc in pcs:
                                    if pc:
                                        generos.append(str(genero).strip())
                                        palavras_chave_todas.append(str(pc).strip())

                        if not generos or not palavras_chave_todas:
                            st.info("‚ÑπÔ∏è N√£o h√° dados suficientes para gerar a matriz. Verifique se existem registros com vocabul√°rio controlado E palavras-chave.")
                        else:
                            # Criar DataFrame de co-ocorr√™ncias
                            df_cooc = pd.DataFrame({'genero': generos, 'palavra_chave': palavras_chave_todas})

                            # Contar co-ocorr√™ncias
                            matriz = pd.crosstab(df_cooc['genero'], df_cooc['palavra_chave'])

                            # Filtrar para mostrar apenas as mais frequentes
                            n_generos = st.slider("N√∫mero de g√™neros a exibir:", 5, 20, 10, key="slider_generos")
                            n_palavras_chave = st.slider("N√∫mero de palavras-chave a exibir:", 5, 30, 15, key="slider_pc")

                            # Top g√™neros e palavras-chave por frequ√™ncia total
                            top_generos = matriz.sum(axis=1).nlargest(n_generos).index.tolist()
                            top_pcs = matriz.sum(axis=0).nlargest(n_palavras_chave).index.tolist()

                            matriz_filtrada = matriz.loc[top_generos, top_pcs]

                            if matriz_filtrada.empty:
                                st.warning("Matriz vazia ap√≥s filtragem.")
                            else:
                                # Criar heatmap com matplotlib/seaborn
                                fig, ax = plt.subplots(figsize=(12, 8))
                                sns.heatmap(
                                    matriz_filtrada,
                                    annot=True,
                                    fmt='d',
                                    cmap='Blues',
                                    ax=ax,
                                    cbar_kws={'label': 'Frequ√™ncia'}
                                )
                                ax.set_xlabel('Palavras-chave', fontsize=12)
                                ax.set_ylabel('G√™nero/Tipo Textual', fontsize=12)
                                ax.set_title('Correla√ß√£o entre G√™neros e Palavras-chave', fontsize=14)
                                plt.xticks(rotation=45, ha='right')
                                plt.yticks(rotation=0)
                                plt.tight_layout()

                                st.pyplot(fig)
                                plt.close()

                                # Estat√≠sticas
                                st.markdown("#### üìä Estat√≠sticas da Matriz")
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("G√™neros √∫nicos", len(matriz.index))
                                with col2:
                                    st.metric("Palavras-chave √∫nicas", len(matriz.columns))
                                with col3:
                                    st.metric("Associa√ß√µes totais", len(df_cooc))

                                # Download matriz
                                csv_matriz = matriz_filtrada.to_csv()
                                st.download_button(
                                    "üì• Baixar matriz (CSV)",
                                    data=csv_matriz,
                                    file_name="matriz_generos_palavras_chave.csv",
                                    mime="text/csv",
                                    key="btn_matriz_csv"
                                )

                    except Exception as e:
                        st.error(f"‚ùå Erro ao gerar matriz de correla√ß√£o: {str(e)}")

            # ========================================
            # TAB 4: DNA DAS EDI√á√ïES (RADAR CHART)
            # ========================================
            with tab_dna:
                st.markdown("### üß¨ Perfil Estrutural das Edi√ß√µes")
                st.markdown("""
                Compare as caracter√≠sticas estruturais de diferentes n√∫meros da Sibila.
                O gr√°fico abaixo tra√ßa uma 'impress√£o digital' baseada em 4 dimens√µes:
                
                *   **Internacionaliza√ß√£o**: Propor√ß√£o de textos em l√≠ngua estrangeira ou com segundo idioma.
                *   **Tradu√ß√£o**: Propor√ß√£o de textos que envolvem tradu√ß√£o.
                *   **Visualidade**: Densidade de imagens por artigo (normalizada).
                *   **Ensa√≠smo**: Propor√ß√£o de textos classificados como 'Ensaio' ou 'Cr√≠tica'.
                """)
                
                try:
                    import plotly.graph_objects as go
                    
                    # Preparar dados por edi√ß√£o
                    revistas_unicas = sorted(list(set(df['n'].dropna().astype(str).unique())), 
                                           key=lambda x: ORDEM_SIBILA.index(x) if x in ORDEM_SIBILA else 999)
                    
                    dados_radar = []
                    
                    # Calcular m√©tricas para todas as revistas para normalizar visualidade
                    max_visualidade_dataset = 0
                    temp_metrics = {}

                    for rev in revistas_unicas:
                        df_rev = df[df['n'].astype(str) == rev]
                        if df_rev.empty: continue
                        
                        total_items = len(df_rev)
                        
                        # 1. Internacionaliza√ß√£o
                        # Idioma 1 diferente de POR ou PRESEN√áA de idioma 2
                        internac_count = df_rev[
                            (df_rev['idioma_01'].str.upper() != 'POR') | 
                            (df_rev['idioma_02'].notna() & (df_rev['idioma_02'] != ''))
                        ].shape[0]
                        score_internac = (internac_count / total_items) * 100
                        
                        # 2. Tradu√ß√£o
                        # Lista de tradutores n√£o vazia
                        traducao_count = df_rev[df_rev['tradutores'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False)].shape[0]
                        score_traducao = (traducao_count / total_items) * 100
                        
                        # 3. Visualidade (Densidade)
                        # Total de √≠cones / Total de artigos
                        total_icones = df_rev['iconografias'].apply(lambda x: len(x) if isinstance(x, list) else 0).sum()
                        density_visual = total_icones / total_items
                        if density_visual > max_visualidade_dataset:
                            max_visualidade_dataset = density_visual
                            
                        # 4. Ensa√≠smo vs Poesia
                        # Contar 'Ensaio', 'Cr√≠tica', 'Resenha' vs Tudo
                        ensaios_count = df_rev[
                            df_rev['vocabulario_controlado'].astype(str).str.upper().str.contains('ENSAIO|CR√çTICA|RESENHA|ENTREVISTA')
                        ].shape[0]
                        score_ensaismo = (ensaios_count / total_items) * 100
                        
                        temp_metrics[rev] = {
                            'Internacionaliza√ß√£o': score_internac,
                            'Tradu√ß√£o': score_traducao,
                            'Raw_Visualidade': density_visual,
                            'Ensa√≠smo': score_ensaismo
                        }
                        
                    # Seletor de revistas
                    opcoes_padrao = revistas_unicas[:3] if len(revistas_unicas) >= 3 else revistas_unicas
                    revistas_selecionadas = st.multiselect(
                        "Selecione as edi√ß√µes para comparar:",
                        revistas_unicas,
                        default=opcoes_padrao
                    )
                    
                    if not revistas_selecionadas:
                        st.warning("Selecione pelo menos uma revista.")
                    else:
                        fig = go.Figure()
                        
                        # Dados para exporta√ß√£o
                        export_data = []
                        
                        for rev in revistas_selecionadas:
                            metrics = temp_metrics.get(rev)
                            if not metrics: continue
                            
                            # Normalizar visualidade (0-100 relativo ao m√°ximo do dataset)
                            norm_visualidade = (metrics['Raw_Visualidade'] / max_visualidade_dataset * 100) if max_visualidade_dataset > 0 else 0
                            
                            valores = [
                                metrics['Internacionaliza√ß√£o'],
                                metrics['Tradu√ß√£o'],
                                norm_visualidade,
                                metrics['Ensa√≠smo'],
                                metrics['Internacionaliza√ß√£o'] # Fechar o ciclo
                            ]
                            
                            categorias = ['Internacionaliza√ß√£o', 'Tradu√ß√£o', 'Visualidade', 'Ensa√≠smo', 'Internacionaliza√ß√£o']
                            
                            fig.add_trace(go.Scatterpolar(
                                r=valores,
                                theta=categorias,
                                fill='toself',
                                name=f'Revista {rev}'
                            ))

                            # Coletar dados para tabela de exporta√ß√£o
                            export_data.append({
                                'Revista': rev,
                                'Internacionaliza√ß√£o (%)': round(metrics['Internacionaliza√ß√£o'], 2),
                                'Tradu√ß√£o (%)': round(metrics['Tradu√ß√£o'], 2),
                                'Ensa√≠smo (%)': round(metrics['Ensa√≠smo'], 2),
                                'Visualidade (√çndice Bruto)': round(metrics['Raw_Visualidade'], 4),
                                'Visualidade (Normalizada 0-100)': round(norm_visualidade, 2)
                            })
                            
                        fig.update_layout(
                            polar=dict(
                                radialaxis=dict(
                                    visible=True,
                                    range=[0, 100]
                                )
                            ),
                            showlegend=True,
                            title={
                                'text': "Perfil Estrutural das Edi√ß√µes",
                                'y':0.95,
                                'x':0.5,
                                'xanchor': 'center',
                                'yanchor': 'top'
                            },
                            height=850, # Aumentado conforme solicitado
                            width=1000,
                            margin=dict(l=80, r=80, t=100, b=80)
                        )
                        
                        # Configura√ß√£o da barra de ferramentas para permitir download SVG/PNG
                        st.plotly_chart(fig, use_container_width=True, config={
                            'toImageButtonOptions': {
                                'format': 'svg', # SVG √© vetorial, ideal para "PDF" ou alta qualidade
                                'filename': 'dna_sibila_radar',
                                'height': 850,
                                'width': 1000,
                                'scale': 2 # Alta resolu√ß√£o
                            },
                            'displayModeBar': True,
                            'displaylogo': False
                        })
                        
                        st.caption(f"*Visualidade normalizada relativa √† edi√ß√£o mais visual (Max Densidade: {max_visualidade_dataset:.2f} img/artigo)")

                        # Bot√µes de Exporta√ß√£o dos Dados
                        if export_data:
                            st.markdown("### üì• Exportar Dados do Gr√°fico")
                            df_export_radar = pd.DataFrame(export_data)
                            
                            col_rad1, col_rad2 = st.columns(2)
                            
                            # CSV
                            csv_radar = df_export_radar.to_csv(index=False)
                            col_rad1.download_button(
                                "üìã Baixar Dados (CSV)",
                                data=csv_radar,
                                file_name="dna_sibila_dados.csv",
                                mime="text/csv",
                                key="btn_radar_csv_export"
                            )
                            
                            # Excel
                            try:
                                excel_radar = UtilsModule.converter_excel(df_export_radar)
                                col_rad2.download_button(
                                    "üìä Baixar Dados (Excel)",
                                    data=excel_radar,
                                    file_name="dna_sibila_dados.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key="btn_radar_excel_export"
                                )
                            except Exception as e:
                                col_rad2.warning(f"Excel indispon√≠vel: {e}")

                except Exception as e:
                    st.error(f"‚ùå Erro ao gerar Radar Chart: {str(e)}")

    # --- DI√ÅRIO DE PESQUISA ---
    elif menu == "DI√ÅRIO DE PESQUISA":
        st.title("üìù DI√ÅRIO DE PESQUISA ‚Äì PROJETO SIBILA")
        diario = PersistenceModule.load_diario()
        with st.expander("‚ûï Registrar nova entrada no di√°rio", expanded=True):
            with st.form("form_diario_geral"):
                titulo = st.text_input("T√≠tulo da entrada")
                texto = st.text_area("Texto da entrada", height=160)
                tags = st.text_input("Tags (separadas por v√≠rgula)")
                reg_ops = []
                reg_ids = []
                for r in dados:
                    label = f"{r.get('n','?')} | Reg: {r.get('registro','?')} | {r.get('titulo_artigo','[sem t√≠tulo]')}"
                    reg_ops.append(label)
                    reg_ids.append(r.get('_id'))
                registros_sel = st.multiselect(
                    "Vincular a registros espec√≠ficos (opcional)", reg_ops
                )
                if st.form_submit_button("üíæ Salvar entrada no di√°rio"):
                    if texto.strip():
                        vinc_ids = [
                            reg_ids[reg_ops.index(lbl)] for lbl in registros_sel
                        ]
                        entrada = {
                            "id": str(int(datetime.now().timestamp() * 1000)),
                            "data": datetime.now().isoformat(),
                            "titulo": titulo.strip() or "[sem t√≠tulo]",
                            "texto": texto.strip(),
                            "tags": [t.strip() for t in tags.split(',') if t.strip()],
                            "registros_relacionados": vinc_ids
                        }
                        diario.append(entrada)
                        if PersistenceModule.save_diario(diario):
                            st.success("Entrada adicionada ao di√°rio.")
                    else:
                        st.warning("O texto da entrada n√£o pode estar vazio.")

        st.markdown("---")
        st.subheader("Entradas registradas")
        if not diario:
            st.info("Nenhuma entrada registrada ainda.")
        else:
            tags_existentes = sorted(
                list(
                    set(
                        t
                        for d in diario
                        for t in d.get('tags', [])
                    )
                )
            )
            c1, c2 = st.columns([1, 2])
            with c1:
                tag_filtro = st.multiselect("Filtrar por tags", tags_existentes)
            with c2:
                ordem = st.selectbox("Ordenar por", ["Mais recentes primeiro", "Mais antigas primeiro"])

            entradas = diario.copy()
            entradas = sorted(
                entradas,
                key=lambda x: x.get('data', ''),
                reverse=(ordem == "Mais recentes primeiro")
            )
            if tag_filtro:
                entradas = [
                    e for e in entradas
                    if any(t in e.get('tags', []) for t in tag_filtro)
                ]

            for e in entradas:
                dt = e.get('data', '')[:16].replace("T", " ")
                st.markdown(
                    f"""
                    <div class="nelic-card">
                        <div class="nelic-card-header">{e.get('titulo','[sem t√≠tulo]')}</div>
                        <div class="nelic-card-subtitle">Data: {dt}</div>
                        <div class="nelic-muted">{e.get('texto','')}</div>
                        <div style="margin-top:0.4rem;">
                    """,
                    unsafe_allow_html=True
                )
                if e.get('tags'):
                    st.markdown(
                        " ".join(
                            [f"<span class='nelic-tag nelic-tag-muted'>{t}</span>" for t in e['tags']]
                        ),
                        unsafe_allow_html=True
                    )
                if e.get('registros_relacionados'):
                    st.markdown("<br><span class='nelic-muted'>Registros vinculados:</span>", unsafe_allow_html=True)
                    labels = []
                    for reg_id in e.get('registros_relacionados', []):
                        r = UtilsModule.get_registro_by_id(dados, reg_id)
                        if r:
                            labels.append(
                                f"{r.get('n','?')} | Reg: {r.get('registro','?')} | {r.get('titulo_artigo','[sem t√≠tulo]')}"
                            )
                    if labels:
                        st.markdown(
                            "<br>".join(labels),
                            unsafe_allow_html=True
                        )
                st.markdown("</div>", unsafe_allow_html=True)

    # --- METODOLOGIA ---
    elif menu == "METODOLOGIA":
        st.title("üìö METODOLOGIA NELIC")

        st.markdown("""
        <div class="info-box">
        <p><strong>Sistema NELIC</strong> √© uma ferramenta de cataloga√ß√£o bibliogr√°fica especializada,
        desenvolvida para documenta√ß√£o sistem√°tica de peri√≥dicos liter√°rios. Este sistema implementa
        a metodologia NELIC de indexa√ß√£o para a cataloga√ß√£o de arquivos, auxiliando em an√°lises e
        reflex√µes cr√≠ticas sobre a produ√ß√£o cultural e liter√°ria.</p>
        </div>
        """, unsafe_allow_html=True)

        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üìù Cataloga√ß√£o",
            "üîç Busca e Explora√ß√£o",
            "üìä An√°lises e Relat√≥rios",
            "üéì Metodologia Detalhada",
            "üí° Dicas de Uso"
        ])

        with tab1:
            st.markdown("### üìù GUIA DE CATALOGA√á√ÉO")

            st.markdown("""
            <div class="metod-section">
            <h4>Editor de Registros</h4>
            <p>O editor permite criar novos registros ou editar registros existentes. Cada registro representa
            um texto publicado e deve conter informa√ß√µes bibliogr√°ficas completas.</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("#### Campos do Formul√°rio de Cataloga√ß√£o")

            st.markdown("""
            <div class="metod-section">
            <h4>1. IDENTIFICA√á√ÉO B√ÅSICA</h4>
            <p><em>Campos obrigat√≥rios marcados com asterisco (*)</em></p>
            <ul>
                <li><strong>N¬∫ REVISTA:</strong> N√∫mero da edi√ß√£o da revista (1 a 13)</li>
                <li><strong>REGISTRO:</strong> C√≥digo √∫nico de identifica√ß√£o</li>
                <li><strong>P√ÅGINAS:</strong> Intervalo de p√°ginas (exemplo: 45-48)</li>
                <li><strong>ORDEM:</strong> N√∫mero de ordem de exibi√ß√£o no sistema</li>
                <li><strong>IDIOMAS:</strong> Idioma prim√°rio e secund√°rio (se bil√≠ngue)</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>2. TIPO TEXTUAL (Sistema Hier√°rquico)</h4>
            <p>O sistema utiliza classifica√ß√£o em <strong>dois n√≠veis</strong>:</p>

            <p><strong>TIPOS PRINCIPAIS:</strong></p>
            <ul>
                <li>POEMA(S) - n√£o exige resumo</li>
                <li>ENSAIO - exige resumo anal√≠tico</li>
                <li>RESENHA - exige resumo anal√≠tico</li>
                <li>ENTREVISTA - exige resumo anal√≠tico</li>
                <li>FIC√á√ÉO - n√£o exige resumo</li>
                <li>EDITORIAL</li>
                <li>APRESENTA√á√ÉO</li>
                <li>REPORTAGEM</li>
                <li>CARTAS DO LEITOR</li>
                <li>E outros</li>
            </ul>

            <p><strong>SUBTIPOS (Campo disciplinar):</strong></p>
            <p>Alguns tipos principais permitem especifica√ß√£o disciplinar:</p>
            <ul>
                <li>ENSAIO: Literatura, Filosofia, Hist√≥ria, Lingu√≠stica, etc.</li>
                <li>RESENHA: Literatura, Antropologia, Sociologia, etc.</li>
                <li>ENTREVISTA: Literatura</li>
                <li>INFORME: Literatura</li>
            </ul>
            <p><strong>Exemplo:</strong> ENSAIO - Filosofia</p>
            <p><strong>‚ö†Ô∏è ATEN√á√ÉO:</strong> O sistema valida automaticamente se o tipo textual exige resumo anal√≠tico.</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>3. T√çTULOS E NOTAS</h4>
            <p><strong>T√çTULO (obrigat√≥rio):</strong></p>
            <ul>
                <li>Se o texto possui t√≠tulo: transcreva fielmente</li>
                <li>Se poema sem t√≠tulo: insira primeiro verso entre aspas e retic√™ncias
                    <br>Exemplo: "n√£o penses enquanto passa (‚Ä¶)"</li>
                <li>Se prosa sem t√≠tulo: reproduza as 4-5 primeiras palavras</li>
            </ul>

            <p><strong>SUBT√çTULO:</strong> Caso exista</p>

            <p><strong>NOTA DE EDI√á√ÉO:</strong> Informa√ß√µes editoriais importantes</p>
            <ul>
                <li>[publica√ß√£o bil√≠ngue]</li>
                <li>[tradu√ß√£o do ingl√™s]</li>
                <li>[texto republicado de...]</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>4. RESPONSABILIDADE AUTORAL</h4>
            <p><strong>FORMATO ABNT (autom√°tico):</strong> O sistema converte automaticamente para SOBRENOME, Prenomes</p>

            <p><strong>Exemplos:</strong></p>
            <ul>
                <li>Digite: R√©gis Bonvicino ‚Üí Sistema salva: BONVICINO, R√©gis</li>
                <li>Digite: Claudio Daniel ‚Üí Sistema salva: DANIEL, Claudio</li>
            </ul>

            <p><strong>COLABORADORES:</strong> Autores do texto (um por linha)</p>
            <p><strong>TRADUTORES:</strong> Se aplic√°vel (um por linha)</p>
            <p><strong>üí° Dica:</strong> Digite um nome por linha ou separe por v√≠rgulas</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>5. ASSUNTOS E INDEXA√á√ÉO</h4>
            <p><strong>AUTORES CITADOS:</strong> Autores mencionados no texto (um por linha)</p>
            <ul>
                <li>Use para mapear refer√™ncias bibliogr√°ficas</li>
                <li>Importante para an√°lise de redes intelectuais</li>
            </ul>

            <p><strong>PALAVRAS-CHAVE:</strong> Use APENAS termos do Vocabul√°rio Controlado</p>
            <ul>
                <li>Lista pr√©-estabelecida de 400+ termos</li>
                <li>Garante consist√™ncia nas buscas</li>
                <li>Exemplos: Poesia, Modernismo, Vanguarda, Literatura Brasileira</li>
            </ul>

            <p><strong>NOME PESSOAL COMO ASSUNTO:</strong> Pessoas que s√£o tema principal</p>
            <ul>
                <li>Use para biografias, homenagens, estudos cr√≠ticos</li>
                <li>Exemplo: texto sobre Drummond ‚Üí ANDRADE, Carlos Drummond de</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>6. RESUMO ANAL√çTICO</h4>
            <p><strong>‚ö†Ô∏è OBRIGAT√ìRIO PARA:</strong></p>
            <ul>
                <li>ENSAIO</li>
                <li>RESENHA</li>
                <li>ENTREVISTA</li>
                <li>REPORTAGEM</li>
                <li>EDITORIAL (com conte√∫do anal√≠tico)</li>
                <li>APRESENTA√á√ÉO</li>
                <li>DEBATE</li>
            </ul>

            <p><strong>N√ÉO EXIGIDO PARA:</strong></p>
            <ul>
                <li>POEMA(S)</li>
                <li>FIC√á√ÉO</li>
                <li>CAPA</li>
                <li>IMAGENS</li>
                <li>HQ/CHARGE</li>
            </ul>

            <p><strong>Como escrever:</strong> S√≠ntese cr√≠tica do conte√∫do (150-300 palavras)</p>
            <ul>
                <li>Tema central</li>
                <li>Argumentos principais</li>
                <li>Conclus√µes ou posi√ß√µes defendidas</li>
            </ul>

            <p><strong>Nota:</strong> O sistema valida automaticamente e impede salvar se resumo estiver ausente quando obrigat√≥rio.</p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div class="metod-section">
            <h4>7. ICONOGRAFIA</h4>
            <p>Documenta√ß√£o sistem√°tica de elementos visuais:</p>

            <p><strong>TIPOS:</strong></p>
            <ul>
                <li>Foto</li>
                <li>Ilustra√ß√£o</li>
                <li>Reprodu√ß√£o (de obra de arte)</li>
                <li>Fac-s√≠mile</li>
                <li>Cartografia</li>
                <li>Gr√°fico/Tabela</li>
                <li>HQ/Charge</li>
                <li>Fotograma</li>
                <li>Publicidade</li>
            </ul>

            <p><strong>DESCRI√á√ÉO:</strong> T√≠tulo da obra, cr√©ditos, data</p>
            <p><strong>Exemplo:</strong></p>
            <ul>
                <li>Tipo: Foto</li>
                <li>Descri√ß√£o: "Retrato de Jo√£o Cabral de Melo Neto. Foto: Arquivo Nacional, 1960"</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

        with tab2:
            st.markdown("### üîç Busca e Explora√ß√£o")

            st.markdown("""
            <div class="metod-section">
            <p>A busca e a explora√ß√£o de dados no sistema NELIC de indexa√ß√£o se organizam em torno de uma ideia simples:
            qualquer consulta come√ßa pela defini√ß√£o de um recorte dentro do conjunto de registros catalogados. Esse recorte
            pode ser temporal (per√≠odo, fasc√≠culos, volumes), formal (tipologia dos textos), lingu√≠stico (idiomas envolvidos),
            autoral (quem escreve, quem √© citado), tem√°tico (palavras-chave) ou material (presen√ßa de iconografia).</p>

            <p>O sistema NELIC de indexa√ß√£o funciona sempre sobre a mesma base de dados estruturada, em que cada texto possui
            campos definidos (idioma, vocabul√°rio controlado, autores colaboradores, autores citados, palavras-chave, iconografia,
            p√°ginas, entidade coletiva, entre outros). A busca consiste em selecionar combina√ß√µes desses campos para obter
            subconjuntos coerentes. Alguns exemplos de recortes poss√≠veis:</p>

            <ul>
                <li>textos de um determinado per√≠odo e de um √∫nico tipo textual, como "ensaios entre 2001 e 2002";</li>
                <li>textos em mais de um idioma, de modo a isolar publica√ß√µes bil√≠ngues;</li>
                <li>textos que tenham uma palavra-chave espec√≠fica, como "modernismo" ou "tradu√ß√£o";</li>
                <li>textos em que um determinado nome aparece como autor colaborador, como autor citado ou como "nome pessoal como assunto".</li>
            </ul>

            <p>No caso de recortes temporais, como "ensaios entre 2001 e 2002", o sistema n√£o possui um filtro direto por ano.
            O procedimento depende do mapeamento entre ano e n√∫mero da revista: √© necess√°rio saber quais n√∫meros correspondem
            a 2001 e 2002 e, em seguida, selecionar esses n√∫meros no filtro de "Revista" da aba EXPLORAR DADOS, combinando
            com o tipo textual "Ensaio".</p>

            <p>A l√≥gica √© cumulativa: ao combinar crit√©rios de tipologia, idioma, palavra-chave e autoria, o sistema reduz
            progressivamente o universo de registros at√© chegar a um conjunto bem delimitado. Um recorte como "ensaios em espanhol
            sobre cultura que citam determinado te√≥rico" pode ser trabalhado, na pr√°tica, da seguinte forma: na aba EXPLORAR DADOS,
            selecionar "Ensaio" em "Tipo Textual", escolher "Cultura" (ou o termo tem√°tico mais pr√≥ximo dispon√≠vel) no campo de
            "Palavras-Chave" e inserir o sobrenome do te√≥rico no campo de "Busca Livre (T√≠tulo/Resumo)". Essa busca livre percorre
            tamb√©m colunas textuais internas, de modo que registros em que o te√≥rico apare√ßa como autor citado tendem a ser recuperados.
            Como n√£o h√° filtro espec√≠fico por idioma nessa tela, a etapa "em espanhol" exige um passo adicional: depois de obter o
            conjunto de ensaios com aquele tema e aquele te√≥rico, basta exportar os resultados para Excel e filtrar, na planilha,
            a coluna de idioma pela sigla correspondente (por exemplo, "ESP" para espanhol).</p>

            <p>O resultado t√≠pico de uma busca √© uma lista tabular de registros, em que cada linha corresponde a um texto e cada
            coluna a um campo relevante (t√≠tulo, autores, tipo textual, idiomas, p√°ginas, palavras-chave, presen√ßa de iconografia).
            A partir dessa lista, j√° √© poss√≠vel observar padr√µes simples, como a concentra√ß√£o de um mesmo autor em determinado per√≠odo,
            a recorr√™ncia de certas palavras-chave em tipos textuais espec√≠ficos ou a distribui√ß√£o da iconografia ao longo de uma cole√ß√£o.</p>

            <p>Essa etapa de busca e explora√ß√£o funciona como momento de delimita√ß√£o do corpus para an√°lises posteriores. A qualidade
            desse trabalho depende diretamente da consist√™ncia da cataloga√ß√£o: quanto mais rigorosamente os campos forem preenchidos,
            mais precisos se tornam os recortes poss√≠veis.</p>
            </div>
            """, unsafe_allow_html=True)


        with tab3:
            st.markdown("### üìä An√°lise e Relat√≥rios")

            st.markdown("""
            <div class="metod-section">
            <p>A etapa de an√°lise trabalha com os mesmos registros catalogados, mas desloca o foco da descri√ß√£o individual de
            cada texto para a observa√ß√£o de distribui√ß√µes, frequ√™ncias e propor√ß√µes. Em vez de perguntar "quais textos satisfazem
            determinado crit√©rio?", passa-se a perguntar "como os dados se distribuem dentro de um crit√©rio ou combina√ß√£o de crit√©rios?".</p>

            <p>O sistema NELIC de indexa√ß√£o calcula, a partir dos campos preenchidos, tabelas de frequ√™ncia e percentuais. Alguns
            exemplos de sa√≠das poss√≠veis:</p>

            <ul>
                <li>distribui√ß√£o dos tipos textuais no conjunto: quantos ensaios, resenhas, poemas, entrevistas, fic√ß√µes, editoriais etc.,
                    em n√∫meros absolutos e em porcentagem;</li>
                <li>lista de autores colaboradores com o n√∫mero de textos publicados e sua participa√ß√£o relativa no total;</li>
                <li>lista de autores citados, ordenada por n√∫mero de ocorr√™ncias, o que permite mapear redes de refer√™ncia e campos te√≥ricos predominantes;</li>
                <li>distribui√ß√£o de palavras-chave mais recorrentes, indicando temas estruturantes do corpus;</li>
                <li>propor√ß√£o de textos com iconografia em rela√ß√£o ao total, bem como varia√ß√µes dessa propor√ß√£o em diferentes recortes
                    (por per√≠odo, por tipo textual, por idioma, quando esses dados forem combinados com filtros e exporta√ß√µes).</li>
            </ul>

            <p>Quando a an√°lise √© feita sobre um recorte previamente delimitado na busca (por exemplo, "todos os ensaios de um certo per√≠odo"),
            as tabelas e propor√ß√µes dizem respeito apenas a esse subconjunto. Isso permite, por exemplo, comparar os autores mais citados em
            ensaios com os autores mais citados em resenhas, ou a distribui√ß√£o de idiomas em textos cr√≠ticos em rela√ß√£o √† distribui√ß√£o em
            textos criativos.</p>

            <p>Os resultados podem ser organizados em tabelas simples com as colunas "valor" (por exemplo, o nome do autor ou da palavra-chave),
            "frequ√™ncia absoluta" e "percentual no conjunto analisado". A mesma informa√ß√£o pode ser representada em gr√°ficos de barras que
            facilitam a identifica√ß√£o de concentra√ß√µes, aus√™ncias e deslocamentos.</p>

            <p>Al√©m da visualiza√ß√£o dentro do sistema, as an√°lises podem ser exportadas em formatos adequados ao trabalho de pesquisa. Em
            planilhas, o pesquisador pode reorganizar, filtrar e combinar as tabelas com outros dados. Em relat√≥rios em PDF, os resultados
            podem ser incorporados diretamente a projetos, artigos e cap√≠tulos, documentando com clareza os crit√©rios utilizados e os n√∫meros obtidos.</p>
            </div>
            """, unsafe_allow_html=True)


        with tab4:
            st.markdown("### üéì Metodologia Detalhada")

            st.markdown("""
            <div class="metod-section">
            <p>A metodologia do sistema de cataloga√ß√£o parte da defini√ß√£o de um conjunto de campos que precisam ser preenchidos de
            maneira uniforme. Cada campo corresponde a um aspecto do texto e pode ser posteriormente utilizado como crit√©rio de busca
            ou de an√°lise. O preenchimento cuidadoso desses campos √© a base de toda a explora√ß√£o posterior.</p>

            <p><strong>Alguns campos centrais:</strong></p>

            <h4>Identifica√ß√£o b√°sica</h4>
            <p>Inclui n√∫mero ou c√≥digo do fasc√≠culo, ordem de exibi√ß√£o do texto dentro da cole√ß√£o, intervalo de p√°ginas e registro √∫nico.
            Esses dados permitem localizar o texto fisicamente e reconstruir a organiza√ß√£o interna de cada n√∫mero.</p>

            <h4>Idiomas</h4>
            <p>Registra o idioma principal do texto e, quando pertinente, um segundo idioma em caso de tradu√ß√µes ou publica√ß√µes bil√≠ngues.
            O uso de siglas padronizadas (POR, ESP, ING, ITA etc.) evita ambiguidades e facilita contagens posteriores de distribui√ß√£o lingu√≠stica.</p>

            <h4>Entidade coletiva e autoria</h4>
            <p>Quando um texto n√£o √© atribu√≠do a um indiv√≠duo, o campo "entidade coletiva" indica a responsabilidade institucional (por exemplo,
            a pr√≥pria revista ou um grupo editorial). Nos demais casos, os "autores colaboradores" s√£o listados com nome normalizado em formato
            padr√£o (sobrenome em mai√∫sculas, seguido do prenome). Em entrevistas, tanto entrevistador(es) quanto entrevistado(a) s√£o inclu√≠dos,
            de modo que a busca por qualquer um deles recupere o registro.</p>

            <h4>Tradutor</h4>
            <p>Sempre que houver tradu√ß√£o, o tradutor √© identificado pelo nome completo. Nos casos em que a tradu√ß√£o √© mencionada sem cr√©dito,
            registra-se essa condi√ß√£o (por exemplo, "sem cr√©dito") para n√£o deixar o campo vazio e, ao mesmo tempo, n√£o atribuir autoria inexistente.</p>

            <h4>T√≠tulo, subt√≠tulo e resumo</h4>
            <p>O t√≠tulo √© transcrito conforme aparece no texto, com regras espec√≠ficas para poemas ou textos em prosa sem t√≠tulo, em que se
            utilizam versos ou primeiras palavras como forma de identifica√ß√£o. O subt√≠tulo, quando existe, complementa o t√≠tulo e pode reunir
            dados adicionais, como informa√ß√µes sobre obras resenhadas. O resumo oferece uma descri√ß√£o concisa do conte√∫do em textos de car√°ter
            anal√≠tico (ensaios, resenhas, entrevistas, reportagens, apresenta√ß√µes) e √© dispensado em textos ficcionais ou po√©ticos. Notas
            complementares, informa√ß√µes de publica√ß√£o original ou peculiaridades de autoria s√£o acrescentadas entre colchetes.</p>

            <h4>Vocabul√°rio controlado (tipologia)</h4>
            <p>Cada texto recebe uma categoria de tipo textual, escolhida a partir de uma lista limitada e previamente definida. Entre as
            possibilidades est√£o apresenta√ß√£o, poema, resenha, reportagem, cartas do leitor, correspond√™ncia, depoimento, entrevista, fic√ß√£o,
            editorial, informe, HQ/charge, ensaio, entre outras. Em alguns casos, acrescenta-se um segundo termo para indicar a √°rea disciplinar
            (por exemplo, ensaio ‚Äì filosofia; resenha ‚Äì literatura). Essa solu√ß√£o permite cruzar forma textual e campo de conhecimento.</p>

            <h4>Palavras-chave</h4>
            <p>Em textos anal√≠ticos, o catalogador seleciona at√© seis palavras-chave a partir de um vocabul√°rio controlado mais amplo, que
            inclui conceitos, temas, correntes e no√ß√µes recorrentes. Isso evita varia√ß√µes arbitr√°rias de grafia e garante comparabilidade entre
            textos. Poemas, fic√ß√µes, capas, HQs e charges, em geral, n√£o recebem palavras-chave tem√°ticas para preservar a especificidade de
            seu registro.</p>

            <h4>Nome pessoal como assunto</h4>
            <p>Esse campo √© preenchido quando o texto trata diretamente de uma pessoa (autores, artistas, cr√≠ticos, te√≥ricos), independentemente
            de quem assine o texto. O mesmo nome deve aparecer tamb√©m entre os autores citados, de modo a permitir pesquisas tanto por "assunto
            pessoa" quanto por "cita√ß√£o".</p>

            <h4>Autores citados</h4>
            <p>Re√∫ne os nomes mencionados ao longo do texto. N√£o se trata de uma lista bibliogr√°fica completa, mas de um registro dos nomes que
            aparecem como refer√™ncia ou interlocu√ß√£o. Esse campo √© crucial para an√°lises de redes de cita√ß√£o, identifica√ß√£o de c√¢nones cr√≠ticos
            e mapeamento de refer√™ncias te√≥ricas.</p>

            <h4>Iconografia</h4>
            <p>Registra a presen√ßa de imagens associadas ao texto, classificadas em categorias (cartografia, fac-s√≠mile, fotografia, fotograma,
            gr√°fico/tabela, HQ/charge, ilustra√ß√£o, publicidade, reprodu√ß√£o). Para cada item, descrevem-se t√≠tulo, cr√©dito e data, com conven√ß√µes
            para casos em que essas informa√ß√µes n√£o est√£o dispon√≠veis.</p>

            <p><strong>Considera√ß√µes finais:</strong></p>
            <p>Todos esses campos s√£o simultaneamente descritivos e anal√≠ticos. Ao preencher "vocabul√°rio controlado" e "palavras-chave",
            estabelece-se a base para an√°lises tem√°ticas e formais. Ao registrar "autores citados" e "nome pessoal como assunto", cria-se a
            possibilidade de estudar redes de influ√™ncia. Ao marcar iconografia, torna-se poss√≠vel discutir o papel das imagens no conjunto.
            O sistema de indexa√ß√£o transforma, assim, o conjunto de textos em um banco de dados preparado para opera√ß√µes comparativas de diferentes ordens.</p>
            </div>
            """, unsafe_allow_html=True)


        with tab5:
            st.markdown("### üí° Dicas de Uso")

            st.markdown("""
            <div class="metod-section">
            <p>O sistema de cataloga√ß√£o foi pensado para ser √∫til tanto em consultas pontuais quanto em pesquisas de f√¥lego. Algumas
            orienta√ß√µes podem facilitar esse uso.</p>

            <p>Uma primeira etapa consiste em transformar perguntas vagas em recortes claros. Em vez de "quero ver artigos sobre teoria",
            √© poss√≠vel formular quest√µes como "ensaios com palavra-chave teoria" ou "textos em que determinado autor aparece como citado".
            A partir disso, os filtros correspondentes podem ser aplicados de forma mais precisa, em especial na aba EXPLORAR DADOS e nas
            p√°ginas de an√°lise.</p>

            <p>Os cruzamentos de dados tornam-se mais interessantes quando se pensa em pares de campos. Alguns exemplos de perguntas que
            o sistema ajuda a responder, combinando filtros e an√°lises:</p>

            <ul>
                <li>Qual a distribui√ß√£o de tipos textuais em determinado per√≠odo da cole√ß√£o?</li>
                <li>Quais autores colaboradores concentram mais publica√ß√µes em um intervalo de n√∫meros de revista?</li>
                <li>Quais autores s√£o mais citados em textos classificados como "ensaio ‚Äì literatura", e como isso se compara a textos
                    classificados como "ensaio ‚Äì filosofia"?</li>
                <li>Que palavras-chave aparecem com maior frequ√™ncia em textos bil√≠ngues, identificados depois na coluna de idiomas?</li>
                <li>Em quais tipos de texto a iconografia √© mais utilizada?</li>
            </ul>

            <p>As sa√≠das num√©ricas (contagens e percentuais) precisam ser lidas sempre em rela√ß√£o ao conjunto considerado. Um mesmo autor
            pode aparecer com um percentual baixo na base completa, mas ser central em um recorte espec√≠fico. Interpretar a propor√ß√£o dentro
            de cada recorte √© decisivo para n√£o generalizar conclus√µes.</p>

            <p>Os arquivos exportados em planilha permitem prolongar as an√°lises: calcular m√©dias, criar gr√°ficos personalizados, agrupar
            registros por per√≠odos (aproximados pelos n√∫meros da revista), comparar duas ou mais cole√ß√µes. J√° os relat√≥rios em PDF s√£o adequados
            para registrar o estado de uma pesquisa em determinado momento, servindo como documento de trabalho e registro dos recortes utilizados.</p>

            <p>O uso continuado do sistema tamb√©m funciona como revis√£o da pr√≥pria cataloga√ß√£o. Consultas que retornam resultados inesperados
            podem revelar inconsist√™ncias de preenchimento, diferen√ßas indesejadas de grafia ou campos sem dados em lugares estrat√©gicos. Nesse
            sentido, a explora√ß√£o n√£o apenas extrai informa√ß√£o anal√≠tica, mas retroalimenta o cuidado com o banco de dados, fortalecendo a
            confiabilidade do sistema de indexa√ß√£o como um todo.</p>
            </div>
            """, unsafe_allow_html=True)



    # --- MAIS DADOS ---
    elif menu == "MAIS DADOS":
        st.title("üìä MAIS DADOS - AN√ÅLISE COMPLETA")
        if not df.empty:
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("REGISTROS", len(df))
            c2.metric("COLABORADORES", DataModule.get_normalized_series(df, 'autores_colaboradores').nunique())
            c3.metric("AUTORES CITADOS", DataModule.get_normalized_series(df, 'autores_citados').nunique())
            if 'iconografias' in df.columns:
                n_icon = df['iconografias'].apply(
                    lambda x: 1 if isinstance(x, list) and len(x) > 0 else 0
                ).sum()
                p_icon = (n_icon / len(df)) * 100
                c4.metric("√çNDICE ICONOGRAFIA", f"{p_icon:.1f}%", help=f"{n_icon} registros cont√™m iconografia")
            else:
                c4.metric("√çNDICE ICONOGRAFIA", "0%")

            st.markdown("---")
            st.subheader("üì• EXPORTAR BASE COMPLETA")
            col_exp1, col_exp2, col_exp3 = st.columns(3)
            excel_completo = UtilsModule.converter_excel(df)
            pdf_completo = PDFModule.gerar_pdf_analitico(df, len(df), "Base de dados completa")
            json_completo = json.dumps(dados, ensure_ascii=False, indent=2)
            col_exp1.download_button(
                "üìä EXCEL COMPLETO",
                excel_completo,
                f"sibila_completo_{datetime.now().strftime('%Y%m%d')}.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width='stretch'
            )
            col_exp2.download_button(
                "üìÑ PDF COMPLETO",
                pdf_completo,
                f"sibila_completo_{datetime.now().strftime('%Y%m%d')}.pdf",
                "application/pdf",
                width='stretch'
            )
            col_exp3.download_button(
                "üíæ JSON COMPLETO",
                json_completo,
                f"sibila_completo_{datetime.now().strftime('%Y%m%d')}.json",
                "application/json",
                width='stretch'
            )

            st.markdown("---")
            g1, g2 = st.columns(2)
            with g1:
                s = df['vocabulario_controlado'].apply(
                    lambda x: 'Manifesto' if 'manifesto' in str(x).lower() else (str(x).split(' - ')[0] if isinstance(x, str) else x)
                )
                v = s.value_counts().head(10).reset_index()
                v.columns = ['Tipo', 'Qtd']
                fig = px.bar(v, x='Tipo', y='Qtd', text='Qtd')
                fig.update_layout(title="DISTRIBUI√á√ÉO POR TIPO TEXTUAL", height=380)
                st.plotly_chart(fig, width='stretch')
            with g2:
                r = df['n'].value_counts().reset_index()
                r.columns = ['Revista', 'Qtd']
                fig2 = px.bar(
                    r.sort_values('Revista'),
                    x='Revista',
                    y='Qtd',
                    text='Qtd'
                )
                fig2.update_layout(title="REGISTROS POR REVISTA", height=380)
                fig2.update_xaxes(type='category', tickmode='linear')
                st.plotly_chart(fig2, width='stretch')

            st.markdown("---")
            t1, t2, t3, t4 = st.tabs(
                ["PALAVRAS-CHAVE", "AUTORES CITADOS", "COLABORADORES", "TRADUTORES"]
            )
            def show_stats_with_export(col, label, tab_key):
                s = DataModule.get_normalized_series(df, col)
                if s.empty:
                    st.info(f"Sem dados de {label.lower()}.")
                    return
                counts = UtilsModule.calculate_stats_with_percentage(s)
                df_export = counts.rename(
                    columns={'Termo': 'Campo', 'Qtd': 'Num. Absoluto', '%': 'Percentual'}
                )
                st.markdown(f"### üì• Exportar dados de {label}")
                exp_col1, exp_col2, exp_col3 = st.columns(3)
                excel_cat = UtilsModule.converter_excel(df_export)
                exp_col1.download_button(
                    f"üìä EXCEL - {label.upper()}",
                    excel_cat,
                    f"sibila_{tab_key}_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    width='stretch',
                    key=f"btn_excel_{tab_key}"
                )
                pdf_cat = PDFModule.gerar_pdf_tabela_estatistica(df_export, label)
                exp_col2.download_button(
                    f"üìÑ PDF - {label.upper()}",
                    pdf_cat,
                    f"sibila_{tab_key}_{datetime.now().strftime('%Y%m%d')}.pdf",
                    "application/pdf",
                    width='stretch',
                    key=f"btn_pdf_{tab_key}"
                )
                csv_data = df_export.to_csv(index=False, encoding='utf-8-sig')
                exp_col3.download_button(
                    f"üìã CSV - {label.upper()}",
                    csv_data,
                    f"sibila_{tab_key}_{datetime.now().strftime('%Y%m%d')}.csv",
                    "text/csv",
                    width='stretch',
                    key=f"btn_csv_{tab_key}"
                )
                st.markdown("---")
                st.markdown(f"**‚¨ÜÔ∏è {label.upper()} MAIS FREQUENTES (Top 30)**")
                counts.index = counts.index + 1
                st.dataframe(counts.head(30), width='stretch')
                with st.expander(f"Mostrar tabela completa de {label} ({len(counts)} termos)"):
                    st.dataframe(counts, width='stretch')

            with t1:
                show_stats_with_export('palavras_chave', 'Palavra-chave', 'palavras_chave')
            with t2:
                show_stats_with_export('autores_citados', 'Autor Citado', 'autores_citados')
            with t3:
                show_stats_with_export('autores_colaboradores', 'Colaborador', 'colaboradores')
            with t4:
                show_stats_with_export('tradutores', 'Tradutor', 'tradutores')
        else:
            st.warning("‚ö†Ô∏è Base de dados vazia. Cadastre registros na aba CATALOGA√á√ÉO.")

    # --- EXPORTAR ---
    elif menu == "EXPORTAR":
        st.title("üíæ GERENCIAMENTO DE DADOS")
        st.markdown("### üì§ IMPORTA√á√ÉO")
        c1, c2 = st.columns(2)
        with c1:
            u = st.file_uploader("Importar JSON (cat√°logo)", type=['json'])
            if u:
                try:
                    n = json.load(u)
                    if isinstance(n, list):
                        dados.extend(n)
                        un = {v.get('_id', str(i)): v for i, v in enumerate(dados)}.values()
                        if PersistenceModule.save_data(list(un)):
                            st.success("‚úÖ Dados importados com sucesso!")
                            st.balloons()
                except Exception as e:
                    st.error(f"‚ùå Erro ao importar: {str(e)}")
        with c2:
            u2 = st.file_uploader("Importar JSON (di√°rio de pesquisa)", type=['json'])
            if u2:
                try:
                    d = json.load(u2)
                    if isinstance(d, list):
                        if PersistenceModule.save_diario(d):
                            st.success("‚úÖ Di√°rio importado com sucesso!")
                            st.balloons()
                except Exception as e:
                    st.error(f"‚ùå Erro ao importar di√°rio: {str(e)}")

        st.markdown("---")
        st.markdown("### üì• EXPORTA√á√ÉO")
        if not df.empty:
            exp_row1_col1, exp_row1_col2, exp_row1_col3 = st.columns(3)
            js = json.dumps(dados, ensure_ascii=False, indent=2)
            exp_row1_col1.download_button(
                "üì• BAIXAR JSON (CAT√ÅLOGO)",
                js,
                f"backup_sibila_{datetime.now().strftime('%Y%m%d')}.json",
                "application/json",
                width='stretch'
            )
            excel_data = UtilsModule.converter_excel(df)
            exp_row1_col2.download_button(
                "üìä BAIXAR EXCEL (CAT√ÅLOGO)",
                excel_data,
                f"backup_sibila_{datetime.now().strftime('%Y%m%d')}.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width='stretch'
            )
            csv_data = df.astype(str).to_csv(index=False, encoding='utf-8-sig')
            exp_row1_col3.download_button(
                "üìÑ BAIXAR CSV (CAT√ÅLOGO)",
                csv_data,
                f"backup_sibila_{datetime.now().strftime('%Y%m%d')}.csv",
                "text/csv",
                width='stretch'
            )
        else:
            st.info("Nenhum dado para exportar (cat√°logo).")

        st.markdown("#### Di√°rio de pesquisa")
        diario = PersistenceModule.load_diario()
        if diario:
            js_d = json.dumps(diario, ensure_ascii=False, indent=2)
            st.download_button(
                "üì• BAIXAR JSON (DI√ÅRIO)",
                js_d,
                f"diario_sibila_{datetime.now().strftime('%Y%m%d')}.json",
                "application/json",
                width='stretch'
            )
        else:
            st.info("Nenhuma entrada no di√°rio para exportar.")

        st.markdown("---")
        st.markdown("### üìä ESTAT√çSTICAS DO SISTEMA")
        stat_col1, stat_col2 = st.columns(2)
        if os.path.exists(BACKUP_DIR):
            backups = sorted(os.listdir(BACKUP_DIR), reverse=True)
            stat_col1.metric("Backups dispon√≠veis", len(backups))
        else:
            backups = []
            stat_col1.metric("Backups dispon√≠veis", 0)
        stat_col2.metric("Total de Registros", len(df))
        diario = PersistenceModule.load_diario()
        st.markdown(f"**Entradas no di√°rio de pesquisa:** {len(diario)}")
        if backups:
            st.markdown("#### üì¶ Backups salvos (√∫ltimos 5)")
            backups_recentes = backups[:5]
            for bkp in backups_recentes:
                bkp_path = os.path.join(BACKUP_DIR, bkp)
                try:
                    with open(bkp_path, 'r', encoding='utf-8') as f:
                        conteudo = f.read()
                    st.download_button(
                        f"üì• Baixar {bkp}",
                        conteudo,
                        file_name=bkp,
                        mime="application/json",
                        width='stretch',
                        key=f"btn_bkp_{bkp}"
                    )
                except Exception as e:
                    st.warning(f"N√£o foi poss√≠vel carregar o backup {bkp}: {e}")
            if len(backups) > 5:
                st.info(f"‚ÑπÔ∏è Existem mais {len(backups) - 5} backup(s) antigo(s) n√£o exibido(s).")

if __name__ == "__main__":
    main()
